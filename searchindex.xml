<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>自定义控制器开发</title><url>https://xshrim.github.io/post/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%A7%E5%88%B6%E5%99%A8%E5%BC%80%E5%8F%91/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag><tag>crd</tag><tag>operator</tag><tag>自定义控制器</tag></tags><content type="html"> 资源与控制器 资源 在Kubernetes中, 所有可被管理的对象都被抽象为资源, 如节点, 存储, 网络策略, 工作负载, 配置信息, 命名空间, 事件, 用户角色, 网络出入口等等都是资源. 资源会按照用途或关联度被划分为不同的分组.
资源分为集群和命名空间两个级别, 集群级资源可以作用于所有命名空间. 所有资源的信息都是以json或yaml格式的资源清单的形式呈现的. 资源清单中描述的资源信息会由apiserver经转换后以json或protobuf的结构持久化存储到etcd数据库中.
所有资源都可以通过统一的REST API进行声明式管理, 即只要通过API将资源清单传递到apiserver, Kubernetes将自动维护该资源在清单中指定的状态.
Kubernetes是以API Group的方式组织各种资源的API的, API群组是一组相关API对象的集合, 如Deployment, DaemonSet, StatefulSet等资源的API就属于apps组, Role, RoleBindings, ClusterRoleBindings等资源的API就属于rbac.authorization.k8s.io组. 此外由于最初并未考虑资源分组, 因此一些核心资源如node, pod, service等属于core组并可省略组名. API群组的概念使得API的管理和扩展变得更为方便.
每一个API群组都可以存在多个版本, 基于稳定性的差异, 每个版本又可以细分Alpha, Beta和Stable三个级别. 资源API的多版本是在群组层面统一定义的, 所有版本在一个Kubernetes集群中是可以通过apiserver的无损转换机制并存使用的.
对于API而言, 通过**GVR三元组(API Group, API Version和Resource)就可以唯一定位某个资源的API路径, 如: /apis/rbac.authorization.k8s.io/v1beta1/clusterroles. 而在我们熟悉的资源清单文件中, 则是对应通过GVK三元组(API Group, API Version和Kind)**进行资源区分的. 如: {"apiVersion": "apps/v1"，"kind": "Deployment"}.
控制器 资源是数据, 而处理资源的逻辑就是控制器, Kubernetes是基于控制器模式设计的, 所有资源的生命周期由apiserver管理, 而资源所代表的实际含义则是由对应的控制器完成解释的. 系统组件kube-controller-manager中内置了大量的控制器用于对各种原生资源类型的逻辑处理 , 如Pod控制器, Endpoint控制器, Namespace控制器, Serviceaccount控制器等.
每个控制器内部都包含两个核心组件: Informer/SharedInformer和Workqueue, Informer或SharedInformer负责监听Kubernetes中资源对象的状态变化并缓存资源, 同时将状态变化事件(create, update, delete)通过ResourceEventHandler发送到Workqueue中, 然后由控制器中的Worker从Workqueue中取出事件交由具体的处理逻辑进行处理.
Informer 控制器监控资源状态需要向apiserver发送查询请求以获取相应资源全部对象的详细信息, 大量控制器对apiserver的频繁请求会对apiserver产生较大压力, 因此控制器普遍采用本地cache缓存机制实现对资源的监听和同步缓存, 具体流程如下:
Reflector反射器通过Liste/Watche机制获取监听资源的变化, 然后将变化的资源对象添加到Delta FIFO队列 Informer通知器从Delta FIFO队列中取出变化的对象, 将其传递到Indexer索引器 Index索引器为资源对象构建索引, 然后将资源数据存储到线程安全的Key-Value本地存储 当同一种资源被多个控制器监听时, 可以通过SharedInformer进行统一监听和缓存, 以节省监听和缓存开销.
Workqueue 控制器除了监听资源变化并缓存资源对象到本地之外, 还需要针对资源变化作出响应. 被监听资源对象的变化以事件的方式被存储到Workqueue工作队列中等待被处理, 事件是动作(create, update, delete)和资源对象key的组合. 具体流程如下:
Informer通知器将变化的资源传递到Indexer索引器的同时, 还会通过ResourceEventHandler资源事件处理函数将事件动作和资源对象key发送到Workqueue工作队列 Worker从Workqueue中取出事件, 根据资源对象key从Key-Value本地存储中获取资源对象详细数据, 然后根据事件中的动作决定对该资源对象具体的处理逻辑 Worker将处理结果通过Client客户端调用APIServer写入Kubernetes. 控制器的所有功能组件中, Informer(包含Lister/Watcher, Reflector, Local Store),Workqueue和Client都是Kubernetes的原生SDKclient-go默认提供的, 仅ResourceEventHandler和Worker是需要开发者根据具体需求自行开发实现的.
关于client-go sdk的源码分析可参考charlieroro博客文章.
自定义资源与控制器 除了内置的资源和控制器外, Kubernetes还原生支持自定义资源和控制器以扩展Kubernetes的功能.
自定义资源 自定义资源类型 Kubernetes内置了一种称为CustomResourceDefinition的资源类型, 通过自定义资源定义类型可以直接在Kubernetes中定义新的资源类型. 自定义的资源类型必须属于一个与已有群组不同的新群组, 新群组内可以有任意数量的自定义资源类型, 并且这些资源类型可以与其他群组中的资源类型重名. 自定义资源类型的生命周期和原生资源类型一样由apiserver管理, 二者地位相同, 在API访问, 数据持久化等各种管理方式上也是一样的.
自定义资源是通过CustomResourceDefinition资源清单的方式声明的, 典型的格式如下:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # apps-crd.yaml apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: apps.demo.k8s.io spec: group: demo.k8s.io versions: - name: v1 served: true storage: true scope: Namespaced names: kind: App plural: apps 各字段解释:
apiVersion: 固定字段, 表示CustomResourceDefinition这一内建资源所在的群组及当前使用的api版本 kind: 固定字段，表示是在声明自定义资源类型 metadata.name: 自定义资源类型的全名，它由spec.group和spec.names.plural字段组合而成 spec.group: 自定义资源类型所在群组 spec.scope: 表示自定义资源对象的作用范围，Namespaced或Cluster. 自定义资源类型本身是Cluster的. spec.versions[].name: 自定义资源类型的群组版本 spec.versions[].served: 自定义资源类型的该群组版本是否启用, 多个版本可以同时启用 spec.versions[].storage: 自定义资源类型的该群组版本是否持久化到etcd(即存储版本), 仅一个版本可持久化 spec.names.kind: 自定义资源的类型，惯例首字母大写 spec.names.plural: 其值通常为kind的全小写复数，关系到自定义资源在REST API中的HTTP路径 spec.names中还有许多其他字段, 不指定则会由API Server在创建自定义资源类型时自动填充.
spec.versions字段可以指定资源的多个版本, 在每个版本中可以通过OpenAPI V3规范定义schema, 在schema中可以指定该资源类型的具体字段结构和描述信息. 但这不是强制的.
自定义资源类型声明完成后就可以通过kubectl create -f apps-crd.yaml或kubectl apply -f apps-crd.yaml命令进行创建了, 创建完成后可通过kubectl get crd apps.demo.k8s.io -o yaml命令进行查看.
自定义资源类型创建完成后, 其REST API的HTTP访问路径为/apis/apiextensions.k8s.io/v1beta1/customresourcedefinitions/apps.demo.k8s.io.
可以通过kubectl的proxy命令开启本机到api server的反向代理(kubeconfig需要事先配置好), 方便测试.
1 2 kubectl proxy --port 1111 curl http://127.0.0.1:1111/apis/apiextensions.k8s.io/v1beta1/customresourcedefinitions/apps.demo.k8s.io 自定义资源对象 自定义资源类型定义时只需要提供资源类型的元数据信息, 并不需要对资源的具体结构作出强制定义(当然也可以通过schema字段进行指定), 创建自定义资源的对象时可以随意指定其具体结构, 如:
1 2 3 4 5 6 7 8 9 10 11 # app.yaml apiVersion: demo.k8s.io/v1 kind: App metadata: name: test namespace: default spec: deploymentName: "webserver" appName: "nginx" replicas: 1 image: "nginx:latest" 自定义资源spec下的字段只有在被特定控制器或应用按照约定的规范读取解析和处理后才具有实际意义.
自定义资源声明完成后就可以通过kubectl create -f app.yaml或kubectl apply -f app.yaml命令进行创建了, 创建完成后可通过kubectl get apps.demo.k8s.io -o yaml命令进行查看.
自定义资源创建完成后, 其REST API的HTTP访问路径为/apis/demo.k8s.io/v1/namespaces/default/apps/test(以default命名空间为例).
自定义控制器 自定义控制器与内置控制器的工作机制相同, 都可以通过对Kubernetes资源的监听并进行特定的逻辑处理完成对定制化需求的实现. 自定义控制器既能监听原生资源类型也能监听自定义资源类型. 与内置控制器不同的是, 自定义控制器通常是以单独容器的形式运行的. 自定义控制器能够极大丰富Kubernetes的功能特性.
自定义资源与控制器的组合可以认为是一种Kubernetes应用, 由于CoreOS推出的流行的Kubernetes应用开发框架的名称为Operator Framework, 因此自定义资源与控制器又被称为Operator. 自定义资源的声明和生命周期是由Kubernetes apiserver直接管理的, 因此Operator的开发实际上是自定义控制器的开发.
自定义控制器的开发主要包含以下内容:
初始化项目结构 定义自定义资源 编写自定义资源相关API 初始化自定义控制器 注册自定义资源 编写自定义控制器业务逻辑代码 其中只有自定义资源定义和自定义控制器逻辑代码是需要针对具体需求进行开发的(前者只是为了供后者调用).
自定义资源相关API通常是根据自定义资源定义和相关tag由Kubernetes官方提供的code-generator自动生成的, code-generator能够提供自定义资源的deepcopy, clientset, informer和lister的代码的自动生成.
项目结构, 自定义控制器初始化和自定义资源注册由于是比较通用的结构和代码, 因此通常由一些脚手架工具自动生成. 典型的脚手架是CoreOS的Operator Framwork和Kubernetes兴趣小组的Kubebuilder. 当然这些脚手架工具还提供一些诸如自定义资源生命周期管理, Webhook集成等其他功能.
接下来我们会以手动构建, 脚手架和rancher server集成三种方式一步步介绍自定义资源和控制器的开发.
自定义资源与控制器开发 由于Kubernetes对自定义资源与控制器的支持是构建于CustomResourceDefinition的基础上的, 因此自定义资源与控制器开发除了可以称为Operator开发外, 还可被称为CRD开发, 后者更为官方.
CRD开发方式有很多, 但其核心原理是相同的, 本文将以手动构建, 脚手架和rancher server集成三种方式一步步介绍Kubernetes的CRD开发. 所有的开发方式都是基于golang的, 并且启用了module特性.
手动构建方式CRD开发 以手动构建的方式开发CRD虽然比较繁琐, 但相比其他方式能够更加直观深入地帮助我们理解CRD的项目结构和实现机制, 熟悉这些基本原理后在使用其他方式开发能够更加得心应手游刃有余.
手动构建方式开发CRD的基本原理和实现步骤与上文中关于控制器和自定义控制器的介绍基本上是一致的, 不再赘述.
假设我们需要自定义一个名为App的资源并为其开发自定义控制器, 该CRD的功能是根据自定义资源对象中指定的工作负载名, 镜像和副本数, 自动在Kubernetes集群中创建Deployment工作负载并维持该工作负载的副本数为期望状态. 以下是具体的开发过程.
初始化go module 由于是基于go module的项目, 因此需要在项目根目录下进行初始化:
1 go mod init github.com/xshrim/democrd # 项目根目录下执行, 初始化module名github.com/xshrim/democrd可随意指定 初始化后会自动在项目根目录下生成go.mod和go.sum文件, 其中go.mod文件首行为module github.com/xshrim/democrd, 后续项目根目录下的所有包的导入路径都需要以github.com/xshrim/democrd为前缀.
初始化项目结构 项目结构并不是强制约束, 不同脚手架生成的结构也不尽相同, 假设当前开发的CRD的自定义资源组名为demo.k8s.io, 版本为v1, 自定义资源名为App, 这里我们提供一种比较典型的结构:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 sample # 项目根目录 ├── main.go # 程序入口 ├── main_test.go # 代码功能测试 ├── controller.go # 自定义控制器业务逻辑 ├── Makefile # make配置文件 ├── Dockerfile # docker镜像构建文件 ├── deployment.yaml # 自定义控制器部署文件 ├── go.mod # go module文件 ├── go.sum # go module校验文件 ├── hack # 自动代码生成工具目录 │ ├── boilerplate.go.txt # 自动生成代码文件头内容 │ ├── tools.go # code-generator库引入 │ └── update-codegen.sh # 自动生成代码执行脚本 ├── manifest # 资源清单目录 │ ├── crd.yaml # 自定义资源类型声明文件 │ └── app.yaml # 自定义资源对象创建文件 └── pkg # 自定义资源代码目录 ├── signals # 自定义控制器优雅中断代码目录 | ├── signal.go # 中断信号Handler | ├── signal_posix.go # unix与类unix中断信号实现 | └── signal_windows.go # windows中断信号实现 └── apis # 自定义资源API代码目录 └── demo # 自定义资源组目录 ├── register.go # 自定义资源组元数据文件 └── v1 # 自定义资源版本目录 ├── doc.go # 自定义资源描述文件 ├── types.go # 自定义资源定义 └── register.go # 自定义资源注册文件 此项目结构中manifest/foo.yaml文件名需要自行指定(建议为自定义资源名), pkg/apis/demo目录名需要自行指定(建议为自定义资源组名), 其他目录和文件名均可以是固定的.
信号Handler编写 默认情况下当应用程序收到终止/中断信号后, 操作系统会根据信号的类型决定如何让应用退出. 在应用中加入信号Handler的作用是让应用捕获到信号并完成一些善后工作后再优雅退出. 信号Handler并不是必须的. 我们将信号handler相关代码放置在pkg/signals目录下.
signal.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package signals import ( "os" "os/signal" ) var onlyOneSignalHandler = make(chan struct{}) // 监听SIGTERM终止和SIGINT中断信号并返回一个channel, 第一次发送这些信号将关闭channel, 第二次将直接退出 func SetupSignalHandler() (stopCh &lt;-chan struct{}) { close(onlyOneSignalHandler) // panics when called twice stop := make(chan struct{}) c := make(chan os.Signal, 2) signal.Notify(c, shutdownSignals...) go func() { &lt;-c close(stop) &lt;-c os.Exit(1) // 第二次街道终止或中断信号, 直接退出 }() return stop } signal_posix.go 1 2 3 4 5 6 7 8 9 10 // +build !windows package signals import ( "os" "syscall" ) var shutdownSignals = []os.Signal{os.Interrupt, syscall.SIGTERM} signal_windows.go 1 2 3 4 5 6 7 package signals import ( "os" ) var shutdownSignals = []os.Signal{os.Interrupt} API代码编写 依照上述项目结构创建pkg/apis目录下的相关目录和文件, 其中demo目录建议为自定义资源组名或组名的第一个字段. 各文件内容如下:
register.go 1 2 3 4 5 6 package demo const ( GroupName = "demo.k8s.io" Version = "v1" ) v1/doc.go 1 2 3 // +k8s:deepcopy-gen=package // +groupName=demo.k8s.io package v1 此文件中的两条注释是自动生成代码必须的.
v1/types.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package v1 import ( metav1 "k8s.io/apimachinery/pkg/apis/meta/v1" ) // +genclient // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object type App struct { metav1.TypeMeta `json:",inline"` metav1.ObjectMeta `json:"metadata,omitempty"` Spec AppSpec `json:"spec"` Status AppStatus `json:"status"` } type AppSpec struct { DeploymentName string `json:"deploymentName"` // 工作负载名 AppName string `json:"appName"` // 应用名 Replicas int32 `json:"replicas"` // 工作负载副本数 Image string `json:"image"` // 应用镜像 } type AppStatus struct { AvailableReplicas int32 `json:"availableReplicas"` } // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object type AppList struct { metav1.TypeMeta `json:",inline"` metav1.ListMeta `json:"metadata"` Items []App `json:"items"` } 自定义资源定义就是在此文件中完成的. 这里我们定义了一个名为App的自定义资源及其结构, 其中App结构体中的metav1.TypeMeta和metav1.ObjectMeta组合表示该自定义资源自动拥有Kubernetes资源类型的标准元数据字段. Spec字段名为Kubernetes资源类型的标准字段名, 但其值为为该自定义资源的特定数据结构. AppList为该自定义资源的数组结构.
此文件中的注释也是自动生成代码所需的.
v1/register.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package v1 import ( "github.com/xshrim/democrd/pkg/apis/demo" metav1 "k8s.io/apimachinery/pkg/apis/meta/v1" "k8s.io/apimachinery/pkg/runtime" "k8s.io/apimachinery/pkg/runtime/schema" ) var SchemeGroupVersion = schema.GroupVersion{ Group: demo.GroupName, Version: demo.Version, } var ( SchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes) AddToScheme = SchemeBuilder.AddToScheme ) func Resource(resource string) schema.GroupResource { return SchemeGroupVersion.WithResource(resource).GroupResource() } func Kind(kind string) schema.GroupKind { return SchemeGroupVersion.WithKind(kind).GroupKind() } func addKnownTypes(scheme *runtime.Scheme) error { scheme.AddKnownTypes( SchemeGroupVersion, &amp;App{}, &amp;AppList{}, ) metav1.AddToGroupVersion(scheme, SchemeGroupVersion) return nil } 此文件实现自定义资源的注册, 后续自动生成的API代码中的client代码会调用AddToScheme, Resource和Kind方法注册自定义资源, 实现GVK与Go types的相互映射. 如果缺失这些方法会导致编译失败.
此段代码中大部分内容都是固定的, 仅addKnownTypes函数中需要添加自定义资源类型到Scheme.
API代码自动生成 完成上述API代码的编写后, 就可以使用Kubernetes的code-generator自动生成API相关的接口和方法. 该功能由hack目录下的代码完成.
boilerplate.go.txt 此文件中定义了自动生成的文件的文件头, 其中主要包括License和功能说明等
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /* Copyright The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ tools.go 此文件没有仅用于导入code-generator库到项目中, 文件中的// +build tools表示库导入后执行build操作, code-generator build后会在$GOPATH/bin目录下生成以下二进制文件, 这些二进制文件负责具体的代码的生成:
deepcopy-gen: 为自定义资源生成深度拷贝方法以避免性能开销 client-gen: 为自定义资源生成标准的操作方法(get,list,create,update,patch,delete,deleteCollection,watch) informer-gen: 为自定义资源生成informer以提供list/watch机制来监听相应kubernetes的event lister-gen: 为get和list方法提供只读缓存层 1 2 3 4 5 6 // +build tools // 导入code-generator库 package tools import _ "k8s.io/code-generator" update-codegen.sh 自动代码生成与更新的执行脚本.
1 2 3 4 5 6 7 8 9 10 11 12 13 #!/usr/bin/env bash set -o errexit set -o nounset set -o pipefail bash ../vendor/k8s.io/code-generator/generate-groups.sh \ "deepcopy,client,informer,lister" \ ../pkg/generated \ ../pkg/apis \ demo:v1 \ --go-header-file $(pwd)/boilerplate.go.txt \ --output-base $(pwd)/ 脚本的主要工作是调用code-generator的generate-groups.sh脚本, 其语法为: generate-groups.sh &lt;generators> &lt;output-package> &lt;apis-package> &lt;groups-versions> ....
脚本含义是为pkg/apis下的demo组的v1版自定义资源生成deepcopy, client, informer和lister代码, 生成的代码保存在$pwd目录下的pkg/generated目录下.
代码中唯一需要注意的是demo:v1需要与项目结构中的组名和版本匹配. 其他内容保持默认即可.
update-codegen.sh脚本中使用的generate-groups.sh脚本的路径是当前项目的vendor目录下, 因此需要先使用go mod vendor命令将code-generator库添加到项目下. 我们将导入库和生成代码的操作添加到Makefile中. (后续还可以将docker镜像构建已经自定义资源和控制器部署操作也添加到Makefile中)
1 2 3 4 5 vendor: go mod vendor go mod tidy gen: vendor cd hack &amp;&amp; bash update-codegen.sh 随后执行make gen命令即可自动生成自定义资源API相关代码. 生成后的项目结构如下:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 sample ├── main.go ├── main_test.go ├── controller.go ├── Makefile ├── Dockerfile ├── deployment.yaml ├── go.mod ├── go.sum ├── hack │ ├── boilerplate.go.txt │ ├── tools.go │ └── update-codegen.sh ├── manifest │ ├── crd.yaml │ └── foo.yaml ├── pkg | ├── signals | | ├── signal.go | | ├── signal_posix.go | | └── signal_windows.go │ ├── apis │ │ └── demo │ │ ├── register.go │ │ └── v1 │ │ ├── doc.go │ │ ├── register.go │ │ ├── types.go │ │ └── zz_generated.deepcopy.go # 自定义资源的deepcopy方法 │ └── generated # 自定义资源的client, informer, lister相关接口和方法 │ ├── clientset │ │ └── versioned │ │ ├── clientset.go │ │ ├── doc.go │ │ ├── fake │ │ │ ├── clientset_generated.go │ │ │ ├── doc.go │ │ │ └── register.go │ │ ├── scheme │ │ │ ├── doc.go │ │ │ └── register.go │ │ └── typed │ │ └── demo │ │ └── v1 │ │ ├── app.go │ │ ├── demo_client.go │ │ ├── doc.go │ │ ├── fake │ │ │ ├── doc.go │ │ │ ├── fake_app.go │ │ │ └── fake_demo_client.go │ │ └── generated_expansion.go │ ├── informers │ │ └── externalversions │ │ ├── demo │ │ │ ├── interface.go │ │ │ └── v1 │ │ │ ├── app.go │ │ │ └── interface.go │ │ ├── factory.go │ │ ├── generic.go │ │ └── internalinterfaces │ │ └── factory_interfaces.go │ └── listers │ └── demo │ └── v1 │ ├── app.go │ └── expansion_generated.go └── vendor # 导入依赖包, 具体内容忽略 自定义资源对象部署 为了方便进行后续的CRD开发测试, 我们可以先将自定义资源的类型声明和对象创建清单文件应用到Kubernetes集群中, 清单文件格式规范在上文自定义资源部分已有介绍. 清单文件放置于manifest目录下.
crd.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: apps.demo.k8s.io spec: group: demo.k8s.io versions: - name: v1 served: true storage: true scope: Namespaced names: kind: App plural: apps app.yaml 1 2 3 4 5 6 7 8 9 10 apiVersion: demo.k8s.io/v1 kind: App metadata: name: test namespace: default spec: deploymentName: "webserver" appName: "nginx" replicas: 1 image: "nginx:latest" 使用kubectl apply -f manifest/crd.yaml manifest/app.yaml命令将自定义资源类型和对象应用到集群中. 也可以添加到Makefile文件中:
1 2 crd: kubectl apply -f manifest/crd.yaml manifest/app.yaml 自动生成代码测试 自定义资源API相关代码生成后, 可以在main_test.go文件中编写测试用例对自动生成的代码进行功能测试.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( "github.com/xshrim/democrd/pkg/generated/clientset/versioned" "github.com/xshrim/democrd/pkg/generated/clientset/versioned/typed/demo/v1" "github.com/xshrim/democrd/pkg/generated/informers/externalversions" "fmt" metav1 "k8s.io/apimachinery/pkg/apis/meta/v1" "k8s.io/client-go/tools/clientcmd" "testing" "time" ) func TestClient(t *testing.T) { config, e := clientcmd.BuildConfigFromFlags() if e != nil { panic(e.Error()) } //注意,这里使用的是v1这个包 client, e := v1.NewForConfig(config) if e != nil { panic(e.Error()) } appList, e := client.Apps("default").List(metav1.ListOptions{}) fmt.Println(appList, e) //注意 这里的versioned包 clientset, e := versioned.NewForConfig(config) factory := externalversions.NewSharedInformerFactory(clientset, 30*time.Second) app, e := factory.Demo().V1().Apps().Lister().Apps("default").Get("test") if e != nil { panic(e.Error()) } fmt.Println(app, e) } 此测试代码要求:
本地已经配置好Kubernetes集群连接配置文件 自定义资源类型声明已经应用到集群中 在集群的default命名空间下已经创建名为test的自定义资源对象 自定义控制器编写 完成自定义资源的定义和API自动生成后, 开始编写针对该资源的自定义控制器实现业务逻辑.
如上文所述, 对于自定义控制器我们只需要开发Event Handler和Worker处理逻辑即可. 以下为示例代码:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 package main import ( "context" "fmt" "time" appsv1 "k8s.io/api/apps/v1" corev1 "k8s.io/api/core/v1" "k8s.io/apimachinery/pkg/api/errors" metav1 "k8s.io/apimachinery/pkg/apis/meta/v1" utilruntime "k8s.io/apimachinery/pkg/util/runtime" "k8s.io/apimachinery/pkg/util/wait" appsinformers "k8s.io/client-go/informers/apps/v1" "k8s.io/client-go/kubernetes" "k8s.io/client-go/kubernetes/scheme" typedcorev1 "k8s.io/client-go/kubernetes/typed/core/v1" appslisters "k8s.io/client-go/listers/apps/v1" "k8s.io/client-go/tools/cache" "k8s.io/client-go/tools/record" "k8s.io/client-go/util/workqueue" "k8s.io/klog/v2" demov1 "github.com/xshrim/democrd/pkg/apis/demo/v1" clientset "github.com/xshrim/democrd/pkg/generated/clientset/versioned" demoscheme "github.com/xshrim/democrd/pkg/generated/clientset/versioned/scheme" informers "github.com/xshrim/democrd/pkg/generated/informers/externalversions/demo/v1" listers "github.com/xshrim/democrd/pkg/generated/listers/demo/v1" ) const controllerAgentName = "demo-controller" const ( SuccessSynced = "Synced" ErrResourceExists = "ErrResourceExists" MessageResourceExists = "Resource %q already exists and is not managed by App" MessageResourceSynced = "App synced successfully" ) // App自定义资源的自定义控制器实现 type Controller struct { // kubeclientset是标准kubernetes客户端 kubeclientset kubernetes.Interface // democlientset是自定义资源的客户端 democlientset clientset.Interface deploymentsLister appslisters.DeploymentLister deploymentsSynced cache.InformerSynced appsLister listers.AppLister appsSynced cache.InformerSynced // workqueue是一个限速工作队列, 当资源发生变化时, 将事件加入队列而不是立刻处理, 这可以保证事件以固定的速率被处理且每个事件只会被一个worker处理. workqueue workqueue.RateLimitingInterface // recorder是一个将事件资源记录到api的事件记录器 recorder record.EventRecorder } // NewController返回一个新的自定义资源控制器 func NewController( kubeclientset kubernetes.Interface, democlientset clientset.Interface, deploymentInformer appsinformers.DeploymentInformer, appInformer informers.AppInformer) *Controller { // 创建事件广播器并将demo组类型加入Kubernetes Scheme中以便事件资源对象可以被记录为该类型 utilruntime.Must(demoscheme.AddToScheme(scheme.Scheme)) klog.V(4).Info("Creating event broadcaster") eventBroadcaster := record.NewBroadcaster() eventBroadcaster.StartStructuredLogging(0) eventBroadcaster.StartRecordingToSink(&amp;typedcorev1.EventSinkImpl{Interface: kubeclientset.CoreV1().Events("")}) recorder := eventBroadcaster.NewRecorder(scheme.Scheme, corev1.EventSource{Component: controllerAgentName}) controller := &amp;Controller{ kubeclientset: kubeclientset, democlientset: democlientset, deploymentsLister: deploymentInformer.Lister(), deploymentsSynced: deploymentInformer.Informer().HasSynced, appsLister: appInformer.Lister(), appsSynced: appInformer.Informer().HasSynced, workqueue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), "Apps"), recorder: recorder, } klog.Info("Setting up event handlers") // 设置App资源对象发生变化时的事件处理函数 appInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: controller.enqueueApp, UpdateFunc: func(old, new interface{}) { controller.enqueueApp(new) }, }) // 设置当App资源对象创建的Deployment资源对象发生变化是的事件处理函数 deploymentInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: controller.handleObject, UpdateFunc: func(old, new interface{}) { newDepl := new.(*appsv1.Deployment) oldDepl := old.(*appsv1.Deployment) if newDepl.ResourceVersion == oldDepl.ResourceVersion { return } controller.handleObject(new) }, DeleteFunc: controller.handleObject, }) return controller } // Run函数为控制器关注的资源类型设置事件处理函数, 同步informer缓存并启动worker, 此函数会阻塞直到stopCh被关闭, 此时workqueue将被关闭, 程序将等待所有worker完成当前事件的处理 func (c *Controller) Run(threadiness int, stopCh &lt;-chan struct{}) error { defer utilruntime.HandleCrash() defer c.workqueue.ShutDown() klog.Info("Starting App controller") // 启动worker前等待本地缓存完成同步 klog.Info("Waiting for informer caches to sync") if ok := cache.WaitForCacheSync(stopCh, c.deploymentsSynced, c.appsSynced); !ok { return fmt.Errorf("failed to wait for caches to sync") } klog.Info("Starting workers") // 启动若干worker处理workqueue中的事件 for i := 0; i &lt; threadiness; i++ { go wait.Until(c.runWorker, time.Second, stopCh) } klog.Info("Started workers") &lt;-stopCh klog.Info("Shutting down workers") return nil } // runWorker将持续消费workqueue中的事件 func (c *Controller) runWorker() { for c.processNextWorkItem() { } } // processNextWorkItem 将读取workqueue中的一个事件并调用syncHandler处理该事件 func (c *Controller) processNextWorkItem() bool { obj, shutdown := c.workqueue.Get() if shutdown { return false } // 将这段代码块封装为函数以便使用defer c.workqueue.Done err := func(obj interface{}) error { // 当workqueue中的某个事件被处理后, 需要调用Done函数告知workqueue事件已被处理, 此外如果不希望该事件再次进入workqueue, 还需要调用Forget函数 defer c.workqueue.Done(obj) var key string var ok bool // key是namespace/name的格式 if key, ok = obj.(string); !ok { c.workqueue.Forget(obj) utilruntime.HandleError(fmt.Errorf("expected string in workqueue but got %#v", obj)) return nil } // 调用syncHandler函数处理指定的资源对象 if err := c.syncHandler(key); err != nil { // 如果处理过程中发生错误, 将该资源再次入队 c.workqueue.AddRateLimited(key) return fmt.Errorf("error syncing '%s': %s, requeuing", key, err.Error()) } c.workqueue.Forget(obj) klog.Infof("Successfully synced '%s'", key) return nil }(obj) if err != nil { utilruntime.HandleError(err) return true } return true } // syncHandler函数比较资源对象的期望状态和实际状态并尝试统一二者, 然后更新资源对象的Status字段 func (c *Controller) syncHandler(key string) error { // 将namespace/name格式字符串转换为独立的namespace和name namespace, name, err := cache.SplitMetaNamespaceKey(key) if err != nil { utilruntime.HandleError(fmt.Errorf("invalid resource key: %s", key)) return nil } // 获取对应资源对象 app, err := c.appsLister.Apps(namespace).Get(name) if err != nil { // 资源对象不存在, 停止处理 if errors.IsNotFound(err) { utilruntime.HandleError(fmt.Errorf("app '%s' in work queue no longer exists", key)) return nil } return err } deploymentName := app.Spec.DeploymentName if deploymentName == "" { utilruntime.HandleError(fmt.Errorf("%s: deployment name must be specified", key)) return nil } appName := app.Spec.AppName if appName == "" { utilruntime.HandleError(fmt.Errorf("%s: app name must be specified", key)) return nil } image := app.Spec.Image if image == "" { utilruntime.HandleError(fmt.Errorf("%s: image must be specified", key)) return nil } // 获取App资源对象中指定的Deployment资源 deployment, err := c.deploymentsLister.Deployments(app.Namespace).Get(deploymentName) // 资源不存在则创建 if errors.IsNotFound(err) { deployment, err = c.kubeclientset.AppsV1().Deployments(app.Namespace).Create(context.TODO(), newDeployment(app), metav1.CreateOptions{}) } // 当获取或创建资源对象出错时, 返回错误, 该资源对象会重新入队, 后续还再次被处理 if err != nil { return err } if !metav1.IsControlledBy(deployment, app) { msg := fmt.Sprintf(MessageResourceExists, deployment.Name) c.recorder.Event(app, corev1.EventTypeWarning, ErrResourceExists, msg) return fmt.Errorf(msg) } // 资源对象的副本数与期望不符, 调用Update自动调整为期望状态 if app.Spec.Replicas != *deployment.Spec.Replicas { klog.V(4).Infof("App %s replicas: %d, deployment replicas: %d", name, app.Spec.Replicas, *deployment.Spec.Replicas) deployment, err = c.kubeclientset.AppsV1().Deployments(app.Namespace).Update(context.TODO(), newDeployment(app), metav1.UpdateOptions{}) } // 当更新资源对象出错时, 返回错误, 该资源对象会重新入队, 后续还再次被处理 if err != nil { return err } // 更新资源对象Status字段 err = c.updateAppStatus(app, deployment) if err != nil { return err } c.recorder.Event(app, corev1.EventTypeNormal, SuccessSynced, MessageResourceSynced) return nil } func (c *Controller) updateAppStatus(app *demov1.App, deployment *appsv1.Deployment) error { // 不要试图从store中修改对象, 因为store作为本地缓存, 是只读的, 可以通过DeepCopy方法深度复制对象后再修改 appCopy := app.DeepCopy() appCopy.Status.AvailableReplicas = deployment.Status.AvailableReplicas _, err := c.democlientset.SamplecontrollerV1alpha1().Apps(app.Namespace).Update(context.TODO(), appCopy, metav1.UpdateOptions{}) return err } // 将App资源对象转换为namespace/name字符串并入队到workqueue func (c *Controller) enqueueApp(obj interface{}) { var key string var err error if key, err = cache.MetaNamespaceKeyFunc(obj); err != nil { utilruntime.HandleError(err) return } c.workqueue.Add(key) } //handleObject根据资源对象的metadata.ownerReferences字段获取拥有该资源对象的App资源对象, 并调用enqueueApp将该App资源对象入队 func (c *Controller) handleObject(obj interface{}) { var object metav1.Object var ok bool if object, ok = obj.(metav1.Object); !ok { tombstone, ok := obj.(cache.DeletedFinalStateUnknown) if !ok { utilruntime.HandleError(fmt.Errorf("error decoding object, invalid type")) return } object, ok = tombstone.Obj.(metav1.Object) if !ok { utilruntime.HandleError(fmt.Errorf("error decoding object tombstone, invalid type")) return } klog.V(4).Infof("Recovered deleted object '%s' from tombstone", object.GetName()) } klog.V(4).Infof("Processing object: %s", object.GetName()) if ownerRef := metav1.GetControllerOf(object); ownerRef != nil { // 只处理由App资源对象创建的Deployment资源对象 if ownerRef.Kind != "App" { return } app, err := c.appsLister.Apps(object.GetNamespace()).Get(ownerRef.Name) if err != nil { klog.V(4).Infof("ignoring orphaned object '%s' of app '%s'", object.GetSelfLink(), ownerRef.Name) return } c.enqueueApp(app) return } } // newDeployment为App资源对象创建一个新的Deployment资源对象并将拥有者设置为App资源对象 func newDeployment(app *demov1.App) *appsv1.Deployment { labels := map[string]string{ "app": app.Spec.AppName, "controller": app.Name, } return &amp;appsv1.Deployment{ ObjectMeta: metav1.ObjectMeta{ Name: app.Spec.DeploymentName, Namespace: app.Namespace, OwnerReferences: []metav1.OwnerReference{ *metav1.NewControllerRef(app, demov1.SchemeGroupVersion.WithKind("App")), }, }, Spec: appsv1.DeploymentSpec{ Replicas: &amp;app.Spec.Replicas, Selector: &amp;metav1.LabelSelector{ MatchLabels: labels, }, Template: corev1.PodTemplateSpec{ ObjectMeta: metav1.ObjectMeta{ Labels: labels, }, Spec: corev1.PodSpec{ Containers: []corev1.Container{ { Name: app.Spec.AppName, Image: app.Spec.Image, }, }, }, }, }, } } 以上自定义控制器代码完成的工作有:
创建自定义控制器结构体Controller, 由于我们开发的crd除了关注自定义的App资源, 还要涉及Deployment资源, 因此结构体中除了包含自定义资源的client外, 还加入了kubernetes的标准client. 此外该结构体中还包括了自定义资源和Deployment资源的Lister, workqueue和事件记录器 通过NewController生成自定义控制器实例, 同时通过AddEventHandler函数完成了对自定义的App资源和Deployment资源的事件处理器的添加, 其中App资源的Event Handler有AddFunc和UpdateFunc, 而Deployment资源的Event Handler有AddFunc, UpdateFunc和DeleteFunc, 各处理器均实现了相应的Handler函数. 这些Handler函数负责在必要时将监听到的事件发送到workqueue中. 在Run函数中启动了几个Worker协程, worker协程消费workqueue中的事件, 交由syncHandler处理, syncHandler通过对比App资源对象中指定的Deployment资源对象的期望状态和Kubernetes集群中实际的Deployment资源对象的状态, 决定如何处理以维持期望状态. main函数编写 自定义控制器最终是以独立的应用程序运行的, 自定义资源API和控制器代码编写完成后, 就需要编写程序入口函数了.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package main import ( "flag" "time" kubeinformers "k8s.io/client-go/informers" "k8s.io/client-go/kubernetes" "k8s.io/client-go/tools/clientcmd" "k8s.io/klog/v2" clientset "ithub.com/xshrim/democrd/pkg/generated/clientset/versioned" informers "ithub.com/xshrim/democrd/pkg/generated/informers/externalversions" "k8s.io/sample-controller/pkg/signals" ) var ( masterURL string kubeconfig string ) func main() { klog.InitFlags(nil) flag.Parse() // 启动信号处理器以便优雅响应第一次终止或中断信号 stopCh := signals.SetupSignalHandler() cfg, err := clientcmd.BuildConfigFromFlags(masterURL, kubeconfig) if err != nil { klog.Fatalf("Error building kubeconfig: %s", err.Error()) } kubeClient, err := kubernetes.NewForConfig(cfg) if err != nil { klog.Fatalf("Error building kubernetes clientset: %s", err.Error()) } demoClient, err := clientset.NewForConfig(cfg) if err != nil { klog.Fatalf("Error building demo clientset: %s", err.Error()) } kubeInformerFactory := kubeinformers.NewSharedInformerFactory(kubeClient, time.Second*30) demoInformerFactory := informers.NewSharedInformerFactory(demoClient, time.Second*30) controller := NewController(kubeClient, demoClient, kubeInformerFactory.Apps().V1().Deployments(), demoInformerFactory.Demo().V1().Apps()) // Start方法本身是非阻塞的且每个informer均运行在独立的协程中, 因此这里不必开启单独的协程 kubeInformerFactory.Start(stopCh) demoInformerFactory.Start(stopCh) if err = controller.Run(2, stopCh); err != nil { klog.Fatalf("Error running controller: %s", err.Error()) } } func init() { flag.StringVar(&amp;kubeconfig, "kubeconfig", "", "Path to a kubeconfig. Only required if out-of-cluster.") flag.StringVar(&amp;masterURL, "master", "", "The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.") } main函数的主要工作是读取命令行配置参数, 实例化kubernetes标准client, 自定义资源client以及自定义控制器, 最后启动自定义控制器. main函数中的代码基本上都是固定代码.
项目运行与部署 以上内容完成后就可以直接运行项目了, 此外也可以将其打包为docker镜像并部署到Kubernetes集群中. 我们把这些操作也添加到Makefile中.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 vendor: go mod vendor gen: vendor cd hack &amp;&amp; bash update-codegen.sh crd: kubectl apply -f manifest/crd.yaml manifest/app.yaml run: vendor go run -mod vendor . build: vendor CGO_ENABLED=0 GOOS=linux go build -mod vendor -a -o demo-controller . package: vendor docker build -t demo-controller:v1 . deploy: crd kubectl apply -f deployment.yaml Dockerfile 这里使用了docker的多阶段构建特性, 也可以选择先在本地生成二进制文件.
1 2 3 4 5 6 7 8 9 10 FROM golang:alpine as builder WORKDIR /root/ COPY ./ ./ RUN CGO_ENABLED=0 GOOS=linux go build -mod vendor -a -o demo-controller . FROM alpine:latest LABEL maintainer="xshrim@yeah.net" WORKDIR /root/ COPY --from=builder /root/demo-controller . CMD ["./demo-controller"] deployment.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 apiVersion: apps/v1 kind: Deployment metadata: labels: app: demo-controller name: demo-controller namespace: default spec: replicas: 1 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 25% maxSurge: 1 selector: matchLabels: app: demo-controller template: metadata: labels: app: demo-controller spec: containers: - image: demo-controller:v1 name: demo-controller resources: limits: cpu: "1000m" memory: "1024Mi" 其他 tag 在上述部分代码中存在一些特殊的注释, 如// +k8s:deepcopy-gen=package, // +groupName=demo.k8s.io等, 这些是code-generator的tag, 这些tag用于告诉code-generator如何自动生成代码.
code-generator tag的语法为:
1 2 3 // +tagname or // +tagname=value code-generator tag分为两类:
全局tags: 全局的tag, 放在具体版本的doc.go文件中
+groupName=xxxx定义api组名称
+k8s:deepcopy-gen=package: 为包中的每一个类型自动创建deepcopy方法
+k8s:deepcopy-gen=false: 关闭自动创建deepcopy方法
+k8s:deepcopy-gen=true: 放在具体的结构体上为该结构体自动创建deepcopy方法
本地tags: 本地的tag, 放在types.go文件的具体struct上
+k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object: 放在具体的结构体上表示为该结构体生成的deecopy方法需要实现指定的接口
+genclient: 放在具体的结构体上为该资源类型创建clientset, 支持多种参数:
+genclient:nonNamespaced: 集群级资源类型的clientset +genclient:noStatus: 资源类型没有status字段 +genclient:noVerbs: clientset不生成增删改查等方法 +genclient:onlyVerbs=create,delete: clientset只生成指定的方法 +genclient:skipVerbs=get,list,create,update,patch,delete,deleteCollection,watch: clientset不生成指定的方法 +genclient:method=Create,verb=create,result=k8s.io/apimachinery/pkg/apis/meta/v1.Status: clientset生成的方法返回指定类型 脚手架方式CRD开发 从上文介绍手动构建的开发方式不难看出, 即便是使用了code-generator进行部分代码的自动生成, 但过程依然很繁琐, 而且很多代码都是通用代码却只能手动编写. 为此诞生了一些脚手架工具, 在手动构建的基础上对通用代码进行了进一步的封装, 并提供一些额外的功能特性和工具集, 最大化程度低简化CRD的开发.
比较主流的脚手架工具是CoreOS的Operator SDK和Kubernetes兴趣小组的KubeBuilder. 二者实现方式有所不同, 但核心原理大同小异. 我们选择KubeBuilder作为代表进行介绍.
此外, 流行的Kubernetes多集群管理系统Rancher的开发商也开源了一套轻量级的Controller开发框架Wrangler, 该框架是作为Rancher Server中的Norman框架的替代者而开发的, 目前与Norman框架在Rancher Server源代码中并存, Wrangler框架对Rancher Server的自定义资源的开发具有更好的亲和性, 因此也会进行介绍.
KubeBuilder KubeBuilder是在控制器运行时库和控制器工具库的基础上开发的, 它提供了一套强大的库和工具来简化从头开始构建和发布自定义资源和控制器的过程.
框架 KubeBuilder主要包含四大核心组件:
Manager: 负责运行所有的controller, 初始化共享cache并提供list/watch功能, 以及初始化与apiserver通信的client Cache: 负责在Controller进程中根据Scheme同步apiserver中所有该Controller关注的资源对象 Client: 封装了资源读写方法的客户端, 客户端的查询操作是查询的本地Cache, 而写操作是直接访问apiserver Controller: 自定义控制器, 控制器的调谐控制逻辑均在其中实现, KubeBuilder已经自动生成了自定义控制器的通用代码, 开发者只需要实现Reconcile方法即可 Scheme用于提供GVK与Go结构体类型的相互映射关系
Cache是对Reflector, Delta FIFO Queue, Indexer和LocalCache等一系列组件的封装
此外, KubeBuilder还提供了一组增强的功能组件:
Index: 由于Controller经常要对Cache进行查询, KubeBuilder提供Index utility给Cache添加索引提升查询效率 OwnerReference: Kubernetes GC在删除一个对象时, 任何OwnerReference是该对象的对象都会被清除, KubeBuilder支持所有对象的变更都会触发Owner对象controller的Reconcile方法 Finalizer: KubeBuilder支持利用Kuberntes的Finalizer终止器特性获取被删除资源信息, 实现预删除钩子 KubeBuilder框架整体架构如下图所示:
KubeBuilder整体工作流程如下图所示:
KubeBuilder将Scheme, Cache, Client, Workqueue等都封装到单独的controller-runtime库中, 多个自定义资源的Scheme, Cache, Client和Controller由一个Manager统一管理, Manager通过Scheme中的映射关系为自定义资源和该资源的Informer创建了InformersMap, 每一个自定义资源都拥有一个单独的Informer和Controller.
自定义资源的Informer通过Reflector监听API Server并将资源对象写入Delta FIFO Queue, ProcessDelta内部控制器取出资源对象并通过Indexer缓存到Cache的同时, 调用EventHandler发送资源Event(即资源对象的Namespace/Name字符串)到该资源对应的Workqueue, 该资源的Controller负责消费Workqueue中的Event, 将Event交由Reconciler进行处理.
KubeBuilder对自定义控制器进行了更为抽象的封装, 但核心原理还是一样的. 不难看出, 使用KubeBuilder进行CRD开发时, 开发人员需要做的仅仅是自定义资源的定义和controller中Reconcile方法的实现.
开发 与手动构建方式应用, 我们仍然假设当前开发的CRD的自定义资源组名为demo.k8s.io, 版本为v1, 自定义资源名为App.
安装 kubebuilder脚手架工具就是一个golang二进制文件, 此外其各种yaml的构造依赖kustomize.
1 2 3 4 5 6 7 8 9 10 11 os=$(go env GOOS) arch=$(go env GOARCH) # install kubebuilder curl -sL https://go.kubebuilder.io/dl/latest/${os}/${arch} | tar -xz -C /tmp/ mv /tmp/kubebuilder_master_${os}_${arch} /usr/local/share/kubebuilder export PATH=$PATH:/usr/local/share/kubebuilder/bin # install kustomize curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"|bash mv kustomize /usr/local/share/kubebuilder/bin/ 初始化go module 1 go mod init github.com/xshrim/democrd # 项目根目录下执行, 初始化module名github.com/xshrim/democrd可随意指定 初始化项目 1 kubebuilder init --domain k8s.io # 注意初始化项目时指定的domain相当于自定义资源API组的后缀 创建API 1 kubebuilder create api --group demo --version v1 --kind App --controller --resource # 同时创建resource和controller 这一步将生成自定义资源结构体定义和该资源的controller脚手架文件. 执行完成之后项目结构如下:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 sample # 项目根目录 ├── main.go # 程序入口 ├── Makefile # make配置文件 ├── PROJECT # 项目元数据文件 ├── Dockerfile # docker镜像构建文件 ├── go.mod # go module文件 ├── go.sum # go module校验文件 ├── hack # 自动代码生成辅助文件目录 │ └── boilerplate.go.txt # 自动生成代码文件头内容 ├── api # 自定义资源API代码目录 │ └── v1 # 自定义资源版本目录 │ ├── app_types.go # 自定义资源定义 │ ├── groupversion_info.go # 自定义资源描述文件 │ └── zz_generated.deepcopy.go # 自定义资源深度复制代码 ├── bin # 二进制文件保存目录 │ └── manager # 生成的controller可执行文件 ├── config # 可能使用到的yaml文件 │ ├── certmanager # 提供证书管理支持的清单文件目录 │ │ ├── certificate.yaml │ │ ├── kustomization.yaml │ │ └── kustomizeconfig.yaml │ ├── crd # 部署crd的清单文件目录 │ │ ├── kustomization.yaml │ │ ├── kustomizeconfig.yaml │ │ └── patches │ │ ├── cainjection_in_apps.yaml │ │ └── webhook_in_apps.yaml │ ├── default # 默认的清单文件目录 │ │ ├── kustomization.yaml │ │ ├── manager_auth_proxy_patch.yaml │ │ ├── manager_webhook_patch.yaml │ │ └── webhookcainjection_patch.yaml │ ├── manager # 部署controller的清单文件目录 │ │ ├── kustomization.yaml │ │ └── manager.yaml │ ├── prometheus # 部署监控servicemonitor的清单文件目录 │ │ ├── kustomization.yaml │ │ └── monitor.yaml │ ├── rbac # 提供角色访问控制的清单文件目录 │ │ ├── auth_proxy_role_binding.yaml │ │ ├── auth_proxy_role.yaml │ │ ├── auth_proxy_service.yaml │ │ ├── kustomization.yaml │ │ ├── leader_election_role_binding.yaml │ │ ├── leader_election_role.yaml │ │ └── role_binding.yaml │ ├── samples # 自定义资源对象示例清单文件目录 │ │ └── demo_v1_app.yaml │ └── webhook # 提供准入控制的清单文件目录 │ ├── kustomization.yaml │ ├── kustomizeconfig.yaml │ └── service.yaml └── controllers # 自定义控制器目录 ├── app_controller.go # 自定义控制器业务逻辑 └── suite_test.go # 自定义控制器功能测试 编写API定义 自定义资源结构体位于api/v1/app_types.go文件中, 通常我们只需要自定义AppSpec结构体中的内容即可.
1 2 3 4 5 6 7 8 9 10 11 // AppSpec defines the desired state of App type AppSpec struct { // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run "make" to regenerate code after modifying this file // Foo is an example field of App. Edit App_types.go to remove/update DeploymentName string `json:"deploymentName"` // 工作负载名 AppName string `json:"appName"` // 应用名 Replicas int `json:"replicas"` // 工作负载副本数 Image string `json:"image"` // 应用镜像 } 重新生成代码 自定义资源结构体重新定义后, 需要重新生成相关代码, 包括该资源的控制器代码和crd资源清单. 由于KubeBuilder自动生成的Makefile中包含了大量常用操作的配置, 因此后续的操作均可以通过make命令完成.
1 2 make generate # 更新自定义控制器代码 make manifests # 更新crd资源清单(此target包含generate) 编写自定义控制器 KubeBuilder已经自动在controllers/app_controller.go文件中生成了自定义控制器的脚手架代码, 我们只需要实现其中的Reconcile调谐方法即可.
此方法传入的参数就是从Workqueue中获取到的Event(即资源的NamespacedName), 而其所属类型AppReconciler中包含的Client接口所实现的Reader, Writer和StatusClient能够分别完成Cache读, APIServer写和Status字段写操作. 因此在Reconcile方法中能够满足所有的自定义资源管理逻辑.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // AppReconciler reconciles a App object type AppReconciler struct { client.Client Log logr.Logger Scheme *runtime.Scheme } // +kubebuilder:rbac:groups=demo.k8s.io,resources=apps,verbs=get;list;watch;create;update;patch;delete // +kubebuilder:rbac:groups=demo.k8s.io,resources=apps/status,verbs=get;update;patch func (r *AppReconciler) Reconcile(req ctrl.Request) (ctrl.Result, error) { _ = context.Background() _ = r.Log.WithValues("app", req.NamespacedName) // your logic here return ctrl.Result{}, nil } 项目运行与部署 项目测试, 运行和部署操作命令也都在Makefile文件中, 不再赘述.
1 2 3 4 5 6 7 make test # 测试代码 make install # 安装crd资源到Kubernetes集群 make manager # 构建自定义控制器二进制文件 make run # 运行自定义控制器 make deploy # 部署自定义控制器到Kubernetes集群 make generate # 自动生成代码 make docker-build # 构建自定义控制器镜像 其他 其他关于KubeBuilder的更多使用方法参考KubeBuilder官方文档
Wrangler Wrangler框架作为Norman框架的替代者, 相比Norman具有更好的通用性和易用性, 方便实现与Rancher Server自定义控制器的解耦与集成. Wrangler的开发方式偏向于手动构建式开发, 它主要的工作是作了以下三个方面的封装, 从而让控制器业务逻辑的具体开发过程更加便捷:
在Kubernetes原生client-go API的基础上封装并提供了大量的工具函数 对Kubernetes内置的Controller API进一步封装以提供更加简单好用的接口 提供一个基于code-generatord控制器代码生成器用于为自定义资源生成统一风格的自定义Controller接口 目前Wrangler框架提供的方法和自定义Controller在Rancher Server主版本中有大量使用, 为了后续进行Rancher Server集成式自定义控制器的开发, 有必要对Wrangler框架作一些了解.
框架 Wrangler框架是和Rancher开源的另一个更底层的控制器框架Lasso配合使用的(Lasso也是Norman框架的底层), Wrangler框架通过多层级的工厂类型最终生成相应资源的资源Controller(包括原生资源和自定义资源, 原生资源的资源Controller在Wrangler包中已经提供, 也可自行生成), 资源Controller中封装了资源的所有抽象方法和Handler注册方法, 以及其SharedController对象. 开发者只需要完成自定义资源的定义和OnChange, OnRemove事件的Handler即可.
资源Controller的SharedController对象则是由底层的Lasso框架生成的, 该对象主要包含三大组件:
Cache: 包含Informer(Reflector, Delta FIFO Queue), Indexer, LocalCache及其相关接口的完整封装 Client: 资源的读写客户端, 负责读取Cache中的资源对象并向API Server写入资源数据 Controller: 包含控制器的EventHandler, Workqueue, Worker及其相关接口的完整封装 SharedController类型是对Controller的扩展, 一个SharedController中可以注册多个Handler.
在Wrangler框架层, 用户通过调用资源Controller的事件注册函数将Handler传入Lass框架层的资源SharedController对象, 最终传入Controller的Worker处理逻辑中, 控制器的基本架构的所有组件的实现几乎都在Lasso层. 当资源状态发生变化时, Worker会调用从Wrangler层传入的Handler方法完成处理逻辑. 开发者在Handler方法中只需要调用Wrangler层封装的抽象方法(如Create, Delete, Update, Get, Watch, Patch等), 这些抽象方法最终都会调用Lasso层中对应的具体实现.
Wrangler框架的整体架构如下图所示:
开发 与上文示例应用一样, 我们仍然假设当前开发的CRD的自定义资源组名为demo.k8s.io, 版本为v1, 自定义资源名为App.
初始化go module 1 go mod init github.com/xshrim/democrd # 在项目根目录下执行, 初始化module名github.com/xshrim/democrd可随意指定 初始化项目结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sample # 项目根目录 ├── main.go # 程序入口 ├── main_test.go # 代码功能测试 ├── controller.go # 自定义控制器业务逻辑 ├── Makefile # make配置文件 ├── Dockerfile # docker镜像构建文件 ├── deployment.yaml # 自定义控制器部署文件 ├── go.mod # go module文件 ├── go.sum # go module校验文件 ├── hack # 自动代码生成工具目录 │ └── boilerplate.go.txt # 自动生成代码文件头内容 ├── manifest # 资源清单目录 │ ├── crd.yaml # 自定义资源类型声明文件 │ └── app.yaml # 自定义资源对象创建文件 └── pkg # 自定义资源代码目录 ├── codegen # 代码自动生成程序目录 | ├── main.go # 代码自动生成程序入口 | └── cleanup.go # 自动生成代码清理程序目录 | └── main.go # 自动生成代码清理程序入口 └── apis # 自定义资源API代码目录 └── demo.k8s.io # 自定义资源组目录 └── v1 # 自定义资源版本目录 └── types.go # 自定义资源定义 API代码编写 自定义资源结构体位于pkg/apis/demo.k8s.io/v1/types.go文件中, 代码结构与手动构建方式相同, tag也是通用的. 需要注意的是, 这里的资源组目录最好填写组名全名以与后续自动生成的代码包路径保持一致 . 自定义资源结构体对应的List结构体(如AppList)会自动生成, 无需添加.
types.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package v1 import ( metav1 "k8s.io/apimachinery/pkg/apis/meta/v1" ) // +genclient // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object // App is a specification for a App resource type App struct { metav1.TypeMeta `json:",inline"` metav1.ObjectMeta `json:"metadata,omitempty"` Spec AppSpec `json:"spec"` Status AppStatus `json:"status"` } // AppSpec is the spec for a App resource type AppSpec struct { DeploymentName string `json:"deploymentName"` // 工作负载名 AppName string `json:"appName"` // 应用名 Replicas int32 `json:"replicas"` // 工作负载副本数 Image string `json:"image"` // 应用镜像 } // AppStatus is the status for a App resource type AppStatus struct { AvailableReplicas int32 `json:"availableReplicas"` } 代码自动生成工具编写 代码自动生成工具库是rancher基于code-generator编写的, 自定义资源的注册和API生成都是自动完成的, 我们只需要补全controller-gen的Run方法参数即可. 此外自动生成代码的清理工具代码无需修改.
codegen/main.go
这里需要根据实际项目结构填写OutputPackage, Groups参数, 注意资源的List结构体无需加入Types列表中. 另
外如果自定义控制器中存在对Kubernetes原生资源的操作, 可以将相应资源组也加入列表中生成相应资源的API(core组组名可留空), 但通常这是不必要的, 我们支持导入wrangler框架的包即可, 这里作为演示保留.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( demov1 "github.com/xshrim/democrd/pkg/apis/demo.k8s.io/v1" controllergen "github.com/rancher/wrangler/pkg/controller-gen" "github.com/rancher/wrangler/pkg/controller-gen/args" appsv1 "k8s.io/api/apps/v1" ) func main() { controllergen.Run(args.Options{ OutputPackage: "github.com/xshrim/democrd/pkg/generated", Boilerplate: "hack/boilerplate.go.txt", Groups: map[string]args.Group{ "demo.k8s.io": { Types: []interface{}{ demov1.App{}, }, GenerateTypes: true, }, // Optionally you can use wrangler-api project which // has a lot of common kubernetes APIs already generated. // In this controller we will use wrangler-api for apps api group "apps": { Types: []interface{}{ appsv1.Deployment{}, }, InformersPackage: "k8s.io/client-go/informers", ClientSetPackage: "k8s.io/client-go/kubernetes", ListersPackage: "k8s.io/client-go/listers", }, }, }) } codegen/clean/main.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( "os" "log" "github.com/rancher/wrangler/pkg/cleanup" ) func main() { if err := cleanup.Cleanup("./pkg/apis"); err != nil { log.Fatal(err) } if err := os.RemoveAll("./pkg/generated"); err != nil { log.Fatal(err) } } API代码自动生成 使用命令go run -mod vendor pkg/codegen/main.go即可完成自定义资源API代码的自动生成. 方便起见我们仍然将操作添加到Makefile.
1 2 3 4 5 6 7 8 9 10 vendor: go mod tidy go mod vendor clean: vendor go run -mod vendor pkg/codegen/cleanup/main.go # rm -rf $GOPATH/src/当前module名 generate: clean go run -mod vendor pkg/codegen/main.go 1 make generate 生成后的项目结构如下:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 sample ├── main.go ├── main_test.go ├── controller.go ├── Makefile ├── Dockerfile ├── deployment.yaml ├── go.mod ├── go.sum ├── hack │ └── boilerplate.go.txt ├── manifest │ ├── crd.yaml │ └── app.yaml ├── pkg | ├── codegen | | ├── main.go | | └── cleanup.go | | └── main.go │ ├── apis │ | └── demo.k8s.io │ | ├── v1 | | | ├── doc.go # 自定义资源描述文件 │ | | ├── types.go | | | ├── zz_generated_deepcopy.go # 自定义资源的deepcopy方法 | | | ├── zz_generated_list_types.go # 自定义资源的list类型 | | | └── zz_generated_register.go # 自定义资源注册文件 | | └── zz_generated_register.go # 自定义资源组元数据文件 | └── generated # 自定义资源API相关方法 | └── controllers | ├── apps # kubernetes内置apps组资源API封装 | │ ├── factory.go | │ ├── interface.go | │ └── v1 | │ ├── deployment.go | │ └── interface.go | └── demo.k8s.io # 自定义资源组资源API封装 | ├── factory.go | ├── interface.go | └── v1 | ├── app.go | └── interface.go └── vendor # 导入依赖包, 具体内容忽略 自定义资源对象部署 为了方便进行后续的CRD开发测试, 我们可以先将自定义资源的类型声明和对象创建清单文件应用到Kubernetes集群中, 清单文件格式规范在上文自定义资源部分已有介绍. 清单文件放置于manifest目录下.
crd.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: apps.demo.k8s.io spec: group: demo.k8s.io versions: - name: v1 served: true storage: true scope: Namespaced names: kind: App plural: apps app.yaml 1 2 3 4 5 6 7 8 9 10 apiVersion: demo.k8s.io/v1 kind: App metadata: name: test namespace: default spec: deploymentName: "webserver" appName: "nginx" replicas: 1 image: "nginx:latest" 使用kubectl apply -f manifest/crd.yaml manifest/app.yaml命令将自定义资源类型和对象应用到集群中. 也可以添加到Makefile文件中:
1 2 crd: kubectl apply -f manifest/crd.yaml manifest/app.yaml 自动生成代码测试 自定义控制器编写 完成自定义资源的定义和API自动生成后, 开始编写针对该资源的自定义控制器实现业务逻辑.
如上文所述, 对于自定义控制器我们只需要注册并编写Event Handler即可. Wrangler框架中的Event简化为两种: OnChange和OnRemove. 以下为示例代码:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 package main import ( "context" "fmt" v1 "github.com/rancher/wrangler/pkg/generated/controllers/apps/v1" demov1 "github.com/xshrim/democrd/pkg/apis/demo.k8s.io/v1" democontrollerv1 "github.com/xshrim/democrd/pkg/generated/controllers/demo.k8s.io/v1" appsv1 "k8s.io/api/apps/v1" corev1 "k8s.io/api/core/v1" "k8s.io/apimachinery/pkg/api/errors" metav1 "k8s.io/apimachinery/pkg/apis/meta/v1" "k8s.io/apimachinery/pkg/runtime/schema" utilruntime "k8s.io/apimachinery/pkg/util/runtime" "k8s.io/client-go/kubernetes/scheme" typedcorev1 "k8s.io/client-go/kubernetes/typed/core/v1" "k8s.io/client-go/tools/record" "k8s.io/klog/v2" ) const controllerAgentName = "demo-controller" const ( ErrResourceExists = "ErrResourceExists" MessageResourceExists = "Resource %q already exists and is not managed by App" ) // Handler是App自定义资源的自定义控制器实现, 通常包含自定义资源的Cache和Controller以及事件记录器, 如果涉及对其他资源的操作, 可增加相应资源的Cache和Controller type Handler struct { deployments v1.DeploymentClient deploymentsCache v1.DeploymentCache apps democontrollerv1.AppController appsCache democontrollerv1.AppCache recorder record.EventRecorder } // 注册自定义资源控制器, 单独传入所有需要操作的资源的控制器, 而非通用的k8s实例化客户端 func Register( ctx context.Context, events typedcorev1.EventInterface, deployments v1.DeploymentController, apps democontrollerv1.AppController) { controller := &amp;Handler{ deployments: deployments, deploymentsCache: deployments.Cache(), apps: apps, appsCache: apps.Cache(), recorder: buildEventRecorder(events), } // 注册event handler deployments.OnChange(ctx, "app-handler", controller.OnDeploymentChanged) apps.OnChange(ctx, "app-handler", controller.OnAppChanged) } // 创建事件广播 // 将自定义资源控制器类型加入默认的Kubernetes Scheme中以便Kubernetes能够记录该控制器事件 func buildEventRecorder(events typedcorev1.EventInterface) record.EventRecorder { utilruntime.Must(demov1.AddToScheme(scheme.Scheme)) klog.V(4).Info("Creating event broadcaster") eventBroadcaster := record.NewBroadcaster() eventBroadcaster.StartLogging(klog.Infof) eventBroadcaster.StartRecordingToSink(&amp;typedcorev1.EventSinkImpl{Interface: events}) return eventBroadcaster.NewRecorder(scheme.Scheme, corev1.EventSource{Component: controllerAgentName}) } func (h *Handler) OnAppChanged(key string, app *demov1.App) (*demov1.App, error) { // app will be nil if key is deleted from cache if app == nil { return nil, nil } // 资源删除时首先会设置资源的DeletionTimestamp字段值为删除操作的时间, 这是一个Update事件 // 通过DeletionTimestamp字段是否为空判断资源是否即将删除 // 当资源关联的终止器均被执行后资源才会真正删除, 从而触发Delete事件 // 因此删除资源触发OnChange时, 直接将其关联的终止器删除并直接返回(仅针对我们创建的自定义资源) if app.DeletionTimestamp != nil { finalizers := app.GetFinalizers() for i, finalizer := range finalizers { if finalizer == "wrangler.k8s.io/demo-controller" { finalizers = append(finalizers[:i], finalizers[i+1:]...) app = app.DeepCopy() app.SetFinalizers(finalizers) _, err := h.apps.Update(app) if err != nil { return nil, err } break } } return nil, nil } deploymentName := app.Spec.DeploymentName if deploymentName == "" { utilruntime.HandleError(fmt.Errorf("%s: deployment name must be specified", key)) return nil, nil } appName := app.Spec.AppName if appName == "" { utilruntime.HandleError(fmt.Errorf("%s: app name must be specified", key)) return nil, nil } image := app.Spec.Image if image == "" { utilruntime.HandleError(fmt.Errorf("%s: image must be specified", key)) return nil, nil } deployment, err := h.deploymentsCache.Get(app.Namespace, deploymentName) // 资源不存在则创建 if errors.IsNotFound(err) { deployment, err = h.deployments.Create(newDeployment(app)) } // 获取或创建资源失败时, 直接返回错误, 资源将重新进入workqueue, 稍后再次尝试处理 if err != nil { return nil, err } // 如果资源并非由我们的自定义资源控制器所管理(OwnerReference字段), 将发出事件记录告警并正常返回 if !metav1.IsControlledBy(deployment, app) { msg := fmt.Sprintf(MessageResourceExists, deployment.Name) h.recorder.Event(app, corev1.EventTypeWarning, ErrResourceExists, msg) // 注意此情况不应返回错误, 否则会一直反复进入workqueue return nil, nil } // 对比资源的实际状态与期望状态, 进行调谐(这里对比的状态是副本数) if app.Spec.Replicas != *deployment.Spec.Replicas { klog.Infof("App %s replicas: %d, deployment replicas: %d", app.Name, app.Spec.Replicas, *deployment.Spec.Replicas) deployment, err = h.deployments.Update(newDeployment(app)) } // 调谐失败返回错误, 资源将重新进入workqueue, 稍后再次尝试处理 if err != nil { return nil, err } // 更新自定义资源的状态字段 err = h.updateAppStatus(app, deployment) if err != nil { return nil, err } return nil, nil } func (h *Handler) updateAppStatus(app *demov1.App, deployment *appsv1.Deployment) error { // 注意不要试图修改从本地缓存中获取到的资源对象, 因为它是只读的 // 应该通过DeepCopy获取该对象的副本然后进行修改和应用 appCopy := app.DeepCopy() appCopy.Status.AvailableReplicas = deployment.Status.AvailableReplicas // which is ideal for ensuring nothing other than resource status has been updated. // 优先使用UpdateStatus方法更新自定义资源的Status字段, 因为该方法绝对不会修改其他字段 // 但如果CustomResourceSubresources特性未开启的话, 就只能使用Update方法进行更新了 _, err := h.apps.Update(appCopy) return err } func (h *Handler) OnDeploymentChanged(key string, deployment *appsv1.Deployment) (*appsv1.Deployment, error) { if deployment == nil { return nil, nil } if ownerRef := metav1.GetControllerOf(deployment); ownerRef != nil { // 如果资源对象不是依据我们的自定义资源创建的, 则忽略 if ownerRef.Kind != "App" { return nil, nil } app, err := h.appsCache.Get(deployment.Namespace, ownerRef.Name) if err != nil { klog.Infof("ignoring orphaned object '%s' of app '%s'", deployment.GetSelfLink(), ownerRef.Name) return nil, nil } h.apps.Enqueue(app.Namespace, app.Name) return nil, nil } return nil, nil } // 根据自定义资源App中定义的对Deployment资源的要求, 进行Deployment资源清单数据的生成 // 这里要通过OwOwnerReferences字段指定App资源为其所有者, 以便与其他Deployment区分 func newDeployment(app *demov1.App) *appsv1.Deployment { labels := map[string]string{ "app": app.Spec.AppName, "controller": app.Name, } return &amp;appsv1.Deployment{ ObjectMeta: metav1.ObjectMeta{ Name: app.Spec.DeploymentName, Namespace: app.Namespace, OwnerReferences: []metav1.OwnerReference{ *metav1.NewControllerRef(app, schema.GroupVersionKind{ Group: demov1.SchemeGroupVersion.Group, Version: demov1.SchemeGroupVersion.Version, Kind: "App", }), }, }, Spec: appsv1.DeploymentSpec{ Replicas: &amp;app.Spec.Replicas, Selector: &amp;metav1.LabelSelector{ MatchLabels: labels, }, Template: corev1.PodTemplateSpec{ ObjectMeta: metav1.ObjectMeta{ Labels: labels, }, Spec: corev1.PodSpec{ Containers: []corev1.Container{ { Name: app.Spec.AppName, Image: app.Spec.Image, }, }, }, }, }, } } 以上代码与手动创建方式中的自定义控制器代码的功能逻辑大致相同, 只是Wrangler对事件监听和入队出队代码进行了封装, 开发者只需要编写Event Handler即可. 不再赘述.
需要注意的是, Kubernetes中的资源删除操作是分两阶段进行的:
为资源添加DeletionTimestamp字段(patch)并设置值为发起删除请求的时间戳 等待资源的Finalizers字段指定的所有终止器完成善后工作, 然后删除资源 而第1阶段的行为会被认为是Update操作并触发OnUpdate事件(对应于Wrangler框架, 则会触发OnChange事件), 因此相应Handler中的逻辑会被执行. 之后待资源真正被删除时才会触发OnDelete事件(对应Wrangler框架的OnRemove事件).
OnChange事件Handler通常响应Create和Update操作并执行相应处理逻辑, 因此为了避免OnChange事件Handler误将Delete操作当做Update进行响应, 需要在资源的OnChange事件Handler中进行相应判定和处理, 例如上文if app.DeletionTimestamp != nil 代码段的处理逻辑: 清除资源上的Finalizer然后直接退出Handler函数.
main函数编写 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 package main import ( "context" "flag" "github.com/rancher/wrangler/pkg/generated/controllers/apps" "github.com/rancher/wrangler/pkg/kubeconfig" "github.com/rancher/wrangler/pkg/signals" "github.com/rancher/wrangler/pkg/start" "k8s.io/client-go/kubernetes" "k8s.io/klog/v2" democontroller "github.com/xshrim/democrd/pkg/generated/controllers/demo.k8s.io" ) var ( masterURL string kubeconfigFile string ) func init() { flag.StringVar(&amp;kubeconfigFile, "kubeconfig", "", "Path to a kubeconfig. Only required if out-of-cluster.") flag.StringVar(&amp;masterURL, "master", "", "The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.") flag.Parse() } func main() { // 优雅处理终止信号 klog.V(4).Infof("Starting %s ...", controllerAgentName) ctx := signals.SetupSignalHandler(context.Background()) // 像kubectl一样加载kubeconfig文件(依次从指定文件, 默认文件位置和默认serviceaccount位置加载) cfg, err := kubeconfig.GetNonInteractiveClientConfig(kubeconfigFile).ClientConfig() if err != nil { klog.Fatalf("Error building kubeconfig: %s", err.Error()) } // 实例化通用的k8s客户端(用于获取事件接口) kubeClient := kubernetes.NewForConfigOrDie(cfg) // 获取Kubernetes内置的apps组控制器工厂 apps := apps.NewFactoryFromConfigOrDie(cfg) // 获取自定义资源App所在的demo组控制器工厂 demo := democontroller.NewFactoryFromConfigOrDie(cfg) // 注册资源Handler(仅传递必须的资源控制器) Register(ctx, kubeClient.CoreV1().Events(""), apps.Apps().V1().Deployment(), demo.Demo().V1().App()) // 启动所有控制器 if err := start.All(ctx, 2, apps, demo); err != nil { klog.Fatalf("Error starting: %s", err.Error()) } &lt;-ctx.Done() } main函数的主要工作是读取命令行配置参数, 实例化kubernetes标准client和自定义资源client, 然后注册EventHandler, 最后启动自定义控制器. main函数中的代码基本上都是固定代码.
项目运行与部署 以上内容完成后就可以直接运行项目了, 此外也可以将其打包为docker镜像并部署到Kubernetes集群中. 我们把这些操作也添加到Makefile中.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 vendor: go mod tidy go mod vendor build: vendor generate CGO_ENABLED=0 GOOS=linux go go build -mod vendor -a -o demo-controller . clean: vendor go run -mod vendor pkg/codegen/cleanup/main.go generate: clean go run -mod vendor pkg/codegen/main.go crd: kubectl apply -f manifest/crd.yaml manifest/app.yaml run: vendor go run -mod vendor . build: vendor CGO_ENABLED=0 GOOS=linux go build -mod vendor -a -o demo-controller . package: vendor docker build -t demo-controller:v1 . deploy: crd kubectl apply -f deployment.yaml Dockerfile 这里使用了docker的多阶段构建特性, 也可以选择先在本地生成二进制文件.
1 2 3 4 5 6 7 8 9 10 FROM golang:alpine as builder WORKDIR /root/ COPY ./ ./ RUN CGO_ENABLED=0 GOOS=linux go build -mod vendor -a -o demo-controller . FROM alpine:latest LABEL maintainer="xshrim@yeah.net" WORKDIR /root/ COPY --from=builder /root/demo-controller . CMD ["./demo-controller"] deployment.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 apiVersion: apps/v1 kind: Deployment metadata: labels: app: demo-controller name: demo-controller namespace: default spec: replicas: 1 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 25% maxSurge: 1 selector: matchLabels: app: demo-controller template: metadata: labels: app: demo-controller spec: containers: - image: demo-controller:v1 name: demo-controller resources: limits: cpu: "1000m" memory: "1024Mi" 其他 Wrangler框架此示例代码导入的相关库版本如下:
1 2 3 4 5 6 7 8 9 10 11 12 module github.com/xshrim/democrd go 1.13 require ( github.com/rancher/lasso v0.0.0-20200905045615-7fcb07d6a20b github.com/rancher/wrangler v0.7.2 k8s.io/api v0.18.8 k8s.io/apimachinery v0.18.8 k8s.io/client-go v0.18.8 k8s.io/klog/v2 v2.2.0 ) Rancher集成方式CRD开发 上文中介绍的无论是手动构建方式还是脚手架方式的CRD开发都是独立运行的, 自定义资源控制器通常是以单独的pod的方式运行在Kubernetes集群中的(当然以二进制方式运行在集群外也可以), 这是扩展Kubernetes功能的推荐实现方式, 如Prometheus Operator, BIGIP-Controller等都是如此.
事实上, 很多Kubernetes集群管理平台采用的以Kubernetes集群管理Kubernetes集群的理念本质上也是利用了自定义资源和控制器的扩展能力: 管理数据以自定义资源的形式存储在管理集群的Etcd数据库中, 管理逻辑以自定义控制器的形式作为Pod运行在管理集群上, 用一个全局管理集群纳管多个业务集群. 如流行的Rancher, OpenShift, Alauda容器云平台都是这样做的(OpenShift的管理集群即是业务集群). 其好处是:
保证整个平台是云原生自洽的, 无需引入额外的技术和中间件, 便于维护 最大限度复用Kuberenetes集群组件, 发挥Kuberenetes在高可用, 故障恢复, 弹性伸缩, 分布式和发布策略等方面的优势 Rancher CRD开发简介 Rancher是主流的Kubernetes多集群管理解决方案, Rancher Server是核心的管理服务, 它以Pod的方式运行在管理集群中, 其在管理集群中定义了大量的自定义资源以提供多集群管理功能和丰富的高级特性, 而相应的众多的自定义资源控制器则是以协程的方式运行在Rancher Server中.
如果希望在Rancher Server的基础上进行二次开发, 修改或增加Rancher功能特性, 运行独立的自定义控制器Pod显然是不合适的, 此外Rancher中的自定义资源控制器代码是深度集成在整个Server代码中的:
对自定义资源控制器进行进一步封装以协调配合完成复杂的管理逻辑 批量注册自定义资源控制器并自动完成自定义资源类型的创建 管理自定义资源权限 自定义资源分为全局级和集群级 提供独立的原生和自定义资源API和API-UI 抽象化前后端资源操作并提供统一接口 因此, 上文介绍的手动和脚手架方式开发的CRD控制器代码并不能直接应用到Rancher Server源代码中. 需要进行一些额外的代码集成:
生成自定义资源脚手架代码 编写自定义控制器代码 在RancherServer中注册自定义控制器 封装Rancher风格API 当前Rancher Server(v2.5.0+)中使用了两种自定义资源集成方案: Norman和Wrangler. 其实二者所对应的职能并不相同, 也都不是完整的集成方案, 这里只是以二者作为两种方案的代称. 前者是一直沿用的, 后者是v2.4版开始实验性加入并在v2.5版正式引入的.
Norman Norman其实只是一个用于为原生资源和自定义资源构建Rancher风格API的API框架, 包括自定义控制器和控制器注册. 而自定义资源脚手架代码是通过rancher/types 进行定义和自动生成的.
Norman框架在Rancher Server中有着非常重度的使用, 绝大部分的Rancher自定义资源都是以这种方式集成的. rancher/types生成的自定义资源部分接口和方法是为Norman而提供的特定实现, Norman本身也对原生Kubernetes API进行了封装, 以便适应前端展示的需求, 并提供单独交互的API-UI(View API功能). 这些特异性在提供良好体验的同时也存在一定的劣势:
扩展Rancher API非常复杂, 只有深入阅读Rancher代码或者接受了一定培训的开发人员才能做到
Kubernetes API在不断演变, Rancher API去兼容多个版本的Kubernetes API变得越来越困难
Rancher API屏蔽了一些高级API参数, 对于一些高级用户, 这非常不友好
采用其他方式开发的自定义资源和控制器难以与Norman框架集成, 在API-UI上不能显示, 也无法与传统前端进行交互
Norman框架已被标记为过时的.
Wrangler Wrangler是一个SDK框架, 从上文的介绍不难看出, 它其实是让前三个步骤更加简单, 降低了自定义资源与Rancher Server的耦合性, 自定义资源和控制器的编写测试更加通用和方便. 而封装Rancher风格API的工作则是由另一个新引入的API框架**Steve**与Wrangler配合完成的. Wrangler和Steve都是从V2.4实验性加入并服务于新的Dashboard前端页面(基于Vue开发)的.
Steve Wrangler上文已有详细介绍, 这里重点介绍以下Steve.
Steve是Rancher开发的新的API框架, 相比与Norman, 二者提供的API风格并不相同, Norman风格API以/v3作为访问入口并且各种资源的path是层次递进的, 如Deployment的访问路径为/v3/projects/&lt;cluster-id>:&lt;project-id>/deployments, Steve风格API则以v1作为访问入口并且各种资源的path是直接在apiRoot下的, 如Deployments的访问路径:v1/apps.deployments.
Steve框架的优势有:
完全沿用Rancher的API-UI模式, 不破坏用户的使用习惯
兼容Kubernetes 原生API, 包括原生资源和自定义资源, 最大程度保留其数据字段
扩展API非常简单, 只要向Kubernetes注册了CRD, steve通过内置controller来watch CRD资源变化, 将其热装载加入steve API中
在Rancher v2.5中提供的新的Dashboard UI就是依赖于Steve高度的兼容性才实现了对Kubernetes中所有资源的管理的. Wrangler与Steve框架的配合很明显能够让Rancher集成式CRD的开发变得更加简单. 但也存在一个问题, 这样开发的CRD难以与Rancher的传统前端进行交互(https://github.com/rancher/wrangler/issues/82).
Steve框架本身是一个独立组件, 不需要依赖Rancher也能够独立运行. 它能够自动监听和动态发现任何Kuberenetes集群中的所有原生和自定义资源, 直接对Kubernetes集群API进行二次封装以提供更加友善的API服务.
1 2 3 4 5 6 7 8 # 假设本地已配置好Kubeconfig, 没有Kubernetes环境的化请参考下文"独立CRD开发环境"章节运行Kubernetes集群 git clone https://github.com/rancher/steve.git cd steve CGO_ENABLED=0 go build -ldflags "-extldflags -static -s" -o steve ./steve # 然后就可以直接通过&lt;https://127.0.0.1:9443/v1> 或 &lt;http://127.0.0.1:9080/v1>进行API和API-UI的访问了 # 此外也可以直接使用源码中提供的Makefile生成Docker镜像通过容器的方式提供服务 # 更多启动参数参考源码 Rancher开发概述 综合以上简介内容, 关于Rancher的开发, 我们实际上需要做的就是API的集成和自定义控制器的集成. 事实上API和Controller正是Rancher Server的两大核心, API负责提供API访问服务并维护自定义资源在etcd中的持久化, Controller则负责监听自定义资源并完成相应的管理和控制逻辑.
当然Rancher实现多集群管理并非单独依靠Rancher Server, 它还包括两种运行在业务集群上的Agent组件: Cluster Agent和Node Agent, Agent负责建立到Server的websocket会话连接并提供TCP代理服务, 所有的管理控制行为都是由Server的Controller完成和发起, Agent仅仅提供代理或者配置任务的执行工作.
在进行Rancher CRD集成开发之前, 有必要先了解一下Rancher的主要组件的职责及其工作模式.
Server Server是Rancher容器云平台的核心, 其主要的功能包括:
为用户/客户端/外部应用提供Rancher风格的API服务 维护Rancher定义的自定义资源在集群Etcd中的持久化 监听自定义资源并执行相应的控制逻辑 向纳管集群部署资源和服务 监控纳管集群并同步集群数据, 通过websocket调用Docker/Kubernetes API 为平台所有集群提供统一的访问入口 API API是Rancher Server为外部提供的统一访问接口, 主要分为六大类:
Management API: 与平台和集群管理控制相关的API, 它是Server中最重要的API, 其路径前缀为/v3
Steve API: 由steve框架提供的为集群所有原生和自定义资源提供统一访问接口以及其他自定义接口的API, 主要为V2.4版以后提供的Dashboard UI提供访问, 其路径前缀为/v1
Auth API: 与平台认证服务相关的API, 其路径前缀为/v3-public和/v3/token
K8S Proxy API: Kubernetes原生API的代理, 其路径前缀为/k8s/clusters
Dialer API: 为纳管集群中的Agent提供拨号连接的API, 其路径前缀为/v3/connect和/v3/connect/register
RKE Node Config API: 从纳管集群中的Agent接收RKE节点配置数据的API, 其路径前缀为v3/connect/config
这些API中, 前四者是为用户和外部应用提供的, 后两者是为Rancher Agent提供的.
Controller Controller这里指的是Rancher Server中的自定义控制器, 它们是平台管理的核心, 依功能主要分为四大类:
API Controller: API控制器, 监听与API服务配置(settings, dynamicschemas, nodedrivers等)相关的自定义资源并根据资源的变化配置API服务 Management Controller: 管理控制器, 监听集群/节点相关的自定义资源并根据资源的变化进行集群的置备更新等操作, 集群置备完成后负责启动集群和工作负载相关的Controller Cluster Controller: 集群控制器, 又称为User Controller(被Rancher管理的下游集群相当于Rancher的用户), 监听管理集群上与纳管集群相关的自定义资源并在管理和纳管集群上进行相应自定义资源的创建和更新, 同时负责同步管理集群和纳管集群的资源信息 Workload Controller: 工作负载控制器, 监听纳管集群上的资源并进行相应的处理, 此外根据需要创建和更新额外的资源, 主要用于扩展纳管集群本身的功能特性 每个控制器类别下都包括众多的负责具体工作的控制器, 这些控制器的触发时机是不同的, 其中API控制器和管理控制器是在Rancher Server运行时触发的, 而集群控制器和工作负载控制器是在检测到纳管集群时触发的.
列举几种Rancher Server的自定义控制器实现:
Logging Controller中日志路径(HostPath)的说明:
/var/lib/docker/containers: docker默认的保存容器标准和错误输出的文件路径, 即日志文件路径 /var/log/pods: kubernetes为当前节点上的pod内的容器保存标准和错误输出的文件路径, 其中每个&lt;container_name>目录是pod内容器的日志路径, 该路径内的日志文件是容器运行时的容器日志路径的软链接, 对于docker默认配置而言就是/var/lib/docker/containers目录下相应容器的日志文件的软链接 /var/log/containers: kubernetes为当前节点上的pod内的容器存标准和错误输出的文件路径, 其中每个日志文件就是/var/log/pods目录下相应&lt;container_name>目录下日志文件的软链接 /var/lib/rancher/rke/log: rancher为rke组件保存容器标准和错误输出的文件路径, rke组件即kubernetes系统组件和其他的rke组件, 包括apiserver, etcd, controller-manager, kubelet, kube-proxy, nginx-proxy等 Context 上下文是Rancher中各种控制器的运行环境, 上下文中包括控制器, 平台管理接口, 项目管理接口, 原生资源接口, 访问控制接口, 客户端连接配置, 控制器工厂, REST映射, REST客户端等等配置信息, 服务接口和管理器. Rancher自定义控制器根据相应上下文环境的内容实现平台和集群的各种管理控制逻辑.
Rancher中的控制器运行于以下四种上下文中:
WranglerContext: 全局上下文, Wrangler框架的自定义控制器将使用此上下文, 每一个rancher管理server上均有一个Wrangler上下文, 该上下文用于实例化steve server, dashboard控制器, 认证和审计等模块, 生成其他上下文以及rancher管理server的选主和选主后的事务性操作 ScaledContext: 弹性上下文, ScaledContext也是在每个rancher管理server上均存在一个, 是2.5版本之前的全局上下文, 用于handler前端请求和生成managementContext和UserContext, 此外ScaledContext通常被当做APIContext用于处理API Request ManagementContext: 管理上下文, 管理控制器(处理任何平台全局变更的控制器)使用此上下文进行平台和rancher server master的管理, ManagementContext是具有唯一性的, 只有rancher管理server的master上会有一个管理上下文 UserContext: 用户上下文, 用户上下文其实是集群上下文, 它存在于每一个下游集群(被平台管理的集群)上, 集群控制器(处理任何集群级别变更的控制器)使用此上下文进行集群管理 Rancher在 v2.5版以后代码架构发生了较大调整, 在v2.5版之前, Rancher启动时直接实例化ScaledContext和managementContext, 新集群加入后会实例化UserContext. 但v2.5版以后, Rancher启动时直接实例化WranglerContext, 在检测到features自定义资源发生变更并开启MultiClusterManager特性启用后才会根据WranglerContext实例化ScaledContext和ManagementContext. Rancher Server是无状态的, 但是当多个Server并存时, 为了保证对平台管理资源的操作的一致性, 一些管理资源或者控制逻辑只能在一个Server上执行, 因此Rancher Server之间会进行选主. 选主行为在Kubernetes的系统组件之间同样存在. 选主机制是在etcd的基础上基于分布式锁实现的, 分布式锁选举是client-go封装的功能, 在Wrangler框架中作了二次封装, 它支持使用Endpoint, Configmap和Lease资源实现分布式锁, Rancher使用的是Configmap. 具体资源为kube-system命名空间下的cattle-controllers comfigmap. 目前官方推荐使用Lease资源实现分布式锁选举. 除以上四种上下文外, 还有一个进程上下文context.Context, 用于管理server进程的中断和退出. Rancher Server整体启动流程大致如下, 包括各上下文实例化, API Server服务启动, 自定义资源生成和自定义控制器启动, router路由生成等, 针对v2.5版以后, 后续源码整体架构可能还会有所变动, 仅供参考:
Agent Rancher Agent是Rancher管理其他集群的桥梁和代理人, Agent在被纳管集群和集群节点上运行后, 会主动发起到Rancher Server的Websocket连接, 启动TCP代理服务, 同时定期收集集群和节点信息并发送到Server进行信息同步, Server通过Agent提供的Websocket连接和代理服务实现对纳管集群的API访问和集群节点控制.
Agent分为Cluster Agent和Node Agent两种, 前者用于连接纳管集群API Server并为Rancher Server提供TCP代理调用, 以Deployment的方式运行, 默认仅运行一个实例, 后者用于在节点上执行Rancher Server发出的集群操作并周期性收集和发送集群和节点信息, 以DaemonSet的方式运行在纳管集群的每个节点上. 当Cluster Agent不可用时, Node Agent将作为后备选择用于Rancher Server到被纳管集群的API Server的连接.
API请求处理 Rancher Server中定义了大量的Handler用于处理HTTP请求, 有的用于与agent通信和建立websocket连接, 有的用于审计和认证, 有的用于处理对资源的请求, 有的作为Kubernetes原生API的代理等等. 这些Handler通过HTTP响应链能够对一个HTTP请求依次进行响应. Rancher同时使用了Norman和Steve两套API框架. 二者的路由和Handler关联方式会有所区别.
Norman API Norman API路由是在/pkg/multiclustermanager/routes.go中定义的, 对于平台和集群中的资源, 包括Kubernetes内置资源和Rancher的自定义资源, Rancher会在实例化router时先进行资源的setup, 然后进行api path和handler的绑定. 资源setup主要完成两件事:
自动批量创建自定义资源: 根据资源定义自动在管理集群中创建自定义资源 资源handler关联: 为资源schema(资源类型+资源组版本)关联Norman API Request Handler setup分为两种:
managementstored.setup(): 平台管理相关的资源的setup, 这里面包括大量自定义资源在管理集群中的批量创建和handler关联 userstored.setup(): 下游集群相关的资源的setup, 这里面包括一些主要的Kubernetes原生资源和Prometheus等附带组件的自定义资源的handler关联, 部分资源是直接通过addProxyStore进行代理关联, 部分资源则需要作额外处理 可以看到, 建立了Norman API框架的handler关联的所有资源都是写死到源码中的, 其他的所有Kubernetes原生资源或自定义资源都不支持通过Norman API进行请求.
资源handler关联后对资源的Norman API(norman api请求的前缀是/v3)请求将被路由到相应资源的Handler上, 请求会依次被Validator, Store和Formatter三种handler处理, 然后返回. 关联建立后会自动在Rancher前端页面和API-UI上体现, 可以通过API-UI进行开发调试.
Validator, Store和Formatter用于处理API请求, 通过这三个组件可以实现校验请求, 返回错误, 转换请求, 数据持久化或编辑响应信息等操作.
Validator: Validator通常用于在API请求发往Kubernetes之前检查请求的输入或者直接对请求进行拦截. Validtor仅对POST或PUT请求生效. 关联到某个资源的Validator Handler的具体逻辑代码通常放置在/pkg/api/norman/customization/&lt;资源名>下. Formatter: Formatter通常用于修改或转换请求响应数据, 例如对敏感字段进行隐藏, 为响应数据转换格式等. 关联到某个资源的Formatter Handler的具体逻辑代码通常放置在/pkg/api/norman/customization/&lt;资源名>下. Store: Store是对资源持久化的封装, 在Store Handler中资源会被发送到Kubernetes API Server进行持久化. 在此Handler中同样可以完成Validator和Formatter类似的功能, 但其主要作用还是通过定义增删改查方法实现资源的持久化. 关联到某个资源的Store Handler的具体逻辑代码通常放置在/pkg/api/norman/store/&lt;资源名>下. 除此之外, 对于资源的API请求动作可能不仅限于create, update, delete, get, watch操作, 对某些资源可能还有诸如回滚, 升级等操作, 这些额外的操作可以通过为资源关联ActionHandler实现. 如果希望在资源的API-UI界面集成除增删改查外的其他link, 则可以通过为资源关联LinkHandler实现. 当然还可以关联诸如CollectionFormatter, InputFormatter, ListHandler, DeleteHandler等更多自定义handler, 具体可以查看github.com/rancher/norman/types/types.go下的Schema结构体. 这些自定义handler的具体逻辑代码通常也都放置在/pkg/api/norman/customization/&lt;资源名>下.
以Rancher中的应用商店应用对应的自定义资源App为例:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func App(schemas *types.Schemas, management *config.ScaledContext, kubeConfigGetter common.KubeConfigGetter) { schema := schemas.Schema(&amp;projectschema.Version, projectclient.AppType) store := &amp;appStore.Store{ Store: schema.Store, Apps: management.Project.Apps("").Controller().Lister(), TemplateVersionLister: management.Management.CatalogTemplateVersions("").Controller().Lister(), } schema.Store = store wrapper := app.Wrapper{ Clusters: management.Management.Clusters(""), TemplateVersionClient: management.Management.CatalogTemplateVersions(""), TemplateVersionLister: management.Management.CatalogTemplateVersions("").Controller().Lister(), KubeConfigGetter: kubeConfigGetter, AppGetter: management.Project, UserLister: management.Management.Users("").Controller().Lister(), UserManager: management.UserManager, } schema.Formatter = app.Formatter schema.ActionHandler = wrapper.ActionHandler schema.LinkHandler = wrapper.LinkHandler schema.Validator = wrapper.Validator } Steve API steve api框架原生提供了对集群所有原生和自定义资源的动态支持, 因此steve的API路由主要是将带/k8s/clusters/&lt;cluster_id>前缀的API请求去掉前缀然后交由对应集群的steve server处理即可, 具体逻辑代码位于pkg/api/steve/proxy/proxy.go下.
此外steve支持通过AdditionalAPIs添加任意独立路由及其Handler. 具体逻辑代码位于pkg/api/steve/additionalapi.go下.
使用steve api的前提下为资源添加自定义的handler是通过将资源注册到steve时通过为steve的schema添加Template实现的, Template中指定了资源类型, 资源组和Formatter, Store等, 在Customize字段中可以添加诸如Formatter, CollectionFormatter, Action, List, Delete等各种自定义Handler. 如:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 func Register(ctx context.Context, server *steve.Server, helmop *helmop.Operations, contentManager *content.Manager) error { ops := newOperation(helmop) server.ClusterCache.OnAdd(ctx, ops.OnAdd) server.ClusterCache.OnChange(ctx, ops.OnChange) index := &amp;contentDownload{ contentManager: contentManager, } addSchemas(server, ops, index) return nil } func addSchemas(server *steve.Server, ops *operation, index http.Handler) { server.BaseSchemas.MustImportAndCustomize(types2.ChartUninstallAction{}, nil) server.BaseSchemas.MustImportAndCustomize(types2.ChartUpgradeAction{}, nil) server.BaseSchemas.MustImportAndCustomize(types2.ChartUpgrade{}, nil) server.BaseSchemas.MustImportAndCustomize(types2.ChartRollbackAction{}, nil) server.BaseSchemas.MustImportAndCustomize(types2.ChartInstallAction{}, nil) server.BaseSchemas.MustImportAndCustomize(types2.ChartInstall{}, nil) server.BaseSchemas.MustImportAndCustomize(types2.ChartActionOutput{}, nil) operationTemplate := schema2.Template{ Group: catalog.GroupName, Kind: "Operation", Customize: func(apiSchema *types.APISchema) { apiSchema.LinkHandlers = map[string]http.Handler{ "logs": ops, } apiSchema.Formatter = func(request *types.APIRequest, resource *types.RawResource) { if !resource.APIObject.Data().Bool("status", "podCreated") { delete(resource.Links, "logs") } } }, } releaseTemplate := schema2.Template{ Group: catalog.GroupName, Kind: "Release", Customize: func(apiSchema *types.APISchema) { apiSchema.ActionHandlers = map[string]http.Handler{ "rollback": ops, "uninstall": ops, } apiSchema.ResourceActions = map[string]schemas3.Action{ "rollback": { Input: "chartRollbackAction", Output: "chartActionOutput", }, "uninstall": { Input: "chartUninstallAction", Output: "chartActionOutput", }, } }, } repoTemplate := schema2.Template{ Group: catalog.GroupName, Kind: "Repo", Customize: func(apiSchema *types.APISchema) { apiSchema.ActionHandlers = map[string]http.Handler{ "install": ops, "upgrade": ops, } apiSchema.ResourceActions = map[string]schemas3.Action{ "install": { Input: "chartInstallAction", Output: "chartActionOutput", }, "upgrade": { Input: "chartUpgradeAction", Output: "chartActionOutput", }, } apiSchema.LinkHandlers = map[string]http.Handler{ "index": index, "info": index, "chart": index, "icon": responsewriter.ContentType(index), } }, } chartRepoTemplate := repoTemplate chartRepoTemplate.Kind = "ClusterRepo" server.SchemaFactory.AddTemplate( operationTemplate, releaseTemplate, repoTemplate, chartRepoTemplate) } 自定义资源与控制器 Norman集成开发 Wrangler集成开发 iptables四表五链及顺序, iptables和netfilter的关系 kvm主要有哪些组件, 分别是什么作用(kvm内核模块, qemu设备模拟), 与vmware的虚拟化有什么不同 描述公司的线上CICD自动发布的流程 select, poll, epoll有什么区别 进程切换进行了哪些工作 Linux五种IO模式(阻塞, 非阻塞, IO多路复用, 信号驱动IO, 异步IO) Kubernetes集群规模, 网络模式, 几种网络模式的区别, k8s相关问题 开发环境 独立CRD开发环境 独立CRD的开发相较普通的Golang项目开发, 需要一个Kubernetes集群环境来调试和验证代码. 如果没有云上集群可用, 则需要在本地搭建集群. Kubernetes集群搭建是相对麻烦而且资源消耗比较高的. 本地Kubernetes测试集群有几种可选方案, 如minikube, k3s等, 这里推荐Kubernetes兴趣小组的**kind**项目, 即Kubernetes in Docker.
kind的最大特点是整个Kubernetes集群是运行在一个Docker容器中的, 整个集群的运行和管理只需要一个二进制文件和一个镜像文件, 部署和清理都非常方便. kind启动的集群中除了常规的Kubernetes组件外, 还部署好了网络插件和本地存储类插件, 能够覆盖大多数开发和测试需求.
此外, kind允许多节点集群部署, 还提供全平台支持, 具有很高的可定制性. 详情请查看kind官方文档.
不同的kind版本支持的Kubernetes版本和所需kindest/node镜像也有所不同(通常镜像版本与Kubernetes版本一致), 具体查看kind发行版页面, 以kind v0.9.0版为例, 其支持的Kubernetes版本包括v1.13-19的几个主要版本, 我们使用v1.17.11版, 下载镜像:
1 docker pull kindest/node:v1.17.11 kind的常用操作:
创建集群 1 2 kind create cluster --name=test --config=kind.yaml # name和config参数可省略 kind create cluster --name=test --image=kindest/node:v1.17.11 # 不指定镜像将使用最高版本kindest/node 删除集群 1 kind delete cluster --name=test 查看集群信息 1 kubectl cluster-info --context kind-test # context参数可省略, kind会自动设置其启动的集群为默认上下文 获取kind集群和节点列表 1 2 kind get clusters kind get nodes 管理集群节点内的镜像和容器 1 2 3 4 # kind启动的容器均是一个Kubernetes集群节点, 节点内各集群组件也是以容器的方式运行的 # 节点内容器和镜像管理使用crictl, crictl是CRI兼容的容器运行时命令行接口, 功能和使用方法与docker客户端基本相同. docker exec -it $(kind get nodes|grep control-plane|sed -n '1p') crictl ps # 控制面节点内的容器管理 docker exec -it $(kind get nodes|grep control-plane|sed -n '1p') crictl exec -it etcd sh # 进入节点内容器交互式命令行 复制镜像到集群节点 1 2 3 4 # kind允许直接将本地镜像复制到容器化的集群节点内供集群使用 kind load docker-image nginx:latest --name test kind load image-archive nginx.tar --name test # 镜像复制到节点内后会自动补全镜像名, 如nginx:latest在节点内的镜像名为docker.io/library/nginx:latest SHELL自动完成 1 2 3 4 5 6 7 8 # bash kind completion bash > ~/.kind-completion source ~/.kind-completion # zsh kind completion zsh > /usr/local/share/zsh/site-functions/_kind autoload -U compinit &amp;&amp; compinit # fish kind completion fish > ~/.config/fish/completions/kind.fish kind启动Kubernetes集群后会自动设置本地kubeconfig的默认上下文为该集群, 可以直接使用kubectl进行集群管理, client-go sdk中的client也可以自动连接集群.
Rancher CRD开发环境 1 2 3 4 5 6 # https://lihaoquan.me/2020/3/8/k8s-crd-develop.html # https://tangxusc.github.io/2019/05/code-generator%E4%BD%BF%E7%94%A8/ # https://developer.aliyun.com/article/719215 # https://qiankunli.github.io/2020/08/10/kubernetes_crd.html # https://zhuanlan.zhihu.com/p/141203047 1 2 3 4 5 6 7 go: # embeded will run k3s server and need root privilage CATTLE_DEV_MODE=yes go run main.go --add-local=true --features=multi-cluster-management=true --k8s-mode=external --kubeconfig=/home/xshrim/.kube/config # go run -mod vendor main.go --debug --add-local=true --features=multi-cluster-management=true --k8s-mode=embedded # export http_proxy=http://127.0.0.1:38080 # export https_proxy=http://127.0.0.1:38080 # no_proxy=localhost,127.0.0.1</content></entry><entry><title>容器云稳定性</title><url>https://xshrim.github.io/post/%E5%AE%B9%E5%99%A8%E4%BA%91%E7%A8%B3%E5%AE%9A%E6%80%A7/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag><tag>容器</tag></tags><content type="html"> 容器云是一种平台级基础设施，作为大规模业务应用的载体，其稳定性关系到托管业务的可用性， 保证平台稳定的重要性是不言而喻的。作为容器云的集大成者和行业事实标准，脱胎于Google企业级容器平台Borg的Kubernetes从诞生之初就引入了稳定性的设计，无论是对平台本身还是托管的业务应用，Kubernetes都提供了多种保证自身和业务稳定性的机制。
稳定性是一个比较泛化的概念，诸如兼容性，性能优化，可用性，扩展性等都与之相关。本章将从API、平台和业务三个维度阐述Kubernetes的稳定性设计。通过阅读本章，您将对Kubernetes的API设计，平台组件、节点、网络与存储的关键点优化策略以及业务容器运行保障机制有更深入的了解，从而对保证集群和业务系统的稳定可靠运行成竹在胸。
1 API 稳定性设计 Kubernetes是一个灵活强大的生产级别的开源容器编排系统，与服务器，网络，存储等各基础设施和认证授权，虚拟化，大数据等各种技术领域有着密切的交互与协作，同时也在不断吸纳各种其他领域，迅速地发展壮大。如何保证这样一个几乎"包罗万象"的系统在不断增加和扩展特性的快速迭代过程中各版本的稳定性和兼容性自然是一个至关重要的课题。
依托Google生产环境运维经验，同时凝聚社区最佳创意和实践，Kubernetes社区以其开明的姿态吸引全世界的开发者和爱好者参与其中，提供诸如讨论版，视频会议，Meetup社区，特殊兴趣小组等互动讨论和技术协作渠道，制定严格而高度自动化的开发，审核，迭代规范&hellip;。Kubernetes社区重视代码，重视民主化的治理方式及其丰富的运作机制为Kubernetes产品本身的的稳定性提供了强有力的保障。本节不打算讨论社区治理方面的内容，仅就Kubernetes的API相关内容一窥Kubernetes的稳定性设计。
Kubernetes API是Kubernetes系统的重要组成部分，组件之间的所有操作和通信以及外部对Kubernetes的调用都是由API Server处理的REST API调用。API的设计对于产品内部通信和外部协作的兼容性，扩展性和稳定性有着举足轻重的影响。
1.1 API结构与版本 Kubernetes API是通过HTTP提供的编程接口，以REST风格组织并管理资源，支持通过POST，PUT，DELETE，GET等标准的HTTP方法对资源进行增删改查等操作。
1.1.1 资源 Kubernetes中所有内容都被抽象为资源。所有资源都可以使用清单文件(manifest file)进行描述，使用Etcd数据库进行存储并由API Server统一管理。
资源分为集群和命名空间两级作用域，命名空间级资源会在其命名空间删除时被删除。上图资源类别并不代表其作用域
所有资源在其资源对象模式(清单文件)中都有一个具体的表示形式，称为Kind。同一资源的多个对象(实例)可以组成集合
可以通过kubectl api-resources命令查看当前Kubernetes环境支持的所有资源的名称，缩写，api组，作用域及其对应的Kind
1.1.2 API Kubernetes API大多数情况下遵循标准的HTTP REST规范，JSON和Protobuf是其主要序列化结构，资源通过API接口传入API Server最终持久化到Etcd数据库。API是由API Server组件提供服务，API Server是Kubernetes的管理中心，是唯一能够与Etcd数据库交互的组件.
1.1.2.1 API群组 Kubernetes API除了提供组织和管理各种资源的接口外，还包括一些系统层面的接口。目前API主要分为三种形式:
类型 描述 路径 清单字段示例 Core Group API 核心组API，包括Kubernetes中核心概念相关的API，如node，pod，service等 /api/v1 v1 Named Groups API 指定组API，包括各种非核心概念及自定义的API，如deployment，cronjob等 /apis/GROUP/VERSION apps/v1，batch/v1 System-wide API 系统级API，包括非Kubernetes资源相关的系统级API，如metrics，healthz等 /metrics，/healthz等 除了系统级API外，Kubernetes基本上是以**API Group(API群组)**的方式组织各种API的，核心组API并未使用/apis/core/v1路径是历史原因(事实上核心组也成为遗留组)。API群组是一组相关的API对象的集合，使用群组概念能够更方便的管理和扩展API。结构示意如下:
1.1.2.2 API版本 为了在兼容旧版本的同时不断升级新的API，Kubernetes支持多种API版本，不同的API版本代表其处于不同的稳定性阶段，低稳定性的API版本在后续的产品升级中可能成为高稳定性的版本。
API版本规则是通过基于API level选择版本，而不是基于资源和域级别选择，是为了确保API能够描述一个清晰的连续的系统资源和行为的视图，能够控制访问的整个过程和控制实验性API的访问。
API通过这种三级渐进式版本共存与演化策略，在不断吸纳新的功能特性并给予其足够的孵化空间的同时，保证了整体API的可用性和稳定性。
资源定位三元组 API Group，API Version和Resource(GVR三元组)就可以唯一确定一个资源的API路径。如/apis/rbac.authorizatiok8s.io/v1beta1/clusterroles。
对于命名空间级资源则需要额外包含具体命名空间(否则将请求所有命名空间下相应资源)，如/apis/apps/v1/namespaces/kube-system/deployments。
对应到资源对象模式(清单文件)三元组则为API Group，API Version和Kind(GVK)，相应字段为apiVersion和kind，如{"apiVersion": "app/v1"，"kind": "Deployment"}。
Kubernetes组件默认启用加密通信，并需要请求者提供凭证，为了更方便地请求API，可以开启代理访问。
1 2 kubectl proxy --port=8888 # 开启代理访问 curl http://localhost:8888/api/pods/ # kubectl代理会自动使用默认凭证路径(/etc/kubernetes/ssl/)下的凭证文件(kube-proxy.xx) 可以通过kubectl api-versions命令查看当前Kubernetes环境启用的所有API群组及其版本。
1.1.3 数据持久化与无损转换 用户向Kubernetes发起资源构建请求时只提供了一个资源清单文件(如deployment.yaml)，但事实上Kubernetes基于可用性和稳定性的考虑，却能够支持同时使用不同稳定性的API版本访问同一资源，返回不同版本的资源数据。这一灵活的特性有赖于API Server的资源数据无损耗转换机制。
1.1.3.1 数据持久化 资源数据是持久化到Etcd数据库中的，而从资源清单文件到持久化到Etcd数据库的资源数据的大致流程如下:
客户端(kubectl，curl，sdk等)得到资源清单文件(YAML或JSON格式) 部分支持格式转换的客户端(如kubectl，sdk等)会先将YAML格式的资源清单文件转换为JSON格式化，然后根据清单字段或相应参数获取API Server 请求路径，发送到API Server API Server对收到的资源清单文件进行准入校验和字段预处理，生成资源数据，对同资源的多个版本进行无损转换 API Server将资源数据转换为指定的存储版本 API Server将存储版本的资源数据按照指定编码(PROTOBUF或JSON)进行序列化，以key-value的方式存储到Etcd中 API Server启动时可以通过--storage-versions参数指定资源数据的存储版本(默认是最新稳定版，如v1); 通过--storage-media-type参数指定序列化编码(默认是application/vnd.kubernetes.protobuf)。
Etcd数据库中的资源数据是作为value存储的，而对应的key则是按照**/registry/#{k8s对象}/#{命名空间}/#{具体实例名}**的规范格式生成的。
1.1.3.2 无损转换 Etcd数据库中只存储了资源的一个指定版本，但客户端传入的资源清单文件中指定的资源版本和客户端向API Server请求的资源版本可能并不是Etcd数据库中存储的版本，API Server如何在各个版本之间进行无损转换呢?
如果一个资源存在众多版本，那么编写各种不同版本之间的转换规则无疑是非常麻烦的，因此API Server中维护着一个internal版本，需要作版本转换时，任意原版本都先转换为internal版本，再由internal版本转换到指定的目的版本，如此只要每个版本都可转换为internal版本，则可以支持任意版本之间的转换。
而保证版本转换过程中不出现数据丢失(即无损转换)则是依靠**annotations(注解)**实现。例如从版本A转换到版本B，对不同字段的处理如下:
版本A和B中均存在的字段可直接转换 版本A中存在而版本B中不存在的字段将写入注解中 版本A中不存在而版本B中存在的字段，如果存在于版本A的注解中则从注解中读取字段值，否则字段值置空 1.2 API扩展 Kubernetes因其平台级基础设施的特殊性，与服务器，网络，存储，虚拟化，身份认证等等绝大多数计算机软硬件技术领域存在广泛交集，这需要大量的适配与对接，此外作为底层容器编排引擎，也需要满足高度的可扩展性以面对大量的功能特性扩展需求。
常规的解决方案是修改Kubernetes相关API和控制器的源代码或者定义新的资源类型并作为新的核心资源API合并到Kubernetes官方社区代码中。但这些方无疑会迅速使得Kubernetes核心API资源变得臃肿庞杂难以维护，最终导致API过载，这会为项目本身维护和产品生产环境运行的稳定性带来巨大挑战。
Kubernetes提供了两种API扩展机制保证核心API足够精简的同时满足庞杂的适配对接和特性扩展需求:
自定义资源类型(CRD): 即CustomResourceDefinitions。允许用户通过资源清单的方式定义任意全新的资源对象类型，并由API Server管理自定义资源的整个生命周期，用户还可以通过定义相应的控制器对自定义资源及其他相关资源进行监视，协调和管理。通常将自定义资源和自定义控制器配合工作的方式统称为CRD方式。 API Server聚合(AA): 即API Server Aggregattion。其前身是用户API Server(UAS)，UAS允许用户设计一套自定义的API Server与Kubernetes主API Server并行生效，可以在不影响原API Server的前提下实现更加复杂和定制化的逻辑和功能，但这种方式对代码开发的要求会比较高。自定义API Server可以选择与主API Server进行聚合也可以独立存在，但独立存在的方式无法与Kubernetes很好的集成，因此自定义API Server普遍采用API Server聚合的方式。 1.2.1 自定义资源类型 Kubernetes原生支持自定义资源的创建和生命周期维护，自定义资源类型一经创建便与Pod，Job，Secret等内建资源拥有同等地位，可以像内建资源一样创建并运行自定义资源类型的实例对象。自定义资源配合定制的控制器就可以完成如自动化网络管理，自动化存储管理，自动化证书管理，自动化应用集群管理等广泛的特性需求。
1.2.1.1 自定义资源 自定义资源类型的创建
每个API资源都有相应的Group群组和资源类型，声明自定义资源就必须命名一个与已有群组不重复的新的Group群组，新的群组中可以有任意数量的自定义资源类型，并且这些资源类型可以与其他群组中的资源类型重名。
自定义资源类型的声明方式与Kubernetes的内建资源的创建方式相同，都是通过资源清单文件进行声明并应用，因为CustomResourceDefinition本身就是一种内建资源。一个最简单的自定义资源类型的声明清单示例如下:
1 2 3 4 5 6 7 8 9 10 11 12 # apps-crd.yaml apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: apps.foo.bar spec: group: foo.bar version: v1 names: kind: App plural: apps scope: Namespaced 各字段解释如下:
apiVersion: CustomResourceDefinition这一内建资源所在的群组及当前使用的api版本。目前为固定字段 kind: 固定字段，表示是在声明自定义资源类型 metadata.name: 自定义资源类型的全名，它由spec.group和spec.names.plural字段组合而成 spec.group: 自定义资源类型所在群组 spec.version: 自定义资源类型的群组版本 spec.names.kind: 自定义资源的类型，惯例首字母大写 spec.names.plural: 其值通常为kind的全小写复数，关系到自定义资源在REST API中的HTTP路径 spec.names.scope: 表示自定义资源的作用范围，Kubernetes中大部分资源都是命名空间级(Namespaced) 自定义资源本身是不支持多版本的，但自定义资源的群组支持多版本。也就是说每一个群组的特定版本里的所有自定义资源都不需要考虑资源版本之间的兼容问题，保证群组内各资源的整体一致性。
spec.names中还有许多其他字段，不指定则会由API Server在创建自定义资源类型时自动填充.
自定义资源类型声明完成后就可以通过kubectl create -f apps-crd.yaml或kubectl apply -f apps-crd.yaml命令进行创建了，创建完成后可通过kubectl get crd apps.foo.bar -o yaml命令进行查看。
自定义资源类型创建完成后，其REST API的HTTP访问路径为/apis/foo.bar/v1/namespaces/default/apps(以default命名空间为例)。
自定义资源的创建
自定义资源类型创建完成后就可以创建相应的自定义资源。一个简单的自定义资源的创建清单如下:
1 2 3 4 5 6 7 8 # app.yaml apiVersion: foo.bar/v1 kind: App metadata: name: demo spec: port: 3333 path: /app 自定义资源声明完成后就可以通过kubectl create -f app.yaml或kubectl apply -f app.yaml命令进行创建了，创建完成后可通过kubectl get apps.foo.bar -o yaml命令进行查看。
自定义资源创建完成后，其REST API的HTTP访问路径为/apis/foo.bar/v1/namespaces/default/apps/demo(以default命名空间为例)。
自定义资源spec下的字段只有在被特定控制器或应用按照约定的规范读取解析和处理后才具有实际意义.
终止器
自定义资源和内建资源一样都可以支持终止器(finalizer)，终止器允许控制器实现异步的预删除钩子。
对于具有终止器的资源对象第一个删除请求仅仅是为metadata.deletionTimestamp字段设置一个值，而不是删除它，然后触发相应控制器执行自定义处理并删除该资源对象的终止器，最后再一次发出删除请求。
每个资源对象都可以有多个终止器，删除资源对象时，只有当其所有终止器都删除后才会真正被删除。
1.2.1.2 自定义控制器 在Kubernetes中，工作负载(workload)类的资源(如ReplicaSet，Deployment，StatefulSet，CronJob等运行容器的内建资源)是通过控制器(controller)进行管理的，这些控制器相当于一个状态机，用于控制对应Pod的具体状态和行为。
对于自定义资源，同样可以为其编写相应的控制器，进行资源数据的分析处理和Pod的状态行为控制。自定义资源和自定义资制器的配合使用才能创建，配置和管理复杂的有状态应用，真正提供声明式API服务，实现新特性的添加和Kubernetes API的扩展。
Kubernetes中控制器的主要工作模式如下:
控制器代码主要包括两部分:
客户端SDK: SDK是Kubernetes官方提供的开发工具包(sdk是golang编写，又称为client-go)，提供诸如Reflector，Delta FIFO queue，Thread safe Local store，Informer，Indexer，Workqueue等与API Server进行交互的通用组件 控制器特定内容: 根据特定控制器提供的特定功能而编写的相应回调函数和处理逻辑。这部分是编写自定义控制器的主要内容 控制器的完整工作流如下:
Reflector反射器通过List&amp;Watch机制从API Server获取资源(包括内建资源和自定义资源)变化 Reflector将获取到的资源添加到Delta FIFO队列中 Informer通知器从Delta FIFO队列中弹出资源对象 Informer将得到的资源对象传递到Indexer(索引器) Indexer为资源对象构建索引，以线程安全的方式将资源数据存储到线程安全的Key-Value本地存储中 Informer通过Dispatch Event Handler事件分发处理函数将资源对象的key发送到自定义控制器 自定义控制器通过Resource Event Handler资源事件处理函数将资源对象key发送到Workqueue工作队列 Process Item任务处理函数从工作队列获取资源对象key并将其传递给Object Handler资源对象处理函数 资源对象处理函数通过Indexer的引用从Key-Value本地存储中获取资源对象本身并进行处理 1.2.1.3 Operator和Kubebuilder 声明自定义资源并编写自定义控制器进行Kubenetes API扩展的方式对于代码开发有一定的要求。主要的工作内容如下:
初始化项目结构 定义自定义资源 编写自定义资源相关代码 初始化自定义控制器 编写自定义控制器相关代码(即业务逻辑) 这其中除了定义自定义资源和编写业务逻辑是需要针对具体需求单独开发外，其他内容都是通用的，可以自动化完成，因此社会和官方提供了一些CRD开发脚手架以帮助开发者无需了解复杂的Kubernetes API特性的情况下迅速构建Kubernetes扩展应用。目前比较流行的有两个:
Operator Framework: CoreOS公司(目前属redhat旗下)开发和维护CRD快速开发框架。它包括Operator SDK和Operator Lifecycle Manager两部分，前者是Operator核心开发工具包，后者对Operator提供从安装，更新到运维的全生命周期管理 Kubebuilder: Kubenetes社区兴趣小组开发和维护的CRD快速开发框架。提供与Operator类似的功能，但不支持Operator生命周期管理 Operator和Kubebuilder的实现原理和主要功能类似，二者均使用控制器工具和控制器运行时，封装结构类似，使用难易度相当，其主要区别如下:
Operator SDK原生支持Ansible和Helm Operator; Kubebuilder不支持
Operator SDK集成Operator Lifecycle Manager(OLM)，提供Operator全生命周期管理; Kubebuilder不支持
Kubebuilder使用Makefile帮助用户完成操作员的任务(构建，测试，运行，代码生成等); Operator SDK当前使用内置子命令。Operator SDK团队将来可能会迁移到基于Makefile的方法
Kubebuilder使用Kustomize来构建部署清单; Operator SDK使用带有占位符的静态文件
Kubebuilder改善了对admission准入和CRD转换webhooks的支持; Operator SDK尚未支持
Kubebuilder提供了更为完善的官方文档
鉴于Operator Framework的影响力 ，习惯性将基于CRD构建的Kubernetes应用称为Operator。相对于通过Helm Charts打包和部署Kubenetes应用的方式，Operator的自动化程度更高，更加符合云原生理念，因此越来越流行，目前越来越多的常用应用推出了自己的Operator，Kubernetes社区推出了OperatorHub以供用户进行Operator的发布的使用。
1.2.2 API Server聚合 API聚合机制是Kubernetes 1.7版本引入的特性，能够将用户扩展的API注册到kube-apiserver（即Kubernetes核心API Server）上，仍然通过API Server的HTTP URL对新的API进行访问和操作。
API聚合机制的目标是提供集中的API发现机制和安全的代理功能，将开发人员的新API动态地、无缝地注册到Kubernetes API Server中进行测试和使用。为了实现这个机制，Kubernetes在kube-apiserver服务中引入了一个API聚合层（API Aggregation Layer），用于将扩展API的访问请求转发到用户服务的功能。
1.2.2.1 聚合层 API聚合层（API Aggregation Layer）在kube-apiserver进程内运行。在扩展API注册之前，聚合层不做任何事情。要注册API，用户必须添加一个APIService资源对象，用它来申领Kubernetes API中的URL路径。自此以后，聚合层将会把发给该 API 路径的所有内容（例如 /apis/myextensiomycompany.io/v1/…）代理到已注册的 APIService。
正常情况下，APIService 会实现为运行于集群中某Pod内的扩展API Server。如果需要对增加的资源进行动态管理，扩展API Server 经常需要和一个或多个控制器一起使用。聚合层支持多个自定义API Server对Kubernetes的API进行横向扩展。
扩展API Server与kube-apiserver之间的连接应具有低延迟。 发现请求应当在五秒钟或更短的时间内从kube-apiserver往返。可以在kube-apiserver上设置 EnableAggregatedDiscoveryTimeout=false 功能开关将禁用超时限制，但此开关将在将来的版本中被删除。
API聚合功能需要通过配置kube-apiserver服务的以下启动参数进行启用：
&ndash;requestheader-client-ca-file=/etc/kubernetes/ssl_keys/ca.crt：客户端CA证书。 &ndash;requestheader-allowed-names=：允许访问的客户端common names列表，通过header中&ndash;requestheader-username-headers参数指定的字段获取。客户端common names的名称需要在client-ca-file中进行设置，将其设置为空值时，表示任意客户端都可访问。 &ndash;requestheader-extra-headers-prefix=X-Remote-Extra-：请求头中需要检查的前缀名。 &ndash;requestheader-group-headers=X-Remote-Group：请求头中需要检查的组名。 &ndash;requestheader-username-headers=X-Remote-User：请求头中需要检查的用户名。 &ndash;proxy-client-cert-file=/etc/kubernetes/ssl_keys/kubelet_client.crt：在请求期间验证Aggregator的客户端CA证书。 &ndash;proxy-client-key-file=/etc/kubernetes/ssl_keys/kubelet_client.key：在请求期间验证Aggregator的客户端私钥。 如果kube-apiserver所在的主机上没有运行kube-proxy，即无法通过服务的ClusterIP进行访问，那么还需要设置--enable-aggregator-routing=true。
1.2.2.2 扩展API Server API聚合层提供了扩展API Server的动态注册、发现汇总、和安全代理，但是扩展API Server本身需要自行开发，并且需要遵循Kubernetes的开发规范。扩展API Server是以Kubernetes中的Pod的形式存在的，通常需要与一个或多个控制器一起使用。
官方提供了扩展API Server开发样例sample-apiserver，可以此为模板进行开发，但开发和部署步骤是非常繁琐的。好在可以使用第三方提供的开发框架如apiserver-builder和service-catalog，它们都同时提供了用于管理新资源的API框架和控制器框架，提供了一定的自动化支持。如使用apiserver-builder开发扩展API Server的关键步骤如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建项目目录 mkdir $GOPATH/src/github.com/example/demo-apiserver # 在项目目录下新建一个名为boilerplate.go.txt，里面是代码的头部版权声明 cd $GOPATH/src/github.com/example/demo-apiserver curl -o boilerplate.go.txt https://github.com/kubernetes/kubernetes/blob/master/hack/boilerplate/boilerplate.go.txt # 初始化项目 apiserver-boot init repo --domain example.com # 创建一个非命名空间范围的api-resource apiserver-boot create group version resource --group demo --version v1beta1 --non-namespaced=true --kind Foo # 创建Foo这个api-resource的子资源 apiserver-boot create subresource --subresource bar --group demo --version v1beta1 --kind Foo # 生成上述创建的api-resource类型的相关代码，包括deepcopy接口实现代码、versioned/unversioned类型转换代码、api-resource类型注册代码、api-resource类型的Controller代码、api-resource类型的AdmissionController代码 apiserver-boot build generated # 直接在本地将etcd，apiserver，controller运行起来 apiserver-boot run local 1.2.2.3 APIService注册 扩展API Server是作为APIService注册到Kubernetes的核心API Server上的，启用API Server的聚合功能后就可以通过APIService资源对象注册API了。APIService资源清单文件如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: apiregistratiok8s.io/v1beta1 kind: APIService metadata: name: v1beta1.customapi.k8s.io spec: service: name: customapi namespace: custom group: customapi.k8s.io version: v1beta1 insecureSkipTLSVerify: true groupPriorityMinimum: 100 versionPriority: 100 上述清单文件中apiVersion和kind的值是固定的， metadata.name的值是由spec.version和spec.group的值拼接而来。APIService的API群组为customapi.k8s.io，版本为v1beta1，其API URL则为/apis/customapi.k8s.io/v1beta1。对应的后端扩展API Server为custom命名空间下的customapi服务，该服务将负载到运行扩展API Server的Pod上。
kubectl create命令创建成功后，通过Kubernetes API Server对/apis/customapi.k8s.io/v1beta1路径的访问都会被API聚合层代理转发到后端服务customapi.custom.svc上。
Kubernetes内置的资源监控组件**Metrics Server**是一个典型的API聚合案例，可以通过它学习聚合API Server的开发和部署。
1.2.2.4 CRD与AA 相同
CRD和AA两种方式都是在保证API稳定性的前提下的API扩展方案，均支持横向扩展， 从实现上均采用了资源+控制器的模式提供声明式API服务，使用上二者提供了统一的访问方式，内部差异外部请求者是无感知的。此外，通过CRD或AA创建自定义资源时，与在Kubernetes平台之外实现它相比，能够提供诸如CRUD，通用元数据，通用客户端库，资源显示与字段编辑，内置认证授权模块等部分Kubernetes原生特性的支持：
异同
尽管存在诸多共通之处，但二者的扩展维度是截然不同的，CRD扩展的是API资源，直接复用Kubernetes核心API Server，属于轻量级扩展，这种方式简单易用，无论是代码开发还是部署维护都很方便快捷，但其功能特性受限于核心API Server，无法提供注入额外的认证授权和准入机制，无法使用其他存储层等。API Server聚合扩展的是API Server本身，允许设计并运行单独的API Server，与核心API Server并行生效，认证授权， 准入机制和存储层等的复用都是可选的，提供了更高级的API功能和更大的灵活性。
通常情况下建议采用CRD方式扩展API，CRD简单够用，开发维护难度和成本都远低于AA方式，除非必要不要考虑AA方式。
更多CRD和AA方式的比较可参考官方文档。
2 平台优化实践 不同的容器云平台解决方案在整体架构和实现上是存在差异的，对于平台稳定性的保障和优化方案也会因之而异。如OPENSHIFT容器云平台以一整个Kubernetes集群作为平台，而RANHCHER则通过单独的平台Server提供多种异构Kubernetes集群的纳管。但关系平台稳定性的核心问题都是Kubernetes集群的稳定性。对于Kubernetes集群的性能优化是保证集群稳定性的重要手段。
Kubernetes集群作为一种基础设施，其优化涉及到方方面面的内容，如api-server，etcd，kubelet等集群组件的优化，集群节点，网络和存储的优化等等。当集群到达一定规模的时候，一些细微优化往往能够让集群性能得到显著提升，从而降低各方面性能瓶颈影响集群稳定性的可能。
保证集群稳定性的另一个主要手段是对集群进行高可用设计，这部分内容将在单独章节中详细介绍，这里就不会过多涉及。
2.1 组件优化 Kubernetes集群是通过api-server，etcd，kube-controller-manager,kubelet等一系列系统组件组织起来的，它们是集群的核心。这些组件提供了丰富调优参数和机制以满足不同的集群规模和系统环境。其整体架构如下：
etcd: key-value数据库，存储整个集群的状态和数据 kube-apiserver：资源操作的统一入口，并提供认证、授权、访问控制、API服务，API 注册和发现等机制 kube-controller-manager：通过控制器维护集群资源的状态，比如故障检测、自动扩展、滚动更新等 kube-scheduler：负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet：负责维持容器的生命周期，同时也负责Volume（CVI和网络（CNI的管理 kube-proxy：负责为Service提供cluster内部的服务发现和负载均衡 此外还有一些重要的如coredns，autoscaler等附加组件，对这些核心组件的优化是Kubernetes集群优化的关键。除etcd外，其他组件都是无状态的，为这些组件设计高可用架构可以提高组件的负载能力和组件服务的稳定性。由于高可用将使用单独的章节展开，因此下文关于各组件的优化内容将不对高可用部分作赘述。
2.1.1 etcd优化 etcd是整个Kubernetes集群的集群数据的分布式存储数据库，所有集群数据都是通过api-server对etcd进行读写，etcd的读写性能对整个集群性能的影响是立竿见影的。
决定etcd性能的关键因素是延迟（latency）和吞吐量（throughput）。延迟是完成一次操作所需的时间，吞吐量是一个时间段内能够完成操作的总数。通常情况下，一个三节点的etcd集群在轻负载下可以在低于1ms内完成一个请求，并在重负载下每秒可以完成30000个请求。
etcd基于Raft一致性算法完成节点数据同步的，一致性性能受限于网络IO延迟和磁盘IO延迟。完成一个etcd请求的最小时间是节点之间的网络往返时延(Round Trip Time / RTT)和需要提交数据到持久化存储的 fdatasync 时间之和。吞吐量方面，etcd会将多个请求打包在一起再进行分发以提高重负载下的吞吐量。
2.1.1.1 网络IO延迟优化 Etcd底层的分布式一致性协议依赖两个时间参数来保证节点之间能够在部分节点掉钱的情况下依然能够正确处理主节点的选举。第一个参数是心跳间隔（heartbeat interval），即主节点通知从节点它还是领导者的频率。实践数据表明，该参数应该设置成节点之间 RTT 的时间。Etcd的心跳间隔默认是 100 毫秒。第二个参数是选举超时时间（election timeout），即从节点等待多久没收到主节点的心跳就尝试去竞选领导者。选举超时必须至少是RTT 10 倍的时间以便对网络波动，Etcd的选举超时时间默认是 1000 毫秒。
实际环境尤其是跨数据中心部署etcd集群时，由于网络延迟可能会很高，因此需要根据实际网络情况对etcd的心跳间隔和选举超时时间进行相应调整。调整方法如下：
1 2 3 4 # 通过命令行参数 etcd --heartbeat-interval=100 --election-timeout=1000 # 通过环境变量 ETCD_HEARTBEAT_INTERVAL=100 ETCD_ELECTION_TIMEOUT=1000 etcd 如果Etcd的leader节点要处理大规模并发的客户端请求，就有可能因为网络拥塞的原因延迟对follower节点的响应。在Linux上可以用tc工具调整网络带宽和优先级：
1 2 3 4 5 tc qdisc add dev eth0 root handle 1: prio bands 3 tc filter add dev eth0 parent 1: protocol ip prio 1 u32 match ip sport 2380 0xffff flowid 1:1 tc filter add dev eth0 parent 1: protocol ip prio 1 u32 match ip dport 2380 0xffff flowid 1:1 tc filter add dev eth0 parent 1: protocol ip prio 2 u32 match ip sport 2379 0xffff flowid 1:1 tc filter add dev eth0 parent 1: protocol ip prio 2 u32 match ip dport 2379 0xffff flowid 1:1 2.1.1.2 磁盘IO延迟优化 优化磁盘IO最直接有效的方式就是使用SSD磁盘。鉴于etcd的高读写需求，应尽量将etcd运行在本地SSD磁盘的节点上，集群规模较大时尤其不建议对etcd使用网络磁盘。
etcd的存储目录分为snapshot和wal，他们写入的方式是不同的，snapshot是内存直接dump file。而wal是顺序追加写，对于这两种方式系统调优的方式是不同的，snapshot可以通过增加IO平滑写来提高磁盘IO能力，而wal可以通过降低pagecache的方式提前写入时序。因此对于不同的场景，可以考虑将snap与wal放在不同的磁盘上，提高整体的IO效率，这种方式可以提升etcd 20%左右的性能。
etcd底层的存储引擎boltdb采用了MVCC机制，会把一个key的所有update历史都存储下来，所以相关数据文件会线性增长，这会加重etcd的数据加载负担并降低集群的性能，因此默认情况下每10,000个update后etcd会创建一个snapshot实现日志压缩。如果etcd的内存使用和磁盘使用过高，那么应该尝试调低快照触发的阈值：
1 2 3 4 # 通过命令行参数 etcd —snapshot-count=5000 # 通过环境变量 ETCD_SNAPSHOT_COUNT=5000 etcd etcd需要把log实时写入磁盘，所以其他IO密集型进程可能会提高etcd进程的写延迟，导致心跳超时、处理请求超时、成员失联等问题。可以通过ionice命令提高etcd进程的磁盘操作优先级：
1 ionice -c2 -n0 -p `pgrep etcd` etcd默认的请求大小限制是1.5MiB，存储总量限制是2GiB，前者过大会导致磁盘IO延迟增加，后者过小将导致etcd不可用，可以根据实际情况对这两个限制进行修改：
1 etcd --max-request-bytes=1048576 --quota-backend-bytes=8589934592 此外，可以考虑将etcd集群部署到Kubernetes集群外的独立节点上，以最大化利用节点性能。
2.1.2 kube-apiserver优化 kube-apiserver是Kubernetes集群的核心组件，为集群提供API服务，是其他所有组件和外部请求的唯一入口，也是读写etcd的唯一途径。apiserver对整个集群的性能和稳定性具有举足轻重的影响。
设置--apiserver-count 和 --endpoint-reconciler-type，可使得多个kube-apiserver实例加入到Kubernetes Service的endpoints中，从而实现高可用。
设置--max-mutating-requests-inflight 和--max-requests-inflight ，控制可变和不可变请求连接数（指请求进入apiserver后是否可以被加工）。默认是 200 和 400。 节点数量在 1000 - 3000 之间时，推荐：
1 2 --max-requests-inflight=1500 --max-mutating-requests-inflight=500 节点数量大于 3000 时，推荐：
1 2 --max-requests-inflight=3000 --max-mutating-requests-inflight=1000 对不同的object进行分库存储，首先应该将数据与状态分离，即通过apiserver的--etcd-servers-overrides参数将events放在单独的etcd实例中，后期可以将 pod、node 等 object 也分离在单独的 etcd 实例中：
1 --etcd-servers="http://etcd1:2379,http://etcd2:2379,http://etcd3:2379" --etcd-servers-overrides="/events#http://etcd4:2379,http://etcd5:2379,http://etcd6:2379" 设置--target-ram-mb配置缓存相关的apiserver内存大小，计算公式：
1 --target-ram-mb=node_nums * 60 2.1.3 kube-controller-manager优化 kube-controller-manager作为集群内部的管理控制中心，负责集群内的Node、Pod副本、服务端点（Endpoint）、命名空间（Namespace）、服务账号（ServiceAccount）、资源定额（ResourceQuota）、弹性伸缩（AutoScaling）等的管理。Controller Manager关系到各种资源的状态能否正常维持。
kube-controller-manager可以通过leader election实现高可用：
1 2 3 4 5 --leader-elect=true --leader-elect-lease-duration=15s --leader-elect-renew-deadline=10s --leader-elect-resource-lock=endpoints --leader-elect-retry-period=2s 设置与kube-apiserver通信的qps：
1 2 --kube-api-qps=100 # 每秒向apiserver查询的次数 --kube-api-burst=150 # 每秒向apiserver查询的次数上限 禁用不需要的controller，kubernetes中存在几十个controller，默认启动为--controllers，即启动所有controller，可以禁用不需要的controller。
调整controller同步资源的周期，避免过多的资源同步导致集群资源的消耗，所有带有--concurrent前缀的参数都可调节。
controller-manager 中存储的对象非常多，每次升级过程中从apiserver获取这些对象并反序列化的开销可能导致几分钟的集群功能中断，可以通过预启动备controller的informer预先加载所需数据，在主controller升级时主动释放Leader Lease触发备controller立即接管工作。
2.1.4 kube-scheduler优化 kube-scheduler是Kubernetes集群的默认调度器，调度器负责依据资源需求，策略约束，亲和性规则，数据位置，工作负载间干扰和最后时限等调度原则对Pod做出合适的调度选择。合理的调度能够在兼顾应用部署效率的同时保证整个集群各节点提供平稳的服务。
kube-scheduler可以通过leader election实现高可用：
1 2 3 4 5 --leader-elect=true --leader-elect-lease-duration=15s --leader-elect-renew-deadline=10s --leader-elect-resource-lock=endpoints --leader-elect-retry-period=2s 设置与kube-apiserver通信的qps：
1 2 --kube-api-qps=100 # 每秒向apiserver查询的次数 --kube-api-burst=150 # 每秒向apiserver查询的次数上限 合理利用默认调度器的Pod/Node Affinity &amp; Anti-affinity, Taint &amp; Toleration, Priority &amp; Preemption和 Pod Disruption Budget等特性。
根据需要通过schduler_extender扩展默认调度器。
根据具体场景需求编写特定调度器并在Pod中指定通过spec.schedulerName字段所使用的调度器。
使用Descheduler提供动态调度支持，使集群各节点保持动态平衡状态。
2.1.5 kubelet优化 kubelet是Kubernetes中的节点代理，运行在每个节点上，与容器运行时，网络和存储插件交互，负责提供Pod管理，容器健康检查和资源监控等工作。
设置单节点允许运行的最大Pod数量，默认是110个：
1 --max-pods=110 配置允许并行拉取镜像：
1 --serialize-image-pulls=false 设置镜像拉取超时时间。默认值1分钟，对于大镜像拉取需要适量增大超时时间：
1 --image-pull-progress-deadline=30 设置与kube-apiserver通信的qps：
1 2 --kube-api-qps=100 # 每秒向apiserver查询的次数 --kube-api-burst=150 # 每秒向apiserver查询的次数上限 使用node lease减少心跳上报频率，让kubelet使用轻量级的nodeLease对象作为更新请求代替老的Update Node Status方式，减轻apiserver负担。本特性在v1.16版本后默认启用。
使用bookmark机制告知apiserver只watch特定bookmark的事件，减轻apiserver负担。本特性v1.15版本后默认启用。
kubelet 拥有节点自动修复的能力，例如在发现异常容器或不合规容器后，会对它们进行驱逐删除操作，此默认行为可能存在风险，可以通过设置--eviction-hard=限制其自动驱逐能力。
2.1.6 kube-proxy优化 kube-proxy是集群中每个节点上运行的网络代理，负责维护节点上的网络规则。这些网络规则控制网络流量的路由转发并实现负载均衡，从而允许从集群内部或外部的网络会话与Pod进行网络通信。
kube-proxy有三种运行模式：userspace，iptables，ipvs。其中userspace在用户态完成流量转发，效率低下已经不建议使用。kube-proxy当前使用的是iptables模式，iptables是Linux内核功能，更加简单高效，但其负载算法单一，且通过规则遍历完成匹配，随着集群规模的增长，性能损失是可预见的。ipvs是用于负载均衡的Linux内核功能，基于哈希表的规则匹配使得它的性能几乎不受集群规模的影响，而且能够提供更多样化的负载均衡算法。
kube-proxy的主要优化方案就是将默认运行模式替换为ipvs模式。通常在服务（Kubernetes中的Service）规模超过5000的情况下，在响应时间和CPU用量上ipvs会出现明显的优势。
2.1.7 coredns优化 coredns是Kubernetes内默认的域名解析服务，它并不是系统组件的一部分，可以运行在Node节点上，并通过Service向集群内部提供服务。
coredns默认配置只会运行一份实例，在其升级或是所在节点宕机时，会出现集群内部dns服务不可用的情况，严重时会影响到线上服务的正常运行。为了避免故障，可以将coredns的replicas值设为2或者更多，并用anti-affinity将他们部署在不同的Node节点上。
Kubernetes为Pod提供了四种DNS策略：
None：允许Pod忽略Kubernetes环境中的DNS设置
Default：Pod从运行所在的节点的DNS服务进行域名解析
ClusterFirst：默认策略，让Pod首先使用集群DNS服务进行域名解析，解析不成功才使用所在节点的DNS配置解析
ClusterFirstWithHostNet：以nostNetwork模式运行的Pod使用集群DNS服务解析域名解析
​ 由于默认使用ClusterFirst策略，而集群DNS进行域名解析时会利用search和ndots特性对域名进行逐个拼接解析，部分场景下可以通过Pod的dnsPolicy字段更改默认的DNS策略或者通过Pod的dnsConfig字段更改ndots值避开集群DNS解析的默认规则。
2.2 节点优化 在Kubernetes中，节点（Node）是执行工作的机器。节点可以是虚拟机也可以是物理机。每个节点都包含用于运行 Pod的必要服务，并由主控组件管理。节点上的服务包括容器运行时、kubelet和kube-proxy。
通过对集群规模和节点性能的评估以及操作系统和Kubernetes组件的相关参数的优化，可以为Kubernetes提供必要的特性支持，更好地发挥节点性能，降低因节点资源紧张而影响集群性能和稳定性的风险。
2.2.1 节点基础环境优化 为了获得更稳定的性能体验和更便捷的资源管理，作为Kubernetes集群工作节点的服务器建议在操作系统，CPU内存容量和系统参数等方面进行一定的优化。
操作系统选择
Kubernetes集群对节点操作系统没有硬性要求，主流的Linux发行版都是可用的，但要求内核版本为3.10以上（旧内核在容器兼容性上存在bug），推荐的发行版是RHEL 7.8+，CentOS 7.8+以及Debain buster和Ubuntu 18.04。Kubernetes自v1.14版本以后，已经支持生产级的Windows节点，但处于性能和特性兼容方面的考虑，如非必需，不应考虑Windows节点。
部分厂商为容器化定制了专用操作系统，如RancherOS，CoreOS（RHOS）等，这些操作系统提供了比较完整的容器环境支持，但剔除了任何不必要的软件和服务，甚至对系统结构作了一定程度的改造，以最大化利用主机资源，提供云原生特性支持，但对主机的集中管理带来了一定的不便，需要酌情考虑是否使用。
节点容量规划
Kubernetes并不要求工作节点统一配置，但规划一个通用的CPU内存配置是必要的，一方面便于管理，另一方面主机模板化后也方便进行动态扩缩容。少量大节点和大量小节点的容量规划理念各有优劣，需要根据实际需求和客观条件进行规划。
少量大节点理念优点：
减少管理成本：管理少量主机比管理大量主机更省力，更新和补丁可以更快地应用，预期的故障数量也会更少 节点成本更低：通常一个大节点比同配置的多个小节点成本更低廉 应用适配度高：允许允许诸如ElasticSearch等资源要求高的应用 少量大节点理念缺点：
单节点Pod数量多：高配置的单节点意味着更多的Pod会被调度上去，这会为Kubernetes运行在节点上的代理带来更大的开销，如容器常规检测和信息收集活动需要更多的时间。官方建议每个节点最多运行110个Pod, 低于此值的Pod数量应当不会对代理组件产生明显影响 更大的爆破半径：少量的大节点意味着一旦节点故障将可能影响更多的应用，导致大量的Pod重新部署 弹性伸缩增量大：Kubernetes支持集群节点的弹性伸缩，大节点意味着弹性伸缩时会有较大的伸缩量，这可能导致资源浪费 大量小节点理念优点：
较小的爆破半径：大量小节点意味着节点故障影响的应用会比较少 弹性伸缩增量平稳：节点的弹性伸缩增量比较平稳，资源浪费少 大量小节点理念缺点：
节点数量大：大量节点对Kubernetes控制平面而言可能是个挑战。尽管官方声称单集群支持的节点上限为5000，但实际上规模达到500个节点就会需要额外的优化 系统开销大：每个节点都需要运行一组守护进程，越多的节点意味着越多的系统资源被守护进程占用 我们可以根据实际业务需求，建设成本投入和集群规模预估等因素制定相对折中的容量规划。一般容量为8 Core &amp; 16GB内存到64 Core &amp; 128GB内存的节点通用性更高。
此外，根据应用的特定需求如CPU密集，IO密集，GPU需求，操作系统要求等定制多套不同的容量规范也是推荐做法。
系统参数配置
修改节点的系统内核参数以满足集群需求，最大化利用节点资源，编辑/etc/sysctl.conf文件：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 fs.file-max=1000000 # max-file 表示系统级别的能够打开的文件句柄的数量， 一般如果遇到文件句柄达到上限时，会碰到"Too many open files"或者Socket/File: Can’t open so many files等错误。 net.ipv4.ip_forward=1 # 开启路由转发功能 # 配置arp cache 大小（以下三个参数，当内核维护的arp表过于庞大时候，可以考虑优化） net.ipv4.neigh.default.gc_thresh1=1024 # 存在于ARP高速缓存中的最少层数，如果少于这个数，垃圾收集器将不会运行。缺省值是128。 net.ipv4.neigh.default.gc_thresh2=4096 # 保存在 ARP 高速缓存中的最多的记录软限制。垃圾收集器在开始收集前，允许记录数超过这个数字 5 秒。缺省值是 512。 net.ipv4.neigh.default.gc_thresh3=8192 # 保存在 ARP 高速缓存中的最多记录的硬限制，一旦高速缓存中的数目高于此，垃圾收集器将马上运行。缺省值是1024。 net.netfilter.nf_conntrack_max=10485760 # 允许的最大跟踪连接条目，是在内核内存中netfilter可以同时处理的“任务”（连接跟踪条目） net.netfilter.nf_conntrack_tcp_timeout_established=300 net.netfilter.nf_conntrack_buckets=655360 # 哈希表大小（只读）（64位系统、8G内存默认 65536，16G翻倍，如此类推） net.core.netdev_max_backlog=10000 # 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 fs.inotify.max_user_instances=524288 # 默认值: 128 指定了每一个real user ID可创建的inotify instatnces的数量上限 fs.inotify.max_user_watches=524288 # 默认值: 8192 指定了每个inotify instance相关联的watches的上限 让配置生效：
1 sysctl -p 不同的容器云平台的调优参数可能有所不同。
此外，OPENSHIFT容器云平台还提供Node Tuning Operator通过tuned守护进程自动管理节点性能优化。Node Tuning Operator为用户提供了一个统一的节点级sysctls管理接口，并可以根据具体用户的需要灵活地添加定制的性能优化设置。
其他事项
Kubernetes自v1.6版以后的节点和容器支持上限如下：
不超过 5000 个节点 不超过 150000 个Pod 不超过 300000 个容器 每台节点不超过 110 个Pod 对于公有云上的Kubernetes集群，还应当根据集群规模提前增大相关配额：
虚拟机个数 vCPU 个数 内网 IP 地址个数 公网 IP 地址个数 安全组条数 路由表条数 持久化存储大小 2.2.2 master节点优化 master节点上运行着Kubernetes的集群控制平面相关组件（kube-apiserver，kube-controller-manager，kube-scheduler)，这些组件对集群进行全局决策（例如，调度），并检测和响应集群事件。理论上这些组件可以运行在集群任何节点上，但简单起见一套控制平面组件通常会运行在同一个节点上。控制平面管理整个集群，负载压力巨大且影响整个集群的状态，因此运行这些组件的master节点需要进行特别优化。
由于master节点管理和控制整个集群，随着集群规模的扩大，master节点的压力也会增加，因此需要为master节点规划相匹配的CPU和内存配置规格。
集群节点规模和master节点规格参照（etcd运行在master节点）如下：
节点规模 Master CPU核心 Master 内存 1-5个节点 4 8GB 6-20个节点 4 4C16G 21-100个节点 8 32GB 100-200个节点 16 64GB 200-500个节点 32 128GB 500个节点以上 64 256GB ​ 不同的容器云平台规格参数可能有所不同。
etcd数据库默认也运行在master节点上，由于etcd会产生大量的资源占用，建议将etcd运行在额外的服务器上，避免与控制平面组件争抢资源。
master节点本质上也是工作节点，同样也能够在其上部署业务Pod，建议为master节点打上不可调度污点，防止业务Pod被调度到master节点上挤占控制平面组件资源。master节点默认会添加此污点。
2.2.2 worker节点优化 工作节点是运行工作负载（即应用Pod）的节点，除了常规的基础环境优化外，还应当视集群规模需求进行一些工作负载相关的优化。
限制节点上可部署的Pod数量。节点运行太多Pod会影响节点性能，减慢Pod调度速度，影响应用性能。Kubernetes通过kubelet的--pods-per-core和--max-pods参数限制节点上每个CPU核心可分配的Pod数量和整个节点上可运行的Pod的数量，两个参数都被设置时，其中较小的值决定真正的限制数量。--max-pods的默认值是110。
除了硬性限制外，kubernetes平台还存在一些软性的性能指标上限，即如果集群指标超过这些上限值，虽然不会导致集群不可用，但会显著降低集群的整体性能。因此需要尽量避免接近这些上限值。
限制类型 指标上限 节点数量 2000 Pod数量 150000 每个节点Pod数量 250 命名空间数量 10000 每个命名空间Pod数量 25000 Service数量 10000 每个命名空间Service数量 5000 每个服务的后端Pod数量 5000 每个命名空间的Deployment数量 2000 重新设置插件配额和副本数。很多Kubernetes集群插件被广泛使用，这些插件在部署时已经设定了CPU和内存配额和副本数量，并且不会自动改变。当集群规模扩大时，这些插件可能需要更多CPU和内存资源或者副本才能正常运行提供服务，因此在集群规模变化时要注意对集群插件的这些配置进行相应的手动更新，避免插件Pod负载压力过大或者达到资源配额限制而不断被杀死重建，影响集群性能和插件的正常服务。
配置节点容量预留。节点上的资源（包括CPU，内存，临时存储和PID等）被Kubernetes视为容量（Capacity），默认情况下，Pod可以消耗节点上所有可用的容量，因此可能导致Pod与节点上的操作系统和Kubernetes守护进程争抢资源，影响节点性能。
可以通过Kubernetes的Node Allocatable特性配置节点的容量预留，避免应用Pod消耗掉节点上的所有资源。
Kubernetes将节点容量分为以下几个部分：
可用容量（allocatable）才是应用Pod真正可以使用的容量，其计算方法是：
1 可用容量 = 节点容量 - kube预留容量 - 系统预留容量 - 驱逐阈值 kube-reserved：kube-reserved是为了给诸如 kubelet、container runtime、node problem detector 等kubernetes系统守护进程争取资源预留。但这并不代表要给以Pod形式运行的系统守护进程保留资源。
要在系统守护进程上执行 kube-reserved，需要把kubelet的 --kube-reserved-cgroup 标志的值设置为kube守护进程的父控制组，如kubelet.service
1 2 3 # kubelet参数设置kube资源预留 --kube-reserved=[cpu=100m][,][memory=100Mi][,][ephemeral-storage=1Gi][,][pid=1000] --kube-reserved-cgroup=/kubelet.service system-reserved：system-reserved用于为诸如 sshd、udev 等系统守护进程争取资源预留。 system-reserved也应该为 kernel 预留 内存，因为目前 kernel 使用的内存并不记 Kubernetes的Pod上。 同时还推荐为用户登录会话预留资源。
要想在系统守护进程上执行 system-reserved，需要把kubelet的 --system-reserved-cgroup 标志的值设置为OS系统守护进程的父级控制组，如system.slice
1 2 3 # kubelet参数设置系统资源预留 --system-reserved=[cpu=100m][,][memory=100Mi][,][ephemeral-storage=1Gi][,][pid=1000] --system-reserved-cgroup=/system.slice eviction-threshold：eviction-threshold预留容量后，将在节点可用容量不足该阈值时，尝试驱逐Pod。驱逐阈值只支持 memory 和 ephemeral-storage，且其预留的容量不能为Pod所用。
1 2 # kubelet参数设置驱逐阈值 --eviction-hard=[memory.available&lt;500Mi] 此外Kubernetes还提供了如下相关参数：
reserved-cpus：reserved-cpus显式指定为操作系统和Kubernetes守护进程预留哪几个CPU资源，此选项在 kubernetes 1.17 版本中添加。
1 2 # kubelet参数设置保留CPU --reserved-cpus=0-3 enforce-node-allocatable：enforce-node-allocatable指定为哪些对象启用容量预留，默认支持Pod
1 2 # kubelet参数设置容量预留启用对象 --enforce-node-allocatable=pods[,][system-reserved][,][kube-reserved] cgroup-driver：cgroup-driver指定使用的cgroup驱动，默认为cgroupfs，另一可选项为systemd。kubelet使用的cgroup driver需要与容器运行时使用的cgroup driver一致
cgroups-per-qos：启用QoS和Pod级别的cgroup，开启后，kubelet会将管理所有workload Pods的cgroups。此参数默认是开启的
2.3 网络优化 网络是Kubernetes中的核心部件，Kubernetes对集群网络进行了重新抽象，以实现整个集群网络的扁平化。网络规划和性能表现关系到集群内系统组件，应用容器之间能否正常高效地通信，也关系到集群对外服务的可用性和服务质量。合理的网络优化不仅能够有效维护集群状态，更能够为集群和集群内应用的对外服务提供强有力的质量保障。
2.3.1 Kubernetes网络模型 Kubernetes网络基于容器网络技术。容器网络利用网络命名空间内核特性实现网络隔离，再通过网桥，iptables，overlay等技术实现容器间通信。典型的Docker容器运行时提供了如下四种网络模式：
None模式：容器独立网络命名空间，不分配虚拟网络设备也不提供对外连接 Container模式：同主机容器间共享网络命名空间，容器间网络配置一致，可以通过localhost通信 Host模式：容器和宿主机共享网络命名空间，容器和宿主机网络配置一致，可以通过localhost通信 Bridge模式：默认模式，主机通过虚拟网桥设备和veth pair为主机和主机所有容器提供网络桥接实现互通 对于跨主机容器间通信，需要利用虚拟网桥配合额外的技术实现，主要有overlay和underlay两种模式，每种模式又有多种网络方案，这些网络方案遵循CNI（容器网络接口）规范，能够适配所有兼容CNI的容器运行时。
Kubernetes对网络进行抽象，将其划分为四个层面：
高耦合容器间的网络通信，也就是Pod内部的容器间网络通信 集群内Pod到Pod之间的网络通信 集群内Pod到Service之间的网络通信 集群外部到集群内部的网络通信，也就是集群外部到Service的网络通信 Pod内容器通信利用Linux内核的网络命名空间特性实现。
集群内Pod间网络通信则需要借助网络插件，Kubernetes本身是不负责为Pod提供和管理网络的，而是由kubelet调用网络插件进行相应配置，然后由容器运行时通过CNI调用网络插件为Pod进行自动的网络配置。网络插件除了为Pod配置网络外，还通常需要提供IP统一分配与管理，跨主机Pod通信等功能。不同的网络插件实现方式，网络特性和适用条件都是不同的，因此需要根据实际的集群情况选择合适的网络插件，这是Kubernetes网络优化的重点，下文将详细介绍。
集群内Pod到Service的通信是Kubernetes利用Linux内核的iptables路由转发功能配合kube-proxy监听apiserver并编辑本机iptables规则实现的Pod网络流量负载机制。Service机制在kube-proxy优化中有介绍，后文还会具体说明。Service层面主要的网络优化手段是前文提到的将kube-proxy的iptables模式替换为ipvs模式，不再赘述。
集群外部到集群内部的通信称为集群网络入口，入口方案存在多种实现方案，有的方案是Kubernetes集群原生支持的，但是存在局限性，有的方案需要单独的控制器和负载均衡器，能够提供更强大的功能，但此类方案也存在多种实现，各有优劣，需要根据实际需求进行选择，这也是Kubernetes网络优化的重点，下文将详细介绍。
2.3.2 网络插件选型 Kubernetes中Pod的网络自动配置管理以及Pod间跨主机通信需要使用单独的网络插件实现。网络插件分为两类：
kubenet：这是Kubernetes的默认网络插件，它创建具有IP范围的虚拟网桥，然后在每个主机上手动添加主机之间的路由，这种方式功能单一，自动化程度低，通常不会选择它 CNI插件：CNI插件基于通用的容器网络接口，可以自动生成基本配置，让网络的创建和管理变得更加容易。它是网络供应商、项目与 Kubernetes集成的标准方法。 CNI插件的核心功能是解决Pod跨主机通信的问题，有很多不同的实现方案，从网络结构和实现技术上看，主要分为二层转发和三层转发两种。二层转发需要进行网络封包和解包，称为overlay网络，三层转发直接利用现有网络协议，称为underlay网络。性能上underlay方案会优于overlay方案。当然不同实现方案在易用性，安全性，资源消耗，功能特性等方面也会有所不同。
主流的CNI网络插件有：
Flannel:
flannel是CoreOS公司为容器跨主机通信提供的overlay网络方案，它也是最老牌最成熟的Kubernetes网络插件。flannel通过VxLAN，UDP等方式将二层网络包封装到三层网络包中，借助宿主机的三层网络将包转发到目的容器的宿主机上，再通过解包将网络包转发到正确的容器上。UDP方式在用户态完成封包解包操作，VxLAN在内核态完成，因此VxLAN性能比UDP好很多，通常选择flannel vxlan模式，其网络性能损耗在10%左右。
使用flannel网络插件的Kubernetes集群会在初始化时指定一个16位掩码的网段，默认情况下集群中每个节点会被分配一个24位掩码的网段，因此集群中最多可以有255个节点，每个节点上最多可以有253个Pod（其他地址被系统组件占用）。当然可以通过指定节点的node.spec.podCIDR字段调整每个节点可分配的地址段以调整节点上的Pod上限，但需要保证所有节点的地址段不会冲突。flannel插件适合小规模Kubernetes集群。
flannel还提供一种三层转发的underlay模式：host-gw模式是一种直连主机网关模式，容器到另外一个主机上容器的网关设置成所在主机的网卡地址，不需要通过overlay封包和拆包，性能损耗非常低，但host-gw模式最大的缺点是必须是在一个二层网络中，毕竟下一跳的路由需要在邻居表中，否则无法通行。
Waeve Net：
Weave Net是一个overlay多主机容器网络方案，支持去中心化的控制平面，各个host上的wRouter间通过建立Full Mesh的TCP链接，并通过Gossip来同步控制信息。这种方式省去了集中式的KV Store，能够在一定程度上减低部署的复杂性。
数据平面上，Weave通过UDP封装实现二层overlay，封装支持两种模式，一种是运行在用户态的sleeve mode，另一种是运行在内核态的 fastpathmode。Sleeve mode通过pcap设备在Linux bridge上截获数据包并由wRouter完成UDP封装，支持对L2 traffic进行加密，还支持Partial Connection，但是性能损失明显。
Fastpath mode即通过OVS的odp封装VxLAN并完成转发，wRouter不直接参与转发，而是通过下发odp 流表的方式控制转发，这种方式可以明显地提升吞吐量，但是不支持加密等高级功能。
Weave Net支持网络策略（Network Policy），也内置域名解析，其所有节点都作为网格运行，这会导致数百个节点后，分发路由的开销将成为瓶颈。
Calico：
Calico 是一个基于BGP的纯三层underlay数据中心网络方案，并且与OpenStack、Kubernetes、AWS、GCE等IaaS和容器平台都有良好的集成。
Calico在每一个计算节点利用Linux Kernel实现了一个高效的vRouter来负责数据转发，而每个vRouter通过BGP协议负责把自己上运行的workload的路由信息向整个Calico网络内传播——小规模部署可以直接互联，大规模下可通过指定的BGP route reflector来完成。 这样保证最终所有的workload之间的数据流量都是通过IP路由的方式完成互联的。Calico节点组网可以直接利用数据中心的网络结构（无论是L2或者L3），不需要额外的NAT，隧道或者Overlay Network。
此外，Calico基于iptables还提供了丰富而灵活的网络策略，保证通过各个节点上的ACLs来提供Workload的多租户隔离、安全组以及其他可达性限制等功能。
Cilium：
Cilium 是位于Linux内核与容器编排系统的中间层。向上可以为容器配置网络，向下可以向Linux内核生成 BPF 程序来控制容器的安全性和转发行为。Cilium要求Linux内核版本在4.8.0以上。
管理员通过Cilium CLI配置策略信息，这些策略信息将存储在etcd数据库里，Cilium使用插件（如CNI）与容器编排调度系统交互，来实现容器间的联网和容器IP地址分配，同时Cilium还可以获得容器的各种元数据和流量信息，提供监控 API。
Contiv：
Contiv是思科开源的容器网络方案，是一个用于跨虚拟机、裸机、公有云或私有云的异构容器部署的开源容器网络架构，并与主流容器编排系统集成。Contiv最主要的优势是直接提供了多租户网络，并支持L2(VLAN), L3(BGP), Overlay (VXLAN)以及思科自家的ACI。
Kube Router：
Kube Router是基于Kubernetes网络设计的一个集负载均衡器、防火墙和容器网络的综合方案。它使用IPVS/LVS内核功能来加速负载均衡和路由。利用BGP协议和Go的GoBGP库为容器提供网络直连服务，通过ipset操作iptables，以保证防火墙的规则对系统性能有较低的影响。采用了Kube Router的Kubernetes很容易通过添加标签到Kube Router的方式使用网路策略功能。
Romana：
Romana是Panic Networks提出的纯三层容器网络方案，其目标是通过完全不封装而实现主机级网络性能。Calico和Kube Router都在第3层（通常使用IPIP）封装流量，以便在子网之间路由流量，而这会降低性能。Romana支持基于iptables ACLs的网络策略。
具体对比如下：
Flannel，Cilium和Contiv均支持二层overlay和三层underlay网络模式，Cilium和Contiv相对小众，Flannel是比较流行和成熟的方案，非常适合小规模集群。Flannel的三层模式host-gw要求主机间二层互通，因此使用较少，更多的是使用其vxlan模式，不过vxlan模式下支持DirectRouting选项，开启该选项后可以在通信主机处于同一子网下时切换到host-gw模式，非同一子网下默认使用vxlan模式，从而提高网络性能。
Waeve Net是纯二层overlay网络模式，受限于overlay的性能和节点规模，除非有流量加密需求，否则没有太多理由选择它。
Calico，Kube Router和Romana是纯三层underlay网络模式，其中Calico是最成熟的大规模集群解决方案，underlay网络性能损耗小，集群规模的扩大产生的网络性能影响低，能够充分利用数据中心已有的网络环境，而且提供了丰富灵活的网络策略支持，calico的网络排障也相对容易。Calico目前是最流行的生产级Kubernetes集群网络解决方案。
除了以上方案外，还有诸如OVN，Midonet等其他方案，在此不作介绍。
一些商业容器云产品还会内置网络插件，如OpenShift容器云内置了基于OVS（Open vSwitch）的SDN（软件定义网络）作为统一的集群网络，对于此种情况就没必要再去选择其他的网络插件解决方案了。
而对于定制云，如果集群规模较小，可以使用成熟易管理的Flannel方案，如果是大规模生产集群，则推荐Calico方案。另外，Flannel和Calico还联合发布了统一的网络插件Canal，该方案使用Flannel实现跨节点Pod通信的同时，而Pod和宿主节点的通信则由Calico接管以实现网络策略支持。目前Canal项目已经停止开发，Flannel和Calico都分别开发，但保持了良好的文档以将它们结合在一起。
2.3.3 入口方案选型 网络入口的目标是让集群外部发起的请求最终被发送的部署再集群种的相应目的应用，也就是Pod上。
2.3.3.1 入口方案类型 Kubernetes支持的网络入口方案主要有三种类型：
NodePort：
NodePort是集群原生支持的网络入口方案，它在集群中的主机节点上为Service提供一个代理端口，利用主机节点的iptables路由转发规则，将到主机节点该端口的流量路由到对应的Service上，然后由Service通过iptables规则将流量再路由到对应的后端Pod上，从而实现从主机网络到后端Pod的访问。
NodePort方案简单方便，无需额外工具支持，适合临时测试使用，但此方案存在诸多限制：
需要暴露节点IP：节点是Kubernetes的资源，是允许动态添加和删除的，节点IP是可以动态分配的，因此通过节点IP访问集群是难以保证服务可靠性的 需要占用节点端口：NodePort类型的Service会永久占据一个固定的节点端口（除非Service被删除），一方面存在与其他服务产生端口冲突的风险，另一方面节点端口有限，限制集群应用数量 容错负载能力不足：节点故障将导致服务不可用，且通过主机节点作为网络入口增加节点负载压力，容易产生性能瓶颈。当然这些可以通过结合独立的负载均衡器解决 功能单一：依赖iptables的流量转发，不能提供更加丰富网络管理功能 实际环境种通常不会选择NodePort方案。
LoadBalancer：
LoadBalancer方案可以对NodePort方案进行补充，在集群外部署负载均衡器将网络请求负载到主机节点上，也可以直接在Service种配置laodbalancer类型，将外部请求直接通过负载均衡器负载到相应的Pod上。
LoadBalancer方案也比较简单方便，能够避免节点IP暴露，性能更好，对于云环境，云服务提供商通常会为loadbalancer类型的Service自动创建外部负载均衡，但此方案也有一些缺点：
私有环境下需要外部负载均衡器支持 与NodePort结合的方式依然占用节点端口且需要维护负载节点的更新 LoadBalancer提供的是四层负载，负载模式支持有限，且每个服务都需要创建外部负载均衡器，开销大且影响架构灵活性 LoadBalancer方案局限性大，实际私有环境中也不推荐使用。
Ingress：
Ingress是Kubernetes提供的一种资源，Ingress方案支持七层负载，完成了网络出口层与Service层的解耦，配合第三方的Ingress控制器和负载均衡器能够实现灵活强大的负载控制，Ingress控制器监控Ingress资源，将Ingress资源声明的规则刷入负载均衡器中。外部请求进入负载均衡器后，负载均衡器根据配置规则将请求转发到相应的Service，再由Service转发到相应的Pod。
Ingress是Kubernetes推荐的网络入口方案。但其存在众多的实现方案，需要根据实际需求选择合适的方案。
2.3.3.2 Ingress方案选型 基于Kubernetes Ingress的入口方案都能够解析标准的Ingress资源，它们之间的区别在于Ingress控制器和后端的负载均衡器，Ingress方案通常将Ingress控制器和负载均衡器合二为一，习惯性统称为Ingress控制器，Ingress控制器以Pod的方式提供服务。部分Ingress方案还会提供增强的API网关支持。
多种Ingress控制器在集群中是可以并存使用的，甚至可以配合使用，为Ingress控制器提供Ingress服务以实现Ingress控制器的负载均衡。但根据Kubernetes集群的用途以及具体应用的场景需求，依然需要为整个集群或特定应用选择合适的Ingress控制器。
主流的Ingress控制器都满足开源，动态服务发现，SSL终止，WebSocket支持等特性，除此之外，我们将主要从以下几个方面对各种Ingress控制器进行对比：
协议支持：控制器后端负载均衡器是否支持常用网络通信协议包括HTTP，HTTPS，gRPC，TCP，UDP等 后端负载：控制器后端使用的负载均衡器是各不相同的，对其有所了解总是更好的 流量路由：将流量路由到特定服务的匹配规则以及是否支持正则匹配 命名空间限制：控制器是否支持跨命名空间的流量管理 容错与韧性：控制器是否支持对服务实例进行状态检查，是否提供重试和断路器 负载均衡算法：控制器支持哪些负载均衡算法 认证方式：控制器支持哪些认证方式 流量分配：控制器是否支持常用的流量分配机制，如金丝雀部署，A/B测试，镜像等 付费订阅：控制器是否带有扩展功能或技术支持的付费版本 图形界面：控制器是否搭配图形界面 GWT验证：控制器是否有内置的JSON Web令牌验证 链路跟踪：控制器是否支持通过OpenTracing或其他方式进行链路请求的监视跟踪和调试 WAF支持：控制器是否支持Web应用程序防火墙 DDOS保护：控制器是否能够识别异常请求或基于地址，白名单等提供DDOS保护机制 Lua支持：控制器是否支持Lua扩展 主流的Ingress方案功能特性对比如下：
上表中Kubernetes Ingress是Kubernetes社区官方的Nginx Ingress Controller，它成熟易用，并提供了足以满足大多数场景的出色功能，是最简单直接的选择；表中Nginx Ingress是Nginx官方的Nginx Ingress Controller，其性能更高服务更可靠，但限制较大，缺乏流量分配功能，商业版需要付费；Traefik支持丰富的功能，提供了许多微服务方面的支持，支持动态配置，但控制器的高可用需要单独的key-value数据库；F5 BIGIP是稳定可靠的商业解决方案，更能支持全面，但其使用的负载均衡器是昂贵的F5负载均衡硬件，且运维成本高，也不支持链路追踪；HAproxy支持丰富的负载均衡算法，支持动态配置，性能稳定；Kong Ingress拥有丰富的插件集，支持动态配置；基于Envoy的解决方案用于最丰富的功能集，Ambassador被称为Kubernetes原生API微服务网关，Istio Ingress目前已被IstioGateway取代。
目前社区最热门的解决方案是Kubernetes Ingress，Istio和Traefik。Kubernetes Ingress提供出色而够用的功能，Istio是服务网格最热门的项目，Traefik在基础Kubernetes Ingress功能之外，提供了强大的API Gateway功能。
2.3.3.3 Istio Gateway Istio是广受欢迎的开源服务网格实现，能够为应用提供动态流量管理，网络策略控制，网络安全认证，链路追踪治理等众多网络增强功能，很好的补齐了Kubernetes在微服务治理上的不足。
Istio中包含一个可选的Gateway组件，用于代替Istio Ingress作为新的网络入口解决方案，不同于Kubernetes Ingress，Istio Gateway是一个独立于平台的抽象，配合VirtualService支持4-7层负载，跳过了Kubernetes的Ingress和Service，能够直接将外部访问流量转发到目标Pod。Istio Gateway在集群中以Pod的方式运行，与其他应用Pod一样接受Istio控制平面的统一管理。
Istio Gateway几乎能够实现基于Kubernetes Ingress的入口方案的所有功能，同时支持大量Istio带来的增强功能：
HTTP、gRPC、WebSocket、TCP流量的自动负载均衡 细粒度的流量路由控制，包含丰富的路由控制、重试、故障转移和故障注入 可插拔的访问控制策略层，支持ACL、请求速率限制，请求配额和流量计费 集群内度量指标，日志和调用链的自动收集，管理集群的入口、出口流量 使用基于身份的认证和授权方式来管理服务间通信的安全 结合API Gateway以支持更多特定应用的API网关控制功能 但相比基于Kubernetes Ingress的入口方案，Istio Gateway需要依赖整个Istio系统，丰富的网络控制需要复杂的配置管理，且需要在Pod中注入Sidecar，这会增加些微的请求延迟，带来网络性能损耗（几乎可忽略不计）。
Istio更多是倾向于为微服务提供治理支持，并不是为了取代Kubernetes Ingress，Kubernetes Ingress方案和Istio在集群中是可以并存的，Istio允许只对特定的命名空间或应用生效，可以根据应用的实际情况选择相应的网络出口方案。
2.4 存储优化 Kubernetes内置多种存储插件（In-tree插件），同时允许对接独立存储插件（Out-of-tree插件），提供了非常丰富的存储支持，并且通过**持久卷（PersistentVolume）**子系统对各种存储资源进行抽象，为集群提供了统一的存储API。优化存储有助于确保现有存储资源以高效的方式工作，特定存储配合特定应用也能够为应用提供更好的数据持久化服务，避免不必要的问题。
2.4.1 存储类型 Kubernetes中可用的存储类型包括以下三类:
存储类型 描述 例子 Block(块存储) 在操作系统中作为块设备
也称为存储区域网络（SAN）
适用于需要完全控制存储并绕过文件系统的低层直接操作文件的应用程序
不可共享，每次只有一个客户端可以挂载这种类型的端点 AWS EBS
Ceph RBD File(文件存储) 在操作系统中作为要挂在的文件系统导出
也称为网络附加存储（NAS）
不同协议实现和厂商并行性，延迟，文件锁定机制等可能差异较大
可以有多个客户端共享访问 RHEL NFS
NetApp NFS Object(对象存储) 通过REST API端点访问
应用程序必须在应用或容器中构建其驱动程序
适用于非结构化数据存储需求
可以有多个客户端共享访问 AWS S3 Kubernetes通过In-tree存储插件原生支持主流块存储和文件存储的挂载，对象存储要求容器应用通过API访问或者开发Out-of-tree插件（Flexvolume或CSI方式）进行对接。
主流块存储支持持久卷动态置备，但文件存储需要依赖独立的驱动插件实现，如Redhat的NFS Provisioner和NetApp的Trident。
2.4.2 存储选型 不同的存储类型均有其适用和推荐的应用场景，容器云平台应同时对接这三种类型的存储系统，以便容器化应用能够进行最佳的存储选择。
以下是三种存储在不同应用场景下的适配情况：
存储类型 多只读 多读写 镜像仓 扩展镜像仓 指标 日志 应用 Block 支持 不支持 可用 不可用 推荐 推荐 推荐 File 支持 支持 可用 可用 可用 可用 推荐 Object 支持 支持 推荐 推荐 不可用 不可用 不可用 由于存储系统本身都会实现数据的高可用架构，因此除非现实需要，应用端通常无需考虑存储数据的多副本问题。
镜像仓：代表非结构化数据存储的应用场景： 首选存储技术是对象存储，其次块存储。存储技术不需要支持RWX（多读写）访问模式 存储技术必需保证读写一致性，不推荐使用任何NAS存储 hostPath本地卷的形式不推荐用于生产环境 扩展镜像仓：提供多副本支持，要求存储数据共享： 首选存储技术是对象存储。存储技术必需支持RWX（多读写）访问模式，且必需保证读写一致性 数据共享需求不能使用块存储（除非通过NAS中转） 大量非结构化数据的存储不推荐NAS存储 指标：代表无需共享的结构化数据存储的应用场景： 首选存储技术是块存储。不推荐使用RWX（多读写）访问模式 NAS文件存储在实际测试中可能造成大量无法恢复的数据破坏问题，不建议使用 结构化数据不应使用对象存储，指标引擎（Prometheus等）也不会对接对象存储API 日志：代表日志类统计分析需求高的大数据存储的应用场景： 首选存储技术是块存储 日志类型数据不建议使用NAS存储 应用：不同应用的存储选型依应用的业务需求，技术选型，资源复用等因素的不同而不同，如： Kubernetes集群etcd数据库为了更高的可靠性，应首选使用具有最低一致性延迟的存储技术 RDBMS，NoSQL DB等数据库应用倾向于使用专用的块存储来获得最好的性能 2.3.4 存储编排 Rook是为Kubernetes提供的的开源云原生存储编排系统，它提供了平台，框架和对各种存储解决方案的支持，以与云原生环境进行本地集成。Rook目前提供Ceph，Minion，NFS，EdegeFS，CockroachDB和YugabyteDB等多种存储系统支持，涵盖了全部三种存储类型。
Rook把分布式存储软件转化为自我管理、自我调节和自我修复的存储服务。它通过自动执行存储管理员的任务来实现这一目标，执行的任务包括部署、引导、配置、供应、调节、升级、迁移、灾难恢复、监测和资源管理。此外，Rook还能充分利用底层云原生容器管理、调度和编排平台的强大功能来履行其职责
Rook专为Kubernetes及其它不断演进的云原生环境而设计，它充分利用扩展点，为调度、生命周期管理、资源管理、安全、监测，以及用户体验提供了无缝体验。其优点包括：
在商用硬件上运行软件定义存储
文件、块和对象存储呈现
超大规模和超融合存储选项
可以轻松纵向扩展的弹性存储
零接触管理
带有快照、克隆和版本管理的集成数据保护
3 业务稳定性保障 平台是为业务服务的，保证容器云平台集群的稳定性固然重要，运行在平台上的大量具体业务应用的稳定性保障更是重中之重。对于非容器化应用，保障业务应用的健壮可靠和持续可用通常需要借助单独的集群和负载工具甚至庞大的第三方监控平台,自动化平台等外围系统，应用和基础设施环境的异构性通常导致整个应用稳定性保障体系变得复杂而混乱，维护开销巨大。
容器和容器镜像技术将应用打包成通用镜像并以容器化方式运行，打破了应用和系统环境的异构壁垒，使得应用的打包部署变得简单便捷通用。以Kubernetes为代表的容器云平台充分利用容器化的优势，进一步对应用屏蔽服务器，网络和存储等基础环境的异构性，并集成多种应用服务保障机制，为业务应用的稳定性保驾护航。
在Kubernetes中，业务应用是以容器的方式运行，并以Pod(一组密切相关的容器)作为基本调度单位的。为了保证Pod正常的运行和对外服务，Kubernetes集成了负载均衡，健康检查，服务质量，弹性伸缩，变更策略等平台级服务保障机制，Kubernetes平台上的应用不再需要依赖额外的工具或系统保障业务的稳定性，当然传统的稳定性保障方案依然适用于Kubernetes容器云环境，但建议考虑其必要性。
3.1 负载均衡 负载均衡既能分摊应用节点的服务压力，又能保障应用的不间断服务，是最典型的应用稳定性保障手段。Kubernetes在设计之初就充分考虑了针对容器的服务发现与负载均衡机制，提供了Service资源，并通过kube-proxy配合cloud provider来适应不同的应用场景。Kubernetes的后续更新中又在此基础上产生了一些新的负载均衡机制。
目前kubernetes中主要的负载均衡机制及其应用场景如下：
负载均衡 应用场景 Service 使用Service提供cluster内部的负载均衡，借助cloud provider提供的LB提供外部访问 Ingress Controller 使用Service提供cluster内部的负载均衡，通过自定义LB提供外部访问 Service Load Balancer load balancer直接运行在容器中，实现Bare Metal的Service Load Balancer Custom Load Balancer 自定义负载均衡，并替代kube-proxy，一般在物理部署Kubernetes时使用，方便接入已有的外部服务 3.1.1 Service Service是对一组提供相同功能的Pod的抽象，并为它们提供一个统一的虚IP入口。借助Service，应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service通过标签来选取服务后端，一般配合Replication Controller或者Deployment来保证后端容器的正常运行。
在 Kubernetes 中创建一个新的 Service 对象需要两大模块同时协作，其一是控制器，它需要在每次客户端创建新的 Service 对象时，生成用于暴露一组 Pod 的 Kubernetes 对象，也就是 Endpoint 对象；其二是 kube-proxy，它运行在 Kubernetes 集群中的每一个节点上，会监听API Server，根据 Service 和 Endpoint 的变动改变节点上 iptables 或者 ipvs 中保存的规则，利用这些规则进行高效的流量转发。
Service利用iptables或ipvs的路由转发规则提供的概率路由机制(&ndash;probability)将对Service 虚IP的访问概率性路由到某个真正的后端Pod上，实现应用服务的负载均衡。
Kubernetes的kube-proxy支持三种代理模式: userspace，iptables，ipvs。其中userspace模式在用户态处理流量转发，效率相对较低，iptables和ipvs是Linux内核特性，可以直接在内核态完成转发，效率更高。目前默认的代理模式是iptables，而ipvs相比iptables的遍历式规则匹配，使用了更高效的哈希表匹配，在大量Service导致大量的路由转发规则的情况下性能更优，而且支持更多的负载均衡算法，未来可能成为默认模式。
在 Iptables 模式下，kube-proxy 通过在目标 node 节点上的 Iptables 中的 NAT 表的 PREROUTIN 和 POSTROUTING 链中创建一系列的自定义链 (这些自定义链主要是”KUBE-SERVICE”链， “KUBE-POSTROUTING”链，每个服务对应的”KUBE-SVC-XXXXXX”链和”KUBE-SEP-XXXX”链)，然后通过这些自定义链对流经到该 Node 的数据包做 DNAT 和 SNAT 操作从而实现路由，利用Iptables的概率路由机制(&ndash;probability)将对Service 虚IP的访问概率性路由到某个真正的后端Pod上，实现应用服务的负载均衡。
Service主要有以下几种类型：
ClusterIP：默认类型，自动分配一个仅cluster内部可以访问的虚拟IP NodePort：在ClusterIP基础上为Service在每台机器上绑定一个端口，这样就可以通过:NodePort来访问该服务 LoadBalancer：在NodePort的基础上，借助cloud provider创建一个外部的负载均衡器，并将请求转发到:NodePort Headless Service：不分配ClusterIP，直接通过service域名或者指定的域名(ExternalName)关联到后端Pod或者其他服务上 service还与kubernetes内置的dns组件coredns配合使用提供了服务发现支持。
3.1.2 Ingress Controller Service虽然解决了服务发现和负载均衡的问题，但它在使用上还是有一些限制，比如对外访问的时候，NodePort类型需要在外部搭建额外的负载均衡，而LoadBalancer要求kubernetes必须跑在支持的cloud provider上面。
Ingress就是为了解决这些限制而引入的新资源，主要用来将服务暴露到集群之外，并且可以自定义服务的访问策略。Ingress并不会取代Service，而是作用于Service之上，将外部请求代理或转发到对应的Service上，再由Service向下转发。比如想要通过负载均衡器实现不同子域名到不同服务的访问：
Ingress本身只是一种API资源，需要配合ingress controller使用，ingress controller会通过API Server监听Ingress资源并根据Ingress定义自动更新负载均衡器的规则文件。负载均衡器并非集群组件，可以运行在集群内部或外部，可以是硬件负载也可以是软负载，软负载通常将ingress controller和负载均衡器整合在一个容器中提供服务。目前Kubernetes上主流的ingress controller有Nginx Ingress Controller，Traefik，HAProxy Ingress，F5 BIGIP，Istio Ingress等。其中Nginx Ingress Controller是推荐方案，可以根据实际需要进行选择。
3.1.3 Service Load Balancer 在Ingress出现以前，Service Load Balancer是推荐的解决Service局限性的方式。Service Load Balancer将haproxy跑在容器中，并监控service和endpoint的变化，通过容器IP对外提供4层和7层负载均衡服务。
社区提供的Service Load Balancer支持四种负载均衡协议：TCP、HTTP、HTTPS和SSL TERMINATION，并支持ACL访问控制。
3.1.4 Custom Load Balancer 虽然Kubernetes提供了丰富的负载均衡机制，但在实际使用的时候，还是会碰到一些复杂的场景是它不能支持的，比如：
接入已有的负载均衡设备 多租户网络情况下，容器网络和主机网络是隔离的，这样kube-proxy就不能正常工作 这个时候就可以自定义组件，并代替kube-proxy来做负载均衡。基本的思路是监控kubernetes中service和endpoints的变化，并根据这些变化来配置负载均衡器。比如weave flux、nginx plus、kube2haproxy等。
3.2 健康检查 Kubernetes提供了一整套对于Pod的状态机制和生命周期管。对于Pod的健康检查，Kubernetes默认只检查容器是否正常运行。但容器运行不代表容器内的应用仍可对外提供服务，因此Kubernetes通过Probe(探针)机制提供更准确的健康检查。健康检查为应用提供了故障自动恢复能力，从容器和容器内应用两个层面保证了应用的稳定性。
3.2.1 Pod生命周期 Pod的本质是一组容器，Pod的状态便是容器状态的体现和概括，同时容器的状态变化会影响Pod的状态变化，触发Pod的生命周期阶段转换。Pod 的运行阶段（phase）是 Pod 在其生命周期中的简单宏观概述。该阶段并不是对容器或 Pod 的综合汇总，也不是为了做为综合状态机。Pod的生命周期分为以下几个阶段:
挂起（Pending）：Pod 已被 Kubernetes 系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod 的时间和通过网络下载镜像的时间，这可能需要花点时间 运行中（Running）：该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态 成功（Succeeded）：Pod 中的所有容器都被成功终止，并且不会再重启 失败（Failed）：Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止 未知（Unknown）：因为某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败 Pod 有一个PodStatus对象，其中包含一个PodCondition数组。 PodCondition包含以下以下字段：
lastProbeTime：Pod condition最后一次被探测到的时间戳 lastTransitionTime：Pod最后一次状态转变的时间戳 message：状态转化的信息，一般为报错信息，例如：containers with unready status: [c-1] reason：最后一次状态形成的原因，一般为报错原因，例如：ContainersNotReady status：包含的值有 True、False 和 Unknown type：Pod状态的几种类型 其中type字段包含以下几个值：
PodScheduled：Pod已经被调度到运行节点 Ready：Pod已经可以接收请求提供服务 Initialized：所有的init container已经成功启动 Unschedulable：无法调度该Pod，例如节点资源不够 ContainersReady：Pod中的所有容器已准备就绪 3.3.2 重启策略 当Pod中的容器出现正常或异常退出时，Kubernetes会根据Pod指定的重启策略(restartPolicy)决定处理动作和Pod状态转换，重启策略有以下三种：
Always: 总是尝试重启容器。让Pod保持正常Running状态。无论Pod中几个容器出现正常或异常退出 OnFailure: 只有Pod中的任意容器出现异常退出时才尝试重启容器，让Pod保持正常Running状态.当Pod中所有容器均正常退出时，Pod进入Succeeded状态 Never: 永不尝试重启容器，只要Pod还存在一个运行状态的容器，Pod就保持在Running状态，否则Pod根据容器是正常或异常退出而相应进入Succeeded或Failed状态 可以管理Pod的控制器有Replication Controller，Job，DaemonSet，及kubelet（静态Pod）。
RC和DaemonSet：必须设置为Always，需要保证该容器持续运行。 Job：OnFailure或Never，确保容器执行完后不再重启。 kubelet：在Pod失效的时候重启它，不论RestartPolicy设置为什么值，并且不会对Pod进行健康检查。 3.2.3 Probe机制 容器的健康状态和容器内应用的健康状态并不总是一致的，容器正常运行时，容器内的应用可能由于阻塞，内部错误等原因无法正常处理请求，或者由于应用尚未初始化完成而无法正常接受请求。异常为了提供更精确的健康检查，Kubernetes提供了**Probe(探针)**机制。
Probe分为三种:
Liveness Probe: 存活探针，指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且容器将受到其重启策略的影响。如果容器不提供存活探针，则默认状态为 Success ReadinessProbe：就绪探针，指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟之前的就绪状态默认为 Failure。如果容器不提供就绪探针，则默认状态为 Success StartupProbe: 启动探针, 对于在第一次初始化时可能需要额外启动时间的附加应用程序可以使用启动探针, 一旦验证完成就交由存活探针接管 Probe支持以下三种检查方法:
ExecAction: 在容器中执行指定的命令进行检查，当命令执行成功（返回码为0），检查成功 TCPSocketAction：对于容器中的指定TCP端口进行检查，当TCP端口被占用，检查成功 HTTPGetAction: 发生一个HTTP请求，当返回码介于200~400之间时，检查成功 Probe只是检查容器或应用的健康状态，Pod是否会重启由重启策略根据检查结果进行控制。
如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活探针; kubelet 将根据 Pod 的restartPolicy 自动执行正确的操作。
如果希望容器在探测失败时被杀死并重新启动，那么需要指定存活探针，并指定restartPolicy 为 Always 或 OnFailure。
如果要仅在探测成功时才开始向 Pod 发送流量，那么需要指定就绪探针。在这种情况下，就绪探针可能与存活探针相同，但是 spec 中的就绪探针的存在意味着 Pod 将在没有接收到任何流量的情况下启动，并且只有在探针探测成功后才开始接收流量。
如果希望容器能够自行维护，可以指定一个就绪探针，该探针检查与存活探针不同的端点。
3.3 服务质量 为了实现资源被有效调度和分配的同时提高资源利用率，Kubernetes针对不同服务质量的预期，通过 QoS（Quality of Service）来对 pod 进行服务质量管理。对于一个pod来说，服务质量体现在两个具体的指标：CPU和内存。当节点上内存资源紧张时，kubernetes会根据预先设置的不同QoS类别进行相应处理。
3.3.1 服务质量级别 QoS主要分为Guaranteed、Burstable和Best-Effort三级，优先级从高到低。可以通过kubectl describe命令或者在Pod的status字段查看其QoS级别。
3.3.1.1 Guaranteed 属于该级别的pod有以下两种：
Pod中的所有容器都且仅设置了 CPU 和内存的 limits pod中的所有容器都设置了 CPU 和内存的 requests 和 limits ，且单个容器内的requests==limits（requests不等于0） 若容器指定了requests而未指定limits，则limits的值等于节点resource的最大值；若容器指定了limits而未指定requests，则requests的值等于limits。因此两种情况本质上是一种。
pod中的所有容器都且仅设置了limits：
1 2 3 4 5 6 7 8 9 10 11 containers: name: foo resources: limits: cpu: 10m memory: 1Gi name: bar resources: limits: cpu: 100m memory: 100Mi pod 中的所有容器都设置了 requests 和 limits，且单个容器内的requests==limits：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 containers: name: foo resources: limits: cpu: 10m memory: 1Gi requests: cpu: 10m memory: 1Gi name: bar resources: limits: cpu: 100m memory: 100Mi requests: cpu: 100m memory: 100Mi 容器foo和bar内resources的requests和limits均相等，该pod的QoS级别属于Guaranteed。
3.3.1.2 Burstable pod中只要有一个容器的requests和limits的设置不相同，该pod的QoS即为Burstable。
容器foo指定了resource，而容器bar未指定：
1 2 3 4 5 6 7 8 9 10 11 containers: name: foo resources: limits: cpu: 10m memory: 1Gi requests: cpu: 10m memory: 1Gi name: bar 容器foo设置了内存limits，而容器bar设置了CPU limits：
1 2 3 4 5 6 7 8 9 10 containers: name: foo resources: limits: memory: 1Gi name: bar resources: limits: cpu: 100m 3.3.1.3 Best-Effort 如果Pod中所有容器的resources均未设置requests与limits，该pod的QoS即为Best-Effort。
容器foo和容器bar均未设置requests和limits：
1 2 3 4 5 containers: name: foo resources: name: bar resources: 3.3.2 内存资源回收策略 Kubernetes 通过cgroup给Pod设置QoS级别，由于CPU是可抢占式资源，而内存是不可抢占的，也就是说CPU资源不足不会导致Pod被杀死，而内存资源不足会。当内存资源不足时先杀死优先级低的Pod。
3.3.2.1 OOM评分 容器本质上是宿主机上的进程，在实际使用过程中，通过OOM分数值(score)来区分Pod优先级，OOM分数值范围为0-1000。OOM分数值根据OOM_ADJ参数计算得出。
对于Guaranteed级别的Pod，OOM_ADJ参数设置成了**-998**，对于Best-Effort级别的Pod，OOM_ADJ参数设置成了1000，对于Burstable级别的Pod，OOM_ADJ参数取值从2到999。
对于Kuberntes保留资源，比如kubelet，docker，OOM_ADJ参数设置成了**-999**，表示不会被OOM杀死。OOM_ADJ参数设置的越大，计算出来的OOM分数越高，表明该Pod优先级就越低，当出现资源竞争时会越早被杀死，对于OOM_ADJ参数是-999的表示Kubernetes永远不会因为OOM将其杀死。
3.3.2.2 资源回收顺序 内存资源不足时三类Pod资源的回收顺序:
Best-Effort pods：系统用完了全部内存时，该类型pods会最先被杀死 Burstable pods：系统用完了全部内存，且没有 Best-Effort 类型的容器可以被杀死时，该类型的pods会被杀死 Guaranteed pods：系统用完了全部内存，且没有 Burstable 与 Best-Effort 类型的容器可以被杀死时，该类型的pods会被杀死 3.3.3 CPU资源管理策略 默认情况下，kubelet 使用CFS 配额(Linux内核CPU调度)来执行Pod的CPU约束。当节点上运行了很多CPU密集的Pod时，工作负载可能会迁移到不同的CPU核心，这取决于调度时Pod是否被扼制，以及哪些CPU核心是可用的。许多工作负载对这种迁移不敏感，因此无需任何干预即可正常工作。
然而，有些工作负载的性能明显地受到CPU缓存亲和性以及调度延迟的影响，对此，kubelet提供了可选的CPU管理策略，来确定节点上的一些分配偏好。
CPU管理器（CPU Manager作为 alpha 特性引入 Kubernetes 1.8 版本。从 1.10 版本开始，作为beta特性默认开启。
CPU管理策略通过kubelet参数--cpu-manager-policy来指定。支持两种策略：
none: 默认策略，表示现有的调度行为 static: 允许为节点上具有某些资源特征的Pod 赋予增强的CPU亲和性和独占性 CPU管理器定期通过CRI写入资源更新，以保证内存中CPU分配与cgroupfs一致。同步频率通过新增的kubelet配置参数--cpu-manager-reconcile-period来设置。 如果不指定，默认与--node-status-update-frequency的周期相同。
3.3.3.1 None策略 None策略显式地启用现有的默认CPU亲和方案，不提供操作系统调度器默认行为之外的亲和性策略。 通过CFS配额来实现Guaranteed pods的CPU使用限制。
3.3.3.2 Static策略 Static策略针对具有整数型CPU requests的Guaranteed Pod ，它允许该类Pod中的容器访问节点上的独占CPU资源。这种独占性是使用cpuset cgroup控制器来实现的。
该策略管理一个共享CPU资源池，最初，该资源池包含节点上所有的CPU资源。可用的独占性 CPU 资源数量等于节点的CPU总量减去通过--kube-reserved或--system-reserved参数保留的CPU。
从1.17版本开始，CPU保留列表可以通过 kublet 的 –reserved-cpus参数显式地设置。 通过 –reserved-cpus指定的显式CPU列表优先于使用 –kube-reserved和–system-reserved参数指定的保留CPU。 通过这些参数预留的CPU是以整数方式，按物理内核ID升序从初始共享池获取的。
共享池是BestEffort和Burstable pod 运行的CPU集合。Guaranteed pod中的容器，如果声明了非整数值的CPU requests，也将运行在共享池的CPU上。只有Guaranteed pod 中，指定了整数型CPU requests的容器，才会被分配独占 CPU 资源。
当Guaranteed pod调度到节点上时，如果其容器符合静态分配要求，相应的CPU会被从共享池中移除，并放置到容器的cpuset中，这种静态分配增强了CPU亲和性，减少了CPU密集的工作负载在节流时引起的上下文切换。
诸如容器运行时和kubelet本身的系统服务可以继续在这些独占CPU上运行。独占性仅针对其他Pod。
CPU管理器不支持运行时下线和上线CPUs。此外，如果节点上的在线CPUs集合发生变化，则必须驱逐节点上的pods，并通过删除kubelet根目录中的状态文件cpu_manager_state来手动重置CPU管理器。
当启用static策略时，要求使用--kube-reserved 和/或 --system-reserved 或 --reserved-cpus来保证预留的CPU值大于零。 这是因为零预留CPU值可能使得共享池变空。
由此可见，Kubernetes在提供应用稳定性保障的同时如果资源充足，也考虑到生产实际情况提供了灵活的资源配额和优先级策略。如果资源充足，可将Pod的QoS类型均设置为Guaranteed。用计算资源换业务性能和稳定性，减少排查问题时间和成本。如果想更好的提高资源利用率，业务服务可以设置为Guaranteed，而其他服务根据重要程度可分别设置为Burstable或Best-Effort。
3.3 弹性伸缩 在实际的应用部署过程中，应用的容量规划和实际负载之间往往是存在落差的，对于业务应用的请求数量在不同时段或不同时期往往存在明显的波峰波谷现象。一方面实际负载难以预料，另一方面如果只按照波峰请求规划容量则难免存在资源浪费，而低于波峰请求的容量规划又可能导致应用节点资源利用率过高，影响应用服务的稳定性。
通常解决方案是根据实际负载进行应用容量的扩缩容。在Kubernetes平台中就为Pod提供了水平自动伸缩（Horizontal Pod Autoscaling，HPA）的特性。HPA可以根据Pod的CPU利用率（或其他应程序提供的度量指标custom metrics）自动伸缩一个Replication Controller、Deployment 或者Replica Set中的Pod数量（或者基于一些应用程序提供的度量指标，目前这一功能处于alpha版本），保证应用的稳定性。这一特性无法适用与DaemonSets这一无法缩放的对象。
此外Kubernetes还实验性的提供了垂直自动伸缩（Vertical Pod Autoscaler，VPA）特性，它允许根据Pod使用的资源指标自动调整Pod的CPU和内存的requests值。这一特性目前尚不成熟，自动伸缩过程中会导致Pod重启，且不能和HPA一起工作，实际环境中建议使用HPA。
本节弹性伸缩主题将只讨论HPA。
3.3.1 工作机制 Pod水平自动伸缩特性由Kubernetes API资源和控制器实现。资源决定了控制器的行为。 控制器会周期性的获取平均CPU利用率，并与目标值相比较后来调整replication controller或deployment中的副本数量。
Pod水平自动伸缩的实现是一个控制循环，由controller manager的--horizontal-pod-autoscaler-sync-period参数指定周期（默认值为15秒）。
每个周期内，controller manager根据每个HorizontalPodAutoscaler定义中指定的指标查询资源利用率。
通常情况下，控制器将从一系列的聚合API（metrics.k8s.io、custom.metrics.k8s.io和external.metrics.k8s.io） 中获取指标数据。 metrics.k8s.io API 通常由metrics-server（需要额外启动）提供。
目前在 Kubernetes 中，可以针对replication controllers或deployment执行滚动升级（rolling update），它们会管理底层副本数。 Pod 水平缩放只支持deloyment，也就是说不能将Horizontal Pod Autoscaler绑定到某个replication controller再执行滚动升级（例如使用 kubectl rolling-update 命令），因为Horizontal Pod Autoscaler无法绑定到滚动升级时创建的新副本。
3.3.2 伸缩算法 从最基本的角度来看，Pod水平自动缩放控制器跟据当前指标和期望指标来计算缩放比例。
1 期望副本数 = ceil[当前副本数 * ( 当前指标 / 期望指标 )] 例如，当前指标为200m，目标设定值为100m,那么由于200.0 / 100.0 == 2.0， 副本数量将会翻倍。 如果当前指标为50m，副本数量将会减半，因为50.0 / 100.0 == 0.5。 如果计算出的缩放比例接近1.0（跟据--horizontal-pod-autoscaler-tolerance 参数全局配置的容忍值，默认为0.1）， 将会放弃本次缩放。
如果HorizontalPodAutoscaler指定的是targetAverageValue 或 targetAverageUtilization， 那么将会把指定Pod的平均指标做为currentMetricValue。 然而，在检查容忍度和决定最终缩放值前，我们仍然会把那些无法获取指标的pod统计进去。
所有被标记了删除时间戳(Pod正在关闭过程中)的Pod和 失败的Pod都会被忽略。
如果某个Pod缺失指标信息，它将会被搁置，只在最终确定缩值时再考虑。
当使用CPU指标来缩放时，任何还未就绪（例如还在初始化）状态的Pod或最近的指标为就绪状态前的Pod， 也会被搁置。
由于受技术限制，Pod水平缩放控制器无法准确的知道pod什么时候就绪， 也就无法决定是否暂时搁置 Pod。 --horizontal-pod-autoscaler-initial-readiness-delay 参数（默认为30s），用于设置Pod准备时间， 在此时间内的Pod统统被认为未就绪。 --horizontal-pod-autoscaler-cpu-initialization-period参数（默认为5分钟），用于设置pod的初始化时间， 在此时间内的Pod，CPU资源指标将不会被采纳。
在排除掉被搁置的Pod后，缩放比例就会跟据currentMetricValue / desiredMetricValue计算出来。
如果有任何Pod的指标缺失，我们会更保守地重新计算平均值， 在需要缩小时假设这些Pod消耗了目标值的 100%， 在需要放大时假设这些pod消耗了0%目标值。 这可以在一定程度上抑制伸缩的幅度。
此外，如果存在任何尚未就绪的Pod，我们可以在不考虑遗漏指标或尚未就绪的Pods的情况下进行伸缩， 我们保守地假设尚未就绪的Pods消耗了试题指标的0%，从而进一步降低了伸缩的幅度。
在缩放方向（缩小或放大）确定后，我们会把未就绪的Pod和缺少指标的Pod考虑进来再次计算使用率。 如果新的比率与缩放方向相反，或者在容忍范围内，则跳过缩放。 否则，我们使用新的缩放比例。
如果创建HorizontalPodAutoscaler时指定了多个指标， 那么会按照每个指标分别计算缩放副本数，取最大的进行缩放。 如果任何一个指标无法顺利的计算出缩放副本数（比如，通过API获取指标时出错）， 那么本次缩放会被跳过。
最后，在HPA控制器执行缩放操作之前，会记录缩放建议信息（scale recommendation）。 控制器会在操作时间窗口中考虑所有的建议信息，并从中选择得分最高的建议。 这个值可通过kube-controller-manager服务的启动参数 --horizontal-pod-autoscaler-downscale-stabilization 进行配置， 默认值为5min。 这个配置可以让系统更为平滑地进行缩容操作，从而消除短时间内指标值快速波动产生的影响。
当使用Horizontal Pod Autoscaler管理一组副本缩放时， 有可能因为指标动态的变化造成副本数量频繁的变化，有时这被称为 抖动。--horizontal-pod-autoscaler-downscale-stabilization: 这个 kube-controller-manager 的参数表示缩容冷却时间。 即自从上次缩容执行结束后，多久可以再次执行缩容，默认时间是5分钟(5m0s)。
3.3.3 度量指标 在Kubernetes 1.6支持了基于多个指标进行缩放。 你可以使用 autoscaling/v2beta2 API 来为Horizontal Pod Autoscaler指定多个指标。HorizontalPodAutoscaler将会依次考量各个指标。 HorizontalPodAutoscaler将会计算每一个指标所提议的副本数量，然后最终选择一个最高值。
Horizontal Pod Autoscaler支持三种度量指标：
资源度量指标（resource metric）: HPA默认使用的度量指标，这一指标默认度量Pod的CPU利用率，另外也可以选择度量内存占用
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion: autoscaling/v2alpha1 kind: HorizontalPodAutoscaler metadata: name: php-apache namespace: default spec: scaleTargetRef: apiVersion: apps/v1beta1 kind: Deployment name: php-apache minReplicas: 1 maxReplicas: 10 metrics: - type: Resource resource: name: cpu targetAverageUtilization: 50 Pod度量指标（pod metric）: 一种自定义度量指标，这些指标从某一方面描述了Pod，在不同Pod之间进行平均，并通过与一个目标值比对来确定副本的数量
1 2 3 4 type: Pods pods: metricName: packets-per-second targetAverageValue: 1k 对象度量指标（object metric）: 一种自定义度量指标，这些度量指标用于描述一个在相同名字空间(namespace)中的其他对象。 请注意这些度量指标用于描述这些对象，并非从对象中获取。对象度量指标并不涉及平均计算
1 2 3 4 5 6 7 8 type: Object object: metricName: requests-per-second target: apiVersion: extensions/v1beta1 kind: Ingress name: main-route targetValue: 2k 3.3.4 弹性伸缩示例 本节将以一个php-apache服务器为例展示HPA弹性伸缩如何使用。
部署和运行php-apache服务器并将其暴露为Kubernetes服务
1 kubectl run php-apache --image=gcr.io/google_containers/hpa-example --requests=cpu=200m --expose --port=80 创建Horizontal Pod Autoscaler
1 2 3 4 # 创建一个HPA基于cpu利用率为50%为指标控制Pod的副本数量在1到10之间 kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10 # 查看HPA kubectl get hpa 增加负载
1 2 3 4 5 6 7 8 # 运行负载容器 kubectl run -i --tty load-generator --image=busybox /bin/sh # 容器内运行负载脚本 $ while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done # 查看HPA kubectl get hpa --watch # 查看deployment kubectl get deployment php-apache 停止负载
1 2 3 4 5 # 在负载容器busybox终端中输入&lt;Ctrl> + C终止负载的产生 # 查看HPA kubectl get hpa # 查看deployment kubectl get deployment php-apache 3.4 变更策略 应用通常是需要持续维护和更新的，应用在更新维护时根据变更策略的不同会对应用的服务可用性和服务质量产生不同的影响，同时也对应用的运行环境和资源占用提出了不同的要求。
在对应用服务稳定性，资源环境约束和业务场景需求等多方因素进行权衡后，选择合适的的变更策略是非常重要的。Kubernetes中提供了几种不同的应用变更策略以应对不同的需求：
recreate：重建，停止旧版本后部署新版本 rolling-update：滚动更新，以顺序更新的方式发布新版本 blue/green：蓝绿发布，新版本与旧版本共存并进行流量切换 canary：金丝雀发布，将新版本先面向部分用户发布，然后逐步完成全量发布 a/b testing：A/B测试，以精确的方式（HTTP头部，cookie，权重等）向部分用户发布新版本。A/B测是一种基于数据统计做出业务决策的技术，并不是Kubernetes支持的原生策略，需要依赖诸如Istio，Linkerd，Traefik等高级组件实现。 3.4.1 重建 重建（recreate）策略会终止应用所有正在运行的实例，然后用新的版本重新创建和运行应用。
1 2 3 4 spec: replicas: 3 strategy: type: Recreate 重建策略是一个虚拟部署，它意味着服务的停机时间取决于应用程序的关闭和启动持续时间。
3.4.2 滚动更新 滚动更新（rolling-update）策略通过逐个替换实例来逐步部署新版本的应用，直到所有实例都被替换完成为止。它通常遵循以下过程：在负载均衡器后面使用版本 A 的实例池，然后部署版本 B 的一个实例，当服务准备好接收流量时(Readiness Probe 正常)，将该实例添加到实例池中，然后从实例池中删除一个版本 A 的实例并关闭，如此循环直到全部更新完成。
1 2 3 4 5 6 7 spec: replicas: 3 strategy: type: RollingUpdate rollingUpdate: maxSurge: 2 # 一次可以添加多少个Pod maxUnavailable: 1 # 滚动更新期间最大多少个Pod不可用 滚动更新过程中新版本出现问题可以通过kubectl rollout进行回滚。但该策略新旧版本的实例替换相对较慢，无法控制访问流量。
3.4.3 蓝绿发布 蓝绿发布（blue/green）策略与滚动更新不同，新旧版本一起发布和运行，在测试新版本满足要求后，然后Kubernetes中扮演负载均衡器角色的 Service 对象，通过替换 label selector 中的版本标签来将流量发送到新版本，也可以通过Ingress控制器完成流量控制。
1 2 3 selector: app: my-app version: v1.0.0 蓝绿发布策略能够实现实时部署和回滚，不存在新旧版本同时可用的问题。但这种方式短时间内需要两倍的资源占用，新版本应事先通过良好的测试以保证上线后尽量不影响用户体验。
3.4.4 金丝雀发布 金丝雀发布（canary）策略让部分用户访问到新版本应用，在Kubernetes中，可以使用两个具有相同Pod标签的Deployment来实现金丝雀部署。新版本的副本和旧版本的一起发布。在一段时间后如果没有检测到错误，则可以扩展新版本的副本数量并删除旧版本的应用。
Kubernetes默认通过为新旧版本的副本设置不同的数量实现按照百分比控制流量导向。如需更精确的控制策略，则建议使用A/B测试策略。
1 2 3 4 5 spec: replicas: 9 --- spec: replicas: 1 金丝雀发布策略与滚动更新策略一样是新旧版本共存的，这种方式能够快速回滚，方便错误和性能监控，能够对流量作出更精准的控制。但发布较慢，高精度的流量控制意味着更多的资源浪费，控制策略也过于单一。
3.4.5 A/B测试 A/B测试（a/b testing）策略实际上是一种基于统计信息而非部署策略来制定业务决策的技术，与业务结合非常紧密。但是它们也是相关的，也可以使用金丝雀发布来实现。
除了基于权重在版本之间进行流量控制之外，A/B测试还可以基于一些其他参数（比如Cookie、User Agent、地区等等）来精确定位给定的用户群，该技术广泛用于测试一些功能特性的效果，然后按照效果来进行确定。要使用这些细粒度的控制，建议使用Istio，可以根据权重或HTTP头等来动态请求路由控制流量转发。
1 2 3 4 5 6 7 route: - tags: version: v1.0.0 weight: 90 - tags: version: v2.0.0 weight: 10 A/B测试测允许多版本并行运行，支持多样化的流量控制策略，能够完全控制流量的分配。但特定的访问错误难以排查，需要分布式链路跟踪，此外它不是Kubernetes原生支持的。
发布应用有许多种方法，当发布到开发/测试环境的时候，重建或者滚动更新通常是一个不错的选择。在生产环境，滚动更新或者蓝绿发布比较合适，但是新版本的提前测试是非常有必要的。如果你对新版本的应用不是很有信心的话，那应该使用金丝雀发布，将用户的影响降到最低。最后，如果你的公司需要在特定的用户群体中进行新功能的测试，例如，移动端用户请求路由到版本A，桌面端用户请求路由到版本B，那么你就应该使用A/B测试，借助Istio等服务网格（service mesh）系统，可以根据某些请求参数来确定用户应路由的服务。
Kubernetes提供了丰富的机制保证了业务应用在各个生命周期的服务稳定性，除此之外，还有一个重要的为业务应用稳定性保驾护航的机制，那就是监控告警，Kubernetes内置的监控组件heapster需要配合inflexdb和grafana等第三方工具，在1.12版本后已经废弃，目前主流的Kubernetes容器云监控告警方案是Prometheus+Alert Manager。这方面的内容将在单独章节中进行介绍。
4 本章总结 容器云是一个庞大而复杂的基础设施平台，本章从API设计实现，到平台组件和插件管理，再到业务应用维护，详细介绍了API兼容性和扩展性，平台参数调优，架构优化和插件选型，以及业务应用的高效运行和平滑升级等众多与容器云稳定性息息相关的内容。除此之外，还有很多内容没有涉及到，也有更多经验需要在实际的集群维护中总结挖掘。实践出真知，只有在实践中验证他人方案的有效性，也只有在实践中去发现更多的容器云需要优化，可以优化的地方。
当前容器云蓬勃发展，云原生生态圈日益壮大，随着已有技术的不断成熟，以及云原生项目的逐渐落地，容器云稳定性相关的产品和方案将会越来越成熟，越来越多的最佳实践将为容器云的平稳运行保驾护航。同时新领域，新技术的不断汇入也会为容器云的维护带来更多的挑战，让我们砥砺前行，期待容器云的光明未来。</content></entry><entry><title>日常运维手记</title><url>https://xshrim.github.io/post/%E6%97%A5%E5%B8%B8%E8%BF%90%E7%BB%B4%E6%89%8B%E8%AE%B0/</url><categories><category>ops</category></categories><tags><tag>ops</tag><tag>运维</tag></tags><content type="html"> 运维命令 进程信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 查看进程基本信息 ps -fp &lt;pid> ps aux | grep &lt;pid> # 进程跟踪 strace -p &lt;pid> gdb -p &lt;pid> # 查看进程打开文件 lsof -p &lt;pid> # 查看进程中线程资源占用 ps -mp &lt;pid> -o THREAD,tid,time # jstack &lt;pid> > log printf "%x" &lt;tid> # 查看进程cpu用量 pidstat -p &lt;pid> -u 1 # 查看进程内存用量 pidsta -p &lt;pid> -r 1 # 查看进程磁盘用量 pidsta -p &lt;pid> -d 1 系统信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # 查看cpu top -n 1 vmstat -n 2 3 mpstat -P ALL 2 # 查看内存 free -h # 查看磁盘读写性能 iostat -d -x -k 1 1 # 查看网络 ifconfig ifstat 1 ip a ip r # 查看目录下大文件 find ./ -type f -size +1G -print0|xargs -0 du -sh # 查看系统日志 cat /var/log/messages journalctl -b # 查看内核日志 dmesg -T journalctl -k # 按服务/进程/用户查看日志 journalctl --no-pager # 不分页 journalctl -n 20 # 近20条 journalctl -f # 持续监控日志输出 journalctl -u httpd -o json-pretty # 指定输出格式 journalctl -u httpd.service --since yesterday journalctl _UID=33 httpd.service --since "20 min ago" journalctl _PID=8088 httpd.service --since 09:00 --until "1 hour ago" # 查看dns服务器域名 dig @dnsserver -t AXFR &lt;domain> # 查看日志文件中指定时间段内容 sed -n "/2021-08-12 10:20:01/,/2021-08-12 10:30:01/p" &lt;logfile> # 使用nmon进行系统监控和分析 nmon -f result.nmon -t -s 30 -c 100 # 可以使用nmon analyzer或者nmon visualizer对文件可视化分析 网络信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # 跟踪网络 traceroute google.com mtr -r -c 50 google.com # 域名解析 host baidu.com nslookup -type=mx baidu.com 8.8.8.8 dig @8.8.8.8 baidu.com CNAME dig -p 5533 @8.8.8.8 baidu.com # 指定dnsserver端口 dig baidu.com +trace # 跟踪解析 dig -x 8.8.8.8 # 反向解析 dig baidu.com +short # 简化输出 # 主机探测 ping &lt;ip> nc -zv -w 1 &lt;ip> &lt;port> echo -e '\035\nquit' | telnet &lt;ip> &lt;port> nmap -p &lt;port-range> &lt;ip> # 端口扫描 nmap -vv &lt;ip> # 详细输出 namp -sP &lt;ip> # ping扫描 nmap -traceroute &lt;ip> # 路由跟踪 nmap -sP 192.168.0.1/24 # 地址段扫描 nmap -O &lt;ip> # 操作系统探测 nmap -A &lt;ip> # 万能开关扫描 # api检测 curl -ksvIL http://&lt;ip>:&lt;port>/&lt;path> # 查看tcp连接概览 netstat -nat |awk '{print $6}'|sort|uniq -c|sort -rn netstat -n | awk '/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}' netstat -n | awk '/^tcp/ {++state[$NF]}; END {for(key in state) print key,"\t",state[key]}' netstat -n | awk '/^tcp/ {++arr[$NF]};END {for(k in arr) print k,"\t",arr[k]}' netstat -n |awk '/^tcp/ {print $NF}'|sort|uniq -c|sort -rn netstat -ant | awk '{print $NF}' | grep -v '[a-z]' | sort | uniq -c # 查找较多time_wait连接 netstat -n|grep TIME_WAIT|awk '{print $5}'|sort|uniq -c|sort -rn|head -n20 # 找查较多的SYN连接 netstat -an | grep SYN | awk '{print $5}' | awk -F: '{print $1}' | sort | uniq -c | sort -nr | more # 查找请求数前20的IP netstat -anlp|grep 80|grep tcp|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -nr|head -n20 netstat -ant |awk '/:80/{split($5,ip,":");++A[ip[1]]}END{for(i in A) print A[i],i}' |sort -rn|head -n20 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F"." '{print $1"."$2"."$3"."$4}' | sort | uniq -c | sort -nr |head -20 # 根据端口列出进程 netstat -ntlp | grep 80 | awk '{print $7}' | cut -d/ -f1 # ss命令 ss -t -a # tcp连接 ss -u -a # udp连接 ss -s # socket摘要 ss -l # 打开的端口 ss -pl # 进程端口 ss -o state established '( dport = :smtp or sport = :smtp )' # 建立的smtp连接 ss -o state established '( dport = :http or sport = :http )' # 建立的http连接 ss -4 state &lt;state> # 指定状态的ipv4连接(established,syn-sent,syn-recv,fin-wait-1,fin-wait-2,time-wait,closed,close-wait,last-ack,listen,closing ss dst &lt;ip>:&lt;protocal> # 过滤连接(dst,src) ss dst 192.168.1.5 ss dst 192.168.119.113:http ss dst 192.168.119.113:smtp ss dst 192.168.119.113:443 日志分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 获得访问前10位的ip地址 cat access.log|awk '{print $1}'|sort|uniq -c|sort -nr|head -10 cat access.log|awk '{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}' # 访问次数最多的文件或页面,取前20 cat access.log|awk '{print $11}'|sort|uniq -c|sort -nr|head -20 # 列出传输最大的几个exe文件（分析下载站的时候常用） cat access.log |awk '($7~/\.exe/){print $10 " " $1 " " $4 " " $7}'|sort -nr|head -20 # 列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数 cat access.log |awk '($10 > 200000 &amp;&amp; $7~/\.exe/){print $7}'|sort -n|uniq -c|sort -nr|head -100 # 如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面 cat access.log |awk '($7~/\.php/){print $NF " " $1 " " $4 " " $7}'|sort -nr|head -100 # 列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat access.log |awk '($NF > 60 &amp;&amp; $7~/\.php/){print $7}'|sort -n|uniq -c|sort -nr|head -100 # 列出传输时间超过 30 秒的文件 cat access.log |awk '($NF > 30){print $7}'|sort -n|uniq -c|sort -nr|head -20 # 统计网站流量（G) cat access.log |awk '{sum+=$10} END {print sum/1024/1024/1024}' # 统计404的连接 awk '($9 ~/404/)' access.log | awk '{print $9,$7}' | sort # 统计http status. cat access.log |awk '{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}' cat access.log |awk '{print $9}'|sort|uniq -c|sort -rn # 蜘蛛分析查看是哪些蜘蛛在抓取内容 tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E 'bot|crawler|slurp|spider' # 按域统计流量 zcat squid_access.log.tar.gz| awk '{print $10,$7}' |awk 'BEGIN{FS="[ /]"}{trfc[$4]+=$1}END{for(domain in trfc){printf "%s\t%d\n",domain,trfc[domain]}}' 抓包分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 tcpdump -i any tcpdump net 192.168.1.0/24 tcpdump -i eth0 -vnn host 172.16.1.122 tcpdump -i eth0 -vnn net 172.16.1.0/24 tcpdump -i eth0 -vnn portrange 22-50 tcpdump -i eth0 -vnn udp tcpdump -i eth0 -vnn icmp tcpdump -i eth0 -vnn arp tcpdump -i eth0 -vnn ip tcpdump -i any -nn "ip[16] == 10" tcpdump -i any -nn "ip[16] == 192 and ip[17] == 168 and ip[18] == 1 and ip[19] > 9 and ip[19] &lt; 101" tcpdump -i eth0 -vnn src host 172.16.1.122 tcpdump -i eth0 -vnn dst host 172.16.1.122 tcpdump -i eth0 -vnn src port 22 tcpdump -i eth0 -vnn src host 172.16.1.253 and dst port 22 tcpdump -i eth0 -vnn src host 172.16.1.122 or port 22 tcpdump -i eth0 -vnn src host 172.16.1.122 and not port 22 tcpdump -i eth0 -vnn "src host 172.16.1.59 and dst port 22" or " src host 172.16.1.68 and dst port 80 " tcpdump –i eth0 -vnn -w /tmp/fill.cap -c 100 tcpdump –i eth0 -vnn -r /tmp/fill.cap tcp tcpdump –i eth0 -vnn -r /tmp/fill.cap host 172.16.1.58 # tcpdump -i eth0 "((tcp) and (port 80) and ((dst host 10.10.1.254) or (dst host 10.10.1.200)))" tcpdump -i eth0 -vn dst host foo.bar tcpdump -i eth0 host foo.bar and not port 80 and not port 25 tcpdump -i eth0 "tcp[(tcp[12]>>2):4] = 0x47455420" tcpdump -i eth0 "tcp[20:2]=0x4745 or tcp[20:2]=0x4854" tcpdump -s 0 -A "tcp dst port 80 and tcp[((tcp[12:1] &amp; 0xf0) >> 2):4] = 0x47455420" tcpdump -s 0 -A "tcp dst port 443 and (tcp[((tcp[12:1] &amp; 0xf0) >> 2):4] = 0x504f5354)" tcpdump -i any -s 0 -A "tcp dst port 80 or tcp dst port 443 and tcp[((tcp[12:1] &amp; 0xf0) >> 2):4] = 0x47455420 or tcp[((tcp[12:1] &amp; 0xf0) >> 2):4] = 0x504F5354" and host 192.168.10.1 tcpdump -i any -s 0 -nnvvvXS -A "tcp dst port 8000 and tcp[((tcp[12:1] &amp; 0xf0) >> 2):4] = 0x47455420" tcpdump -i eth0 "tcp[(tcp[12]>>2):4] = 0x5353482D" tcpdump -i eth0 "tcp[((tcp[12:1] &amp; 0xf0) >> 2):4] = 0x48545450 &amp;&amp; tcp[((tcp[12:1] &amp; 0xf0) >> 2) + 4:2] = 0x2f31 &amp;&amp; tcp[((tcp[12:1] &amp; 0xf0) >> 2) + 6:1] = 0x2e" tcpdump -i eth0 udp dst port 53 tcpdump -i eth0 tcp tcpdump -i eth0 "ip[2:2] > 600" tcpdump -i eth0 "tcp[0:2] > 1024" tcpdump -i eth0 "tcp[tcpflags] &amp; (tcp-syn|tcp-ack) != 0" tcpdump -i any -s 0 -v -n -l | egrep -i "POST / | GET / | Host:" tcpdump -i any -s 0 -A -n -l | egrep -i "POST /|pwd=|passwd=|password=|Host:" tcpdump -i any -nn -A -s0 -l | egrep -i "Set-Cookie|Host:|Cookie:" tcpdump -vvAls0 | grep "User-Agent:" time tcpdump -nn -i eth0 "tcp[tcpflags] = tcp-syn" -c 10000 > /dev/null tcpdump -i any -nn -c 10000 port 443 > tcpdump.log cat tcpdump.log | awk "{print $3}" | awk -F "." "{print $1"."$2"."$3"."$4}" | sort | uniq -c | sort -rn nohup tcpdump -i eth0 port 22 -s0 -G 3600 -Z root -w ssh22_%Y_%m%d_%H%M_%S.pcap &amp; 数据库分析 1 2 # 查看数据库执行的sql /usr/sbin/tcpdump -i eth0 -s 0 -l -w - dst port 3306 | strings | egrep -i 'SELECT|UPDATE|DELETE|INSERT|SET|COMMIT|ROLLBACK|CREATE|DROP|ALTER|CALL' 容器分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 查看docker信息 docker info # 查看镜像构建 docker history --no-trunc &lt;mid> # 查看容器信息 docker inspect &lt;cid> docker inspect --format='{{.LogPath}}' &lt;cid> # 指定查看的内容 docker inspect --format='{{range .NetworkSettings.Networks}}{{.MacAddress}}{{end}}' &lt;cid> # 指定查看的内容 # 查看容器资源占用 docker top &lt;cid> # 查看容器内进程资源占用 docker stats &lt;cid> # 查看docker资源占用 docker system df -v # 查看容器内大文件 find /var/lib/docker/overlay2/ -type f -size +1G -print0|xargs -0 du -sh JVM分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 查看当前机器上所有运行的java进程及参数信息 jps -lvm # 查看指定的jvm进程所有的属性设置和配置参数 jinfo &lt;pid> # 查看某个pid进程对应的应用程序内存占用情况 jmap -heap &lt;pid> # 获取堆概要信息 jmap -histo &lt;pid> # 打印堆内类实例统计信息 jcmd &lt;pid> -all GC.class_histogram # 等同上条 jmap -histo:live &lt;pid> # 只打印类实例存活对象 jcmd &lt;pid> GC.class_histogram # 等同上条 jmap -F -dump:format=b,file=&lt;filepath> # dump堆信息到指定文件 jcmd &lt;pid> GC.heap_dump -all &lt;filepath> # 等同上条 jmap -dump:live,format=b,file=&lt;filepath> # 只dump存活对象 jcmd &lt;pid> GC.heap_dump &lt;filepath> # 等同上条 # 查看进程所包含所有线程的Java堆栈信息 jstak -l &lt;pid> # 打印锁信息 jcmd &lt;pid> Thread.print -l # 等同上条 jstack -F &lt;pid> # 强制打印到标准输出 # 实时监测系统资源占用与jvm运行情况 jstat -class -t &lt;pid> 1000 5 # 类加载 jstat -gc -t &lt;pid> 1000 5 # 垃圾回收 jstat -gcutil -t &lt;pid> 1000 5 # 垃圾回收 # 以GUI的方式更直观化呈现jvm进程的实时情况 jconsole 运维工具 Ansible 基于python的无agent自动化运维工具
基本用法 安装相关 1 2 3 4 5 6 7 8 9 10 11 12 yum -y install epel-release yum list all *ansible* yum info ansible yum -y install ansible # 使用帮助 ansible-doc -l # 列出ansible所有的模块 ansible-doc -s MODULE_NAME # 查看指定模块具体适用 # 免密配置 ssh-keygen -t rsa ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.10.149 ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.10.113 ssh-copy-id -i /root/.ssh/id_rsa.pub root@127.0.0.1 配置文件 1 2 3 4 /etc/ansible/ansible.cfg # 主配置文件 /etc/ansible/hosts # Inventory主机清单(与主配置格式相同) /usr/bin/ansible-doc # 帮助文件 /usr/bin/ansible-playbook # 指定运行任务文件 ansible.cfg参数
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 一般连接 ansible_ssh_host # 用于指定被管理的主机的真实IP ansible_ssh_port # 用于指定连接到被管理主机的ssh端口号, 默认是22 ansible_ssh_user # ssh连接时默认使用的用户名 # 特定ssh连接 ansible_connection # ssh连接的类型: local, ssh, paramiko, 在ansible 1.2之前默认是paramiko, 后来智能选择, 优先使用基于ControlPersist的ssh ansible_ssh_pass # ssh连接时的密码 ansible_ssh_private_key_file # 秘钥文件路径, 如果不想使用ssh-agent管理秘钥文件时可以使用此选项 ansible_ssh_executable # 如果ssh指令不在默认路径当中, 可以使用该变量来定义其路径 # 特权升级 ansible_become # 相当于ansible_sudo或者ansible_su, 允许强制特权升级 ansible_become_user # 通过特权升级到的用户, 相当于ansible_sudo_user或者ansible_su_user ansible_become_pass # 提升特权时, 如果需要密码的话, 可以通过该变量指定, 相当于ansible_sudo_pass或者ansible_su_pass ansible_sudo_exec # 如果sudo命令不在默认路径, 需要指定sudo命令路径 # 远程主机环境参数 ansible_shell_executable # 设置目标机上使用的shell, 默认为/bin/sh ansible_python_interpreter # 用来指定python解释器的路径, 默认为/usr/bin/python同样可以指定ruby 、perl的路径 ansible_*_interpreter # 其他解释器路径, 用法与ansible_python_interpreter类似, 这里"*"可以是ruby或才perl等其他语言 Inventory主机清单配置
INI格式
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 给服务器分组, 组名只能用 [a-zA-Z0-9_] # 直接指定登录凭证 [database] 10.1.1.1 ansible_ssh_port=22 ansible_ssh_user="root" ansible_ssh_pass="redhat" 10.1.1.2 ansible_ssh_port=22 ansible_ssh_user="root" ansible_ssh_pass="redhat" [clusterA] # 指定一个数字范围 192.168.1.1[01:50] [clusterB] # 指定一个字母表范围 worker[01:30].k8s.local worker-[a:h].k8s.local # 主机组嵌套 [kubernetes:children] clusterA clusterB # kubernetes组的公用参数 [kubernetes:vars] ntp_server=ntp.svc.local proxy=proxy.svc.local foo=bar # 变量名foo, 值bar, 由组内成员共享 ansible_connection=network_cli # 2.5版本后推出新的连接方式, 代替provider ansible_network_os=ios # 告知ansible是基于ios的系统 ansible_ssh_port=22 # ssh端口 ansible_ssh_user=root # ssh用户 ansible_ssh_pass="cisco" # ssh密码 [app] # 给服务器指定别名（git）, 通过关键字参数指定其他参数 git ansible_host=git.svc.local ansible_port=225 ansible_ssh_private_key_file=&lt;path/to/git-server-ssh> # 使用指定的账号密码（危险！） tester ansible_host=tester.svc.local ansible_user=root ansible_password=xxx YAML模式
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 --- database: hosts: 192.168.1.1[01:50] k8s_cluster: hosts: # 没有别名的服务器 worker[01:30].k8s.local: worker-[a:h].k8s.local: vars: # 公共的参数 ntp_server: ntp.svc.local proxy: proxy.svc.local app: hosts: git: # 服务器别名 ansible_host: git.svc.local # 如果未定义, 默认以别名为host.(即git) ansible_port: 225 ansible_ssh_private_key_file: &lt;path/to/git-server-ssh> tester: ansible_host: tester.svc.local ansible_user: root ansible_password: xxx # 危险!尽量不要写明文密码 命令说明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 语法: ansible &lt;host-pattern> [arguments] [-f forks] [-m module_name] [-a args] &lt;host-pattern> 这次命令对哪些主机生效的 inventory group name ip all &lt;arguments> -a MODULE_ARGS, --args=MODULE_ARGS # module arguments # 指定执行模块使用的参数 --ask-vault-pass # ask for vault password # 加密playbook文件时提示输入密码 -B SECONDS, --background=SECONDS # run asynchronously, failing after X seconds(default=N/A) # 后台运行超时时间, 异步运行, X秒之后失败 -C, --check # don't make any changes; instead, try to predict some of the changes that may occur # 模拟执行, 不会真正在机器上执行(查看执行会产生什么变化) -D, --diff # when changing (small) files and templates, show the differences in those files; works great with --check # 当更新的文件数及内容较少时, 该选项可显示这些文件不同的地方, 该选项结合-C用会有较好的效果 -e EXTRA_VARS, --extra-vars=EXTRA_VARS # set additional variables as key=value or YAML/JSON # 执行命令时添加额外参数变量 -f FORKS, --forks=FORKS # specify number of parallel processes to use(default=5) # 并行任务数. FORKS被指定为一个整数, 默认是5 -h, --help # show this help message and exit # 打开帮助文档API -i INVENTORY, --inventory-file=INVENTORY # specify inventory host path(default=/etc/ansible/hosts) or comma separated host list. # 指定要读取的Inventory文件 -l SUBSET, --limit=SUBSET # further limit selected hosts to an additional pattern # 限定执行的主机范围 --list-hosts # outputs a list of matching hosts; does not execute anything else # 列出执行匹配到的主机, 但并不会执行 -m MODULE_NAME, --module-name=MODULE_NAME # module name to execute (default=command) # 指定执行使用的模块, 默认使用 command -M MODULE_PATH, --module-path=MODULE_PATH # specify path(s) to module library (default=None) # 要执行的模块的路径 --new-vault-password-file=NEW_VAULT_PASSWORD_FILE # new vault password file for rekey # 新vault密码文件 -o, --one-line # condense output #压缩输出, 摘要输出. 尝试一切都在一行上输出 --output=OUTPUT_FILE #output file name for encrypt or decrypt; use - for stdout # 输出文件 -P POLL_INTERVAL, --poll=POLL_INTERVAL # set the poll interval if using -B (default=15) # 设置轮询间隔, 每隔数秒. 需要- B --syntax-check # perform a syntax check on the playbook, but do not execute it # 检查Playbook中的语法书写 -t TREE, --tree=TREE # log output to this directory # 将日志内容保存在该输出目录,结果保存在一个文件中在每台主机上 --vault-password-file=VAULT_PASSWORD_FILE # vault password file # vault密码文件 -v, --verbose # verbose mode (-vvv for more, -vvvv to enable connection debugging) # 执行详细输出 --version # show program's version number and exit # 显示版本 Connection Options: control as whom and how to connect to hosts -k, --ask-pass # ask for connection password # 要求输入连接密码 --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE # use this file to authenticate the connection # ssh连接私钥文件 -u REMOTE_USER, --user=REMOTE_USER # connect as this user (default=None) # 指定远程主机以USERNAME运行命令 -c CONNECTION, --connection=CONNECTION # connection type to use (default=smart) # 指定连接方式, 可用选项paramiko (SSH)、ssh、local, local方式常用于crontab和kickstarts -T TIMEOUT, --timeout=TIMEOUT # override the connection timeout in seconds(default=10) # ssh连接超时时间设定, 默认10s --ssh-common-args=SSH_COMMON_ARGS # specify common arguments to pass to sftp/scp/ssh (e.g.ProxyCommand) # ssh通用参数 --sftp-extra-args=SFTP_EXTRA_ARGS # specify extra arguments to pass to sftp only (e.g. -f, -l) # sftp额外参数 --scp-extra-args=SCP_EXTRA_ARGS #specify extra arguments to pass to scp only (e.g. -l) # scp额外参数 --ssh-extra-args=SSH_EXTRA_ARGS # specify extra arguments to pass to ssh only (e.g. -R) # ssh额外参数 Privilege Escalation Options: control how and which user you become as on target hosts -s, --sudo # run operations with sudo (nopasswd) (deprecated, use become) # 相当于Linux系统下的sudo命令 -U SUDO_USER, --sudo-user=SUDO_USER # desired sudo user (default=root) (deprecated, use become) # 使用sudo, 相当于Linux下的sudo命令 -S, --su # run operations with su (deprecated, use become) # su模式运行(过时, 请使用become) -R SU_USER, --su-user=SU_USER # run operations with su as this user (default=root) (deprecated, use become) # su模式使用的用户(过时, 使用become) -b, --become # run operations with become (does not imply password prompting) # su模式运行 --become-method=BECOME_METHOD # privilege escalation method to use (default=sudo),valid choices: [ sudo | su | pbrun | pfexec | doas |dzdo | ksu | runas ] # su模式方法 --become-user=BECOME_USER # run operations as this user (default=root) # su模式使用的用户 --ask-sudo-pass # ask for sudo password (deprecated, use become) # 要求输入sudo密码 --ask-su-pass # ask for su password (deprecated, use become) # 要求输入su密码(过时, 使用become) -K, --ask-become-pass # ask for privilege escalation password # 要求输入su密码 &lt;modules> ping: 检查指定节点机器是否还能连通 raw: 执行原始的命令, 而不是通过模块子系统 yum: RedHat和CentOS的软件包安装和管理工具 apt: Ubuntu/Debian的软件包安装和管理工具 pip : 用于管理Python库依赖项, 为了使用pip模块, 必须提供参数name或者requirements synchronize: 使用rsync同步文件, 将主控方目录推送到指定节点的目录下 template: 基于模板方式生成一个文件复制到远程主机进行文档内变量的替换的模块 copy: 在远程主机执行复制操作文件 user 与 group: 请求useradd, userdel, usermod, groupadd, groupdel, groupmod service 或 systemd: 用于管理远程主机的服务 get_url: 该模块主要用于从http、ftp、https服务器上下载文件(类似于wget) fetch: 它用于从远程机器获取文件, 并将其本地存储在由主机名组织的文件树中 file: 主要用于远程主机上的文件操作 lineinfile: 远程主机上的文件编辑模块 unarchive模块: 用于解压文件 command: 用于在各被管理节点运行指定的命令, 不支持特殊字符 shell: 用于在各被管理节点运行指定的命令, 支持特殊字符 hostname: 修改远程主机名的模块 script: 在远程主机上执行主控端的脚本, 相当于scp+shell组合 stat: 获取远程文件的状态信息, 包括atime,ctime,mtime,md5,uid,gid等信息 cron: 远程主机crontab配置 mount: 挂载文件系统 find: 帮助在被管理主机中查找符合条件的文件, 就像 find 命令一样 selinux: 远程管理受控节点的selinux的模块 &lt;samples> ansible 192.168.10.113 -m ping ansible -i hosts webserver -m command -a 'date' ansible all -m copy -a 'src=/root/foo dest=/root/bar' 常用模块用法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 command 命令模块(默认模块)用于在远程主机执行命令, 不能使用变量, 管道等 # ansible all -a 'date' cron 计划任务 month 指定月份 minute 指定分钟 job 指定任务 day 表示那一天 hour 指定小时 weekday 表示周几 state 表示是添加还是删除 present: 安装 absent: 移除 # ansible webserver -m cron -a 'minute="*/10" job="/bin/echo hello" name="test cron job"' #不写默认都是*, 每个任务都必须有一个名字 # ansible webserver -a 'crontab -l' # ansible webserver -m cron -a 'minute="*/10" job="/bin/echo hello" name="test cron job" state=absent' #移除任务 user 用户账号管理 name 用户名 uid uid state 状态 group 属于哪个组 groups 附加组 home 家目录 createhome 是否创建家目录 comment 注释信息 system 是否是系统用户 # ansible all -m user -a 'name="user1"' # ansible all -m user -a 'name="user1" state=absent' group 组管理 gid gid name 组名 state 状态 system 是否是系统组 # ansible webserver -m group -a 'name=mysql gid=306 system=yes' # ansible webserver -m user -a 'name=mysql uid=306 system=yes group=mysql' copy 复制文件(复制本地文件到远程主机的指定位置) src 定义本地源文件路径 dest 定义远程目录文件路径(绝对路径) owner 属主 group 属组 mode 权限 content 取代src=,表示直接用此处的信息生成为文件内容 # yum -y install libselinux-python # ansible all -m copy -a 'src=/etc/fstab dest=/tmp/fstab.ansible owner=root mode=640' # ansible all -m copy -a 'content="hello ansible\nHi ansible" dest=/tmp/test.ansible' file 设置文件的属性 path|dest|name 对那个文件做设定 创建文件的符号链接: src: 指定源文件 path: 指明符号链接文件路径 # ansible all -m file -a 'owner=mysql group=mysql mode=644 path=/tmp/fstab.ansible' # ansible all -m file -a 'path=/tmp/fstab.link src=/tmp/fstab.ansible state=link' ping 测试指定主机是否能连接 # ansible all -m ping service 管理服务运行状态 enabled 是否开机自动启动 name 指定服务名 state 指定服务状态 started 启动服务 stoped 停止服务 restarted 重启服务 arguments 服务的参数 # ansible webserver -m service -a 'enabled=true name=httpd state=started' shell 在远程主机上运行命令 尤其是用到管道变量等功能的复杂命令 # ansible all -m shell -a 'echo magedu | passwd --stdin user1' script 将本地脚本复制到远程主机并运行之 # ansible all -m script -a '/tmp/test.sh' yum 安装程序包 name 程序包名称(不指定版本就安装最新的版本latest) state present,latest表示安装, absent表示卸载 # ansible webserver -m yum -a 'name=httpd' # ansible all -m yum -a 'name=ntpdate' #默认就是安装 # ansible all -m yum -a 'name=ntpdate state=absent' setup 收集远程主机的facts 每个被管理节点在接受并运行管理命令之前, 会将自己主机相关信息, 如操作系统版本, IP地址等报告给远程的ansible主机 # ansible all -m setup 高级用法 yaml YAML介绍 YAML是一个可读性高的用来表达资料序列的格式. YAML参考了其它多种语言, 包括: XML、C语言、Python、Perl以及电子邮件格式RFC2822等. ClarkEvans在2001年首次发表了这种语言, 另外Ingy dot Net与Oren Ben-Kiki也是这语言的共同设计者
YAML Ain&rsquo;t Markup Language,即YAML不是XML, 不过, 在开发这种语言时, YAML的意思其实是: &ldquo;Yet Another Markup Language&rdquo;(仍是一种标记语言), 其特性:
YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强, 扩展性好 更多的内容及规范参见http://www.yaml.org
YAML语法 YAML的语法和其他高阶语言类似, 并且可以简单表达清单、散列表、标量等数据结构, 其结构(structure)通过空格来展示, 序列(sequence)里的项用"-&ldquo;来表示, Map里面的键值对用&rdquo;:&ldquo;分割, 下面是一个示例
1 2 3 4 5 6 7 8 9 10 11 12 13 14 name: john smith age: 41 gender: male spouse: name:jane smith age:37 gender: female children: - name:jimmy smith age:17 gender: male - name:jenny smith age: 13 gender: female YAML文件扩展名通常为.yaml, 如example.yaml
list
列表的所有元素均使用&rdquo;-&ldquo;打头, 例如:
1 2 3 4 5 # A list of testy fruits - Apple - Orange - Strawberry - Mango dictionary
字典通过key与value进行标识, 例如:
1 2 3 4 5 --- # An employee record name: Example Developer job: Developer skill: Elite 也可以将key:value放置于{}中进行表示, 例如:
1 2 3 --- #An exmloyee record {name: Example Developer, job: Developer, skill: Elite} 基础元素 变量 变量命名
变量名仅能由字母、数字和下划线组成, 且只能以字母开头
facts
facts是由正在通信的远程目标主机发回的信息, 这些信息被保存在ansible变量中. 要获取指定的远程主机所支持的所有facts, 可使用如下命令进行:
1 ansible hostname -m setup register
把任务的输出定义为变量, 然后用于其他任务, 实例如下:
1 2 3 4 tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True 通过命令行传递变量
在运行playbook的时候也可以传递一些变量供playbook使用, 示例如下:
1 ansible-playbook test.yml --extra-vars "hosts=www user=mageedu" 通过roles传递变量
当给一个主机应用角色的时候可以传递变量, 然后在角色内使用这些变量, 示例如下:
1 2 3 4 - hosts: webserver roles: - common - {role: foo_app_instance, dir: '/web/htdocs/a.com', port: 8080} Inventory ansible的主要功用在于批量主机操作, 为了便捷的使用其中的部分主机, 可以在inventory file中将其分组命名, 默认的inventory file为/etc/ansible/hosts
inventory file可以有多个, 且也可以通过Dynamic Inventory来动态生成
inventory文件格式
inventory文件遵循INI文件风格, 中括号中的字符为组名. 可以将同一个主机同时归并到多个不同的组中；此外, 当如若目标主机使用非默认的SSH端口, 还可以在主机名称之后使用冒号加端口号来表明
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ntp.magedu.com [webserver] www1.magedu.com:2222 www2.magedu.com [dbserver] db1.magedu.com db2.magedu.com db3.magedu.com 如果主机名遵循相似的命名模式, 还可使用列表的方式标识个主机, 例如: [webserver] www[01:50].example.com [databases] db-[a:f].example.com 主机变量
可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用, 例如:
1 2 3 [webserver] www1.magedu.com http_port=80 maxRequestsPerChild=808 www2.magedu.com http_port=8080 maxRequestsPerChild=909 组变量
组变量是指赋予给指定组内所有主机上的在playbook中可用的变量. 例如:
1 2 3 4 5 6 7 [webserver] www1.magedu.com www2.magedu.com [webserver:vars] ntp_server=ntp.magedu.com nfs_server=nfs.magedu.com 组嵌套
inventory中, 组还可以包含其它的组, 并且也可以向组中的主机指定变量. 不过, 这些变量只能在ansible-playbook中使用, 而ansible不支持. 例如:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 [apache] httpd1.magedu.com httpd2.magedu.com [nginx] ngx1.magedu.com ngx2.magedu.com [webserver:children] #固定格式 apache nginx [webserver:vars] ntp_server=ntp.magedu.com inventory参数
ansible基于ssh连接inventory中指定的远程主机时, 还可以通过参数指定其交互方式, 这些参数如下所示:
1 2 3 4 5 6 7 8 9 ansible_ssh_host ansible_ssh_port ansible_ssh_user ansible_ssh_pass ansible_sudo_pass ansible_connection ansible_ssh_private_key_file ansible_shell_type ansible_python_interpreter 条件测试 如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试.
when语句
在task后添加when字句即可使用条件测试；when语句支持jinja2表达式语句, 例如:
1 2 3 4 tasks: - name: 'shutdown debian flavored system" command: /sbin/shutdown -h now when: ansible_os_family == "Debian" when语句中还可以使用jinja2的大多"filter&rdquo;,例如果忽略此前某语句的错误并基于其结果(failed或success)运行后面指定的语句, 可使用类似如下形式:
1 2 3 4 5 6 7 8 9 10 tasks: - command:/bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped 此外, when语句中还可以使用facts或playbook中定义的变量
1 2 3 4 5 6 7 8 9 # cat cond.yml - hosts: all remote_user: root vars: - username: user10 tasks: - name: create {{ username }} user user: name={{ username }} when: ansible_fqdn == "node1.exercise.com" 迭代 当有需要重复性执行的任务时, 可以使用迭代机制. 其使用格式为将需要迭代的内容定义为item变量引用, 并通过with_items语句来指明迭代的元素列表即可. 例如:
1 2 3 4 5 - name: add server user user: name={{ item }} state=persent groups=wheel with_items: - testuser1 - testuser2 上面语句的功能等同于下面的语句:
1 2 3 4 - name: add user testuser1 user: name=testuser1 state=present group=wheel - name: add user testuser2 user: name=testuser2 state=present group=wheel 事实上, with_items中可以使用元素还可为hashes, 例如:
1 2 3 4 5 - name: add several users user: name={{ item.name}} state=present groups={{ item.groups }} with_items: - { name: 'testuser1', groups: 'wheel'} - { name: 'testuser2', groups: 'root'} Ansible的循环机制还有更多的高级功能, 具体请参考官方文档http://docs.ansible.com/playbooks_loops.html
模板示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # grep '{{' conf/httpd.conf MaxClients {{ maxClients }} Listen {{ httpd_port }} # cat /etc/ansible/hosts [webserver] 127.0.0.1 httpd_port=80 maxClients=100 192.168.10.149 httpd_port=8080 maxClients=200 # cat apache.yml - hosts: webserver remote_user: root vars: - package: httpd - service: httpd tasks: - name: install httpd package yum: name={{ package }} state=latest - name: install configuration file for httpd template: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: enabled=true name={{ service }} state=started handlers: - name: restart httpd service: name=httpd state=restarted playbook playbook是由一个或多个"play"组成的列表. play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色. 从根本上来讲, 所有task无非是调用ansible的一个module. 将多个play组织在一个playbook中, 即可以让他们连同起来按事先编排的机制同唱一台大戏
命令说明 1 2 3 4 5 6 7 8 9 10 # 查看脚本影响到的hosts ansible-playbook -i inventory/hosts.yml playbook.yml --list-hosts # 查看输出细节 ansible-playbook playbook.yml --verbose # 并行执行脚本 ansible-playbook playbook.yml -f 10 # 输入密码 ansible-playbook playbook.yml --ask-become-pass # dry-run ansible-playbook playbook.yml --check 组成结构 1 2 3 4 5 6 7 8 9 inventory # 以下操作应用的主机 modules # 调用哪些模块做什么样的操作 ad hoc commands # 在这些主机上运行哪些命令 playbooks tasks # 任务, 即调用模块完成的某操作 variable # 变量 templates # 模板 handlers # 处理器, 由某事件触发执行的操作 roles # 角色 示例:
1 2 3 4 5 6 7 8 9 10 11 12 13 - hosts: webserver vars: http_port: 80 max_clients: 256 remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 基础组件 Hosts和Users
playbook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务. hosts用于指定要执行指定任务的主机, 其可以使一个或多个由冒号分隔主机组；remote_user则用于指定远程主机的执行任务的用户
1 2 - hosts: webserver remote_user: root 不过, remote_user也可用于各task中, 也可以通过指定其通过sudo的方式在远程主机上执行任务, 其可用于play全局或其任务；此外, 甚至可以在sudo时使用sudo_user指定sudo时切换的用户
1 2 3 4 5 6 7 - hosts: webserver remote_user: magedu tasks: - name: test connection ping: remote_user: magedu sudo: yes 任务列表和action
play的主题部分是task list. task list中的各任务按次序逐个在hosts中指定的所有主机上执行, 即在所有主机上完成第一个任务后再开始第二个. 在运行自上而下某playbook时, 如果中途发生错误, 所有已执行任务都可能回滚, 在更正playbook后重新执行一次即可
taks的目的是使用指定的参数执行模块, 而在模块参数中可以使用变量. 模块执行是幂等的. 这意味着多次执行是安全的, 因为其结果均一致
每个task都应该有其name, 用于playbook的执行结果输出, 建议其内容尽可能清晰地描述任务执行步骤, 如果为提供name, 则action的结果将用于输出
定义task可以使用"action: module options"或”module: options“的格式推荐使用后者以实现向后兼容. 如果action一行的内容过多, 也中使用在行首使用几个空白字符进行换行
1 2 3 tasks: - name:make sure apache is running service: name=httpd state=started 在众多的模块中, 只有command和shell模块仅需要给定一个列表而无需使用"key=value"格式, 例如:
1 2 3 tasks: - name: disable selinux command: /sbin/setenforce 0 如果命令或脚本的退出码不为零, 可以使用如下方式替代:
1 2 3 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 或者使用ignore_errors来忽略错误信息:
1 2 3 4 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True handlers
用于当关注的资源发生变化时采取一定的操作
&ldquo;notify"这个action可用于在每个play的最后被触发, 这样可以避免多次有改变发生时每次都执行执行的操作, 取而代之, 仅在所有的变化发生完成后一次性地执行指定操作, 在notify中列出的操作称为handlers, 也即notify中调用handlers中定义的操作
1 2 3 4 5 - name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apache handlers是task列表, 这些task与前述的task并没有本质上的不同
1 2 3 4 5 handlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 简单示例 示例1
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # cat nginx.yml - hosts: webserver remote_user: root tasks: - name: create nginxn group group: name=nginx system=yes gid=208 - name: create nginx user user: name=nginx uid=208 group=nginx system=yes - hosts: dbserver remote_user: root tasks: - name: copy file to dbserver copy: src=/etc/inittab dest=/tmp/inittab.ans # ansible-playbook nginx.yml 示例2
1 2 3 4 5 6 7 8 9 10 11 12 # cat apache.yml - hosts: webserver remote_user: root tasks: - name: install httpd package yum: name=httpd state=latest - name: install configuration file for httpd copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf - name: start httpd service service: enabled=true name=httpd state=started # ansible-playbook apache.yml 示例3
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # cat apache.yml - hosts: webserver remote_user: root tasks: - name: install httpd package yum: name=httpd state=latest - name: install configuration file for httpd copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: enabled=true name=httpd state=started handlers: - name: restart httpd service: name=httpd state=restarted # ansible-playbook apache.yml 示例4
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # cat apache.yml - hosts: webserver remote_user: root vars: - package: httpd - service: httpd tasks: - name: install httpd package yum: name={{ package }} state=latest - name: install configuration file for httpd copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf notify: - restart httpd - name: start httpd service service: enabled=true name={{ service }} state=started handlers: - name: restart httpd service: name=httpd state=restarted 示例5
1 2 3 4 5 6 # cat facts.yml - hosts: webserver remote_user: root tasks: - name: copy file copy: content="{{ ansible_all_ipv4_addresses }} " dest=/tmp/vars.ans roles ansible自1.2版本引入的新特性, 用于层次性、结构化地组织playbook. roles能够根据层次型结构自动转载变量文件、tasks以及handlers等. 要使用roles只需要在playbook中使用include指令即可. 简单来讲, roles就是通过分别将变量、文件、任务、模板以及处理器放置于单独的目录中, 并可以便捷地include他们的一种机制. 角色一般用于基于主机构建服务的场景中, 但也可以使用于构建守护进程的场景中
一个roles的案例如下所示:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 site.yml webserver.yml fooserver.yml roles/ common/ files/ templates/ tasks/ handlers/ vars/ meta/ webserver/ files/ templates/ tasks/ handlers/ vars/ meta/ 而在playbook中, 可以这样使用roles
1 2 3 4 - hosts: webserver roles: - common - webserver 也可以向roles传递参数, 例如:
1 2 3 4 5 - hosts: webserver roles: - common - { role: foo_app_instance, dir:'/opt/a',port:5000} - { role: foo_app_instance, dir:'/opt/b',port:5001} 甚至也可以条件式地使用roles, 例如:
1 2 3 - hosts: webserver roles: - { role: some_role, when: "ansible_so_family == 'RedHat" } 创建role的步骤
创建以roles命名的目录 在roles目录中分别创建以各角色命名的目录, 如webserver等 在每个角色命名的目录中分别创建files、handlers、meta、tasks、templates和vars目录；用不到的目录可以创建为空目录, 也可以不创建 在playbook文件中, 调用各角色 role内各目录中可应用的文件
task目录: 至少应该包含一个为main.yml的文件, 其定义了此角色的任务列表；此文件可以使用include包含其它的位于此目录中的task文件 file目录: 存放由copy或script等模板块调用的文件 template目录: template模块会自动在此目录中寻找jinja2模板文件 handlers目录: 此目录中应当包含一个main.yml文件, 用于定义此角色用到的各handlers, 在handler中使用inclnude包含的其它的handlers文件也应该位于此目录中 vars目录: 应当包含一个main.yml文件, 用于定义此角色用到的变量 meta目录: 应当包含一个main.yml文件, 用于定义此角色的特殊设定及其依赖关系ansible1.3及其以后的版本才支持 default目录: 应当包含一个main.yml文件,用于为当前角色设定默认变量时使用此目录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # mkdir -pv ansible_playbooks/roles/{webserver,dbserver}/{tasks,files,templates,meta,handlers,vars} # cp /etc/httpd/conf/httpd.conf files/ # pwd /root/ansible_playbooks/roles/webserver # cat tasks/main.yml - name: install httpd package yum: name=httpd state=present - name: install configuretion file copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf tags: - conf notify: - restart httpd - name: start httpd service: name=httpd state=started # cat handlers/main.yml - name: restart httpd service: name=httpd state=restarted # pwd;ls /root/ansible_playbooks roles site.yml # cat site.yml - hosts: webserver remote_user: root roles: - webserver # ansible-playbook site.yml tags tags用于让用户选择运行或跳过playbook中的部分代码. ansible具有幂等性, 因此会自动跳过没有变化的部分, 即便如此, 有些代码为测试其确实没有发生变化的时间依然会非常的长. 此时, 如果确信其没有变化, 就可以通过tags跳过此些代码片段
tags: 在playbook可以为某个或某些任务定义一个"标签&rdquo;, 在执行此playbook时, 通过为ansible-playbook命令使用&ndash;tags选项能耐实现仅运行指定的tasks而非所有的
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # cat apache.yml - hosts: webserver remote_user: root vars: - package: httpd - service: httpd tasks: - name: install httpd package yum: name={{ package }} state=latest - name: install configuration file for httpd template: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf tags: - conf notify: - restart httpd - name: start httpd service service: enabled=true name={{ service }} state=started handlers: - name: restart httpd service: name=httpd state=restarted # ansible-playbook apache.yml --tags='conf' 特殊tags: always # 无论如何都会运行
变量 变量的定义方式
通过vars关键字定义
1 2 3 4 5 6 7 - name： use vars define invrionmemnt hosts: test user: ansible vars: http_port: 80 server_name: localhost conf_file: /etc/nginx/conf/default.conf 通过vars_files关键字引入变量文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 - hosts: all remote_user: root vars: favcolor: blue vars_files: - vars/external_vars.yml - vars/user_vars.yml # vars/user_vars.yml示例： users: bjones: first_name: Bob last_name: Jones home_dirs: /users/bjones acook: first_name: Anne last_name: Cook home_dirs: /users/acook 变量的定义格式是成键值对出现的, 键值对之间可以嵌套, 最终形成一个大字典
在playbook中通过host_vars和group_vars目录定义变量
下面这是一个项目的playbook目录结构. 这个项目中, 包含一个ansible.cfg文件, 一个inventory文件, 一个playbook.yml文件, 一个group_vars目录和一个host_vars目录:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # tree /etc/ansible/playbooks/project /etc/ansible/playbooks/project ├── ansible.cfg ├── group_vars │ ├── datacenter1 │ ├── datacenter2 │ └── datacenters ├── host_vars │ ├── demo1.example.com │ ├── demo2.example.com │ ├── demo3.example.com │ └── demo4.example.com ├── inventory └── playbook.yml 其中inventory文件的示例如下:
1 2 3 4 5 6 7 8 9 10 11 [datacenter1] demo1.example.com demo2.example.com [datacenter2] demo3.example.com demo4.example.com [datacenters:children] datacenter1 datacenter2 可以看到group_vars目录中, 定义了三个文件, 分别以inventory文件中的三个主机组命名, 所以这三个文件中定义的就分别是这三个组可以使用的变量
1 2 3 4 5 6 7 8 # cat datacenter1 package: httpd # cat datacenter2 package: apache # cat datacenters package: httpd 在host_vars目录中, 定义了三个文件, 分别以inventory文件中的四个主机命名, 所以这四个文件中定义的就分别是这四个主机可以使用的变量
1 2 3 4 5 6 7 8 9 10 11 # cat demo1.example.com package: httpd # cat demo2.example.com package: apache # cat demo3.example.com package: mariadb-server # cat demo4.example.com package: mysql-server 需要说明的是, 如果主机组定义的变量与主机冲突, 主机变量优先级最高
注册变量
在有些时候, 可能需要将某一条任务执行的结果保存下来, 以便在接下的任务中调用或者做些判断. 可以通过register关键字来实现将某一任务结果保存为一个变量
下面是个简单的例子, 将whoami命令执行的结果注册到变量login：
1 2 3 4 5 6 - name: register variables hosts: test tasks: - name: capture output of whoami command command: whoami register: login 注册变量的应用场景：
在一台远端的服务器获取一个目录下的一列表的文件, 然后下载这些文件 在handler执行之前,发现前面一个task发生了changed,然后执行一个指定的task 获取远端服务器的ssh key的内容,构建出known_hosts文件 通过命令行设置变量
示例如下:
1 2 3 4 5 6 7 --- - hosts: '{{ hosts }}' remote_user: '{{ user }}' tasks: - ... ansible-playbook release.yml --extra-vars "hosts=vipers user=starbuck" 也可以写成类似如下方式:
1 --extra-vars '{"hosts":"vipers","user":"starbuck"}' 使用与调试变量
我们通过以上5种方式在playbook中定义了各种变量. 说到底, 最终的目的, 还是为了方便使用. 下面我们就看一看具体如何使用这些变量
变量的引用
下面是一个变量的基本使用示例:
1 2 3 4 5 6 7 8 9 10 - name: use vars define variables hosts: test vars: http_port: 80 server_name: localhost conf_file: /etc/nginx/conf/default.conf tasks: - name: print variables shell: echo "{{ http_port }} {{ server_name }} {{ conf_file }}" > /tmp/text.txt 我们通过vars_files引用了一个文件user_vars.yml, 在该文件中定义了一个稍微复杂的字典变量, 现在我想要获取users中bjones用户的first_name和acook用户的home_dirs, 可以使用如下方法:
1 2 {{ users.bjones.first_name }} {{ users.acook.home_dirs }} 或者如下写法:
1 2 {{ users['bjones']['first_name'] }} {{ users['acook']['home_dirs'] }} 变量的调试输出
有些时候, 我们在引用变量的时候, 可能需要知道变量中包含哪些信息, 以方便在执行过程中, 对变量做些处理. ansible提供一个debug模块用于调试变量输出:
1 2 3 4 5 6 7 - name: register variables hosts: test tasks: - name: capture output of whoami command command: whoami register: login - debug: var=login 执行后输出如下:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # ansible-playbook register.yml PLAY [register variables] *************************************************************************************************************************************************** TASK [Gathering Facts] ****************************************************************************************************************************************************** ok: [192.168.0.187] TASK [capture output of whoami command] ************************************************************************************************************************************* changed: [192.168.0.187] TASK [debug] **************************************************************************************************************************************************************** ok: [192.168.0.187] => { "login": { "changed": true, "cmd": [ "whoami" ], "delta": "0:00:00.004279", "end": "2019-05-24 00:41:43.710398", "failed": false, "rc": 0, "start": "2019-05-24 00:41:43.706119", "stderr": "", "stderr_lines": [], "stdout": "root", "stdout_lines": [ "root" ] } } PLAY RECAP ****************************************************************************************************************************************************************** 192.168.0.187 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 关于输出的debug部分重点说明如下:
login: 变量名, 其值为一个字典 changed: ansible基于此来判断是否发生了状态改变 cmd: 被调用的命令 failed: 是否运行失败 rc: 返回值, 0代表正常, 非0代表异常 stderr: 如果出现异常, 会在这里显示错误输出 stderr_lines: 按行分割的错误输出 stdout: 如果指令正常运行, 则在这里输出返回结果 stdout: 按行分割的返回结果 需要说明的是, 通过register注册的变量的结果并不是一成不变的, 在不确定返回值的情况下, 尽量调试看看输出结果
关于debug的更多用法说明:
调试模块, 用于在调试中输出信息 常用参数:
msg: 调试输出的消息 var: 将某个变量传递给debug模块, debug会直接将其打印输出 verbosity: debug的级别 示例:
1 2 3 4 5 6 7 8 9 10 11 12 13 # Example that prints the loopback address and gateway for each host - debug: msg="System {{ inventory_hostname }} has uuid {{ ansible_product_uuid }}" - debug: msg="System {{ inventory_hostname }} has gateway {{ ansible_default_ipv4.gateway }}" when: ansible_default_ipv4.gateway is defined - shell: /usr/bin/uptime register: result - debug: var=result verbosity=2 #直接将上一条指令的结果作为变量传递给var, 由debug打印出result的值 - name: Display all variables/facts known for a host debug: var=hostvars[inventory_hostname] verbosity=4 文章推荐 官方文档 运维服务 Zookeeper 分布式数据一致性解决方案
基本概念 顺序一致性: 顺序一致性](https://www.jianshu.com/p/59ea658a1313) 系统中的所有进程, 看到的操作顺序, 都与全局时钟下的顺序一致 线性一致性: 除满足顺序一致性外, 还要求任何一次读都能读到某个数据的最近一次写的数据. 顺序一致性和线性一致性都是强一致性, 因果一致性和最终一致性是弱一致性 Leader: Leader服务器在整个集群正常运行期间有且仅有一台,集群会通过选举的方式选举出Leader服务器, 由它统一处理集群的事务性请求以及集群内各服务器的调度 Follower: 集群中可以有多台Follower服务器, Follower服务器参与Leader选举投票和事务请求(写请求)Proposal的投票, 可以处理客户端非事务请求(读请求), 并会将事务请求(写请求)转发给Leader服务器 Observer: 弱化版的Follower, 其像Follower一样能够处理非事务也就是读请求,并转发事务请求给Leader服务器, 但是其不参与任何形式的投票, 不管是Leader选举投票还是事务请求Proposal的投票. 引入这个角色主要是为了在不影响集群事务处理能力的前提下提升集群的非事务处理的吞吐量 Znode: Zookeeper将数据存储于内存中,具体而言, Znode是存储数据的最小单元. 而Znode被以层次化的结构进行组织, 形容一棵树. 其对外提供的视图类似于Unix文件系统. 树的根Znode节点相当于Unix文件系统的根路径. 正如Unix中目录下可以有子目录一样, Znode结点下也可以挂载子结点 持久结点(PERSISTENT) 最常见的Znode类型, 一旦创建将一直存在于服务端,除非客户端通过删除操作进行删除. 持久结点下可以创建子结点 持久顺序结点(PERSISTENT_SEQUENTIAL) 在具有持久结点基本特性的基础上,会通过在结点路径后缀一串序号来区分多个子结点创建的先后顺序. 这工作由Zookeeper服务端自动给我们做, 只要在创建Znode时指定结点类型为该类型 临时结点(EPHEMERAL) 临时结点的生命周期和客户端会话保持一致. 客户端段会话存在的话临时结点也存在, 客户端会话断开则临时结点会自动被服务端删除. 临时结点下不能创建子结点 临时顺序结点(EPHEMERAL_SEQUENTIAL) 具有临时结点的基本特性, 又有顺序性 架构特性 集群架构
数据模型
请求流
所有的事务请求都交由集群的Leader服务器来处理, Leader服务器会将一个事务请求转换成一个Proposal(提议), 并为其生成一个全局递增的唯一ID, 这个ID就是事务ID(即ZXID), Leader服务器对Proposal是按其ZXID的先后顺序来进行排序和处理的
之后Leader服务器会将Proposal放入每个Follower对应的队列中(Leader会为每个Follower分配一个单独的队列), 并以FIFO的方式发送给Follower服务器
Follower服务器接收到事务Proposal后, 首先以事务日志的方式写入本地磁盘, 并且在成功后返回Leader服务器一个ACK响应
Leader服务器只要收到过半Follower的ACK响应, 就会广播一个Commit消息给Follower以通知其进行Proposal的提交, 同时Leader自身也会完成Proposal的提交
读写请求
Zookeeper数据以Znode为最小单位组成一颗树, 内存中存储了整棵树的全量内容, 包括所有的节点路径、节点数据、ACL信息. Zookeeper会定时将这个数据存储到磁盘上
Zookeeper的Zab一致性协议实现写操作的线性一致性和读操作的顺序一致性. 整体遵循顺序一致性.
Zookeeper的所有写操作都通过主节点进行, 从节点复制修改操作, 这样所有节点的更新顺序都和主节点相同, 不会出现某个节点的更新顺序与其它节点不同的情况.
Zookeeper允许客户端从从节点读取数据, 因此如果客户端在读取过程中连接了不同的节点, 则顺序一致性就得不到保证了.
session与监听
zookeeper会为每个客户端分配一个session, 类似于web服务器一样, 用来标识客户端的身份. Server和客户端都可以主动断开session, session断开后临时ZNode会被删除. 客户端会自动利用其他server重建session.
Watcher(事件监听器)是Zookeeper提供的一种发布/订阅的机制. Zookeeper允许用户在指定ZNode上注册一些Watcher, 并且在一些特定事件触发的时候, Zookeeper服务端会将事件通知给订阅的客户端. Zookeeper的监听器是一次性的, 触发一次后如果希望继续监听, 需要重新注册Watcher.
应用场景
名字服务, 配置管理, 集群管理, 集群选举, 分布式锁, 队列管理, 消息订阅
配置文件 $ZOOKEEPER_HOME/conf/zoo.cfg: 核心配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # ZooKeeper中使用的基本时间单元, 以毫秒为单位, 默认值是2000. 它用来调节心跳和超时. 例如默认的会话超时时间是两倍的tickTime ticketTime=2000 # 用于配置允许followers连接并同步到leader的最大时间. 如果ZooKeeper管理的数据量很大的话可以增加这个值. 默认值是10, 即tickTime属性值的10倍 initLimit=10 # 用于配置leader和followers间进行心跳检测的最大延迟时间. 如果在设置的时间内followers无法与leader进行通信, 那么followers将会被丢弃. 默认值是5, 即tickTime属性值的5倍 syncLimit=5 # 服务器监听客户端连接的端口. 也即客户端尝试连接的端口. 默认值是2181 clientPort=2181 # ZooKeeper用来存储内存数据库快照的目录, 并且除非指定其它目录, 否则数据库更新的事务日志也将会存储在该目录下 dataDir=/opt/zookeeper/data # Zookeeper用来存储服务日志的目录 dataLogDir=/opt/zookeeper/logs # 在socket级别限制单个客户端与单台服务器之前的并发连接数量, 可以通过IP地址来区分不同的客户端. 它用来防止某种类型的DoS攻击, 包括文件描述符耗尽. 默认值是60. 将其设置为0将完全移除并发连接数的限制 maxClientCnxns=0 # 自动清理配置. 配置ZooKeeper在自动清理的时候需要保留的数据文件快照的数量和对应的事务日志文件, 默认值是3 autopurge.snapRetainCount=3 # 和参数autopurge.snapRetainCount配套使用, 用于配置ZooKeeper自动清理文件的频率, 默认值是1, 即默认开启自动清理功能, 设置为0则表示禁用自动清理功能 autopurge.purgeInterval=1 # zookeeper server成员列表(地址:内部通信端口:选举端口) server.1=master:2888:3888 server.2=slave01:2888:3888 server.3=slave02:2888:3888 运维命令 服务起停
1 2 zkServer.sh start zkServer.sh stop 状态查看
1 zkServer.sh status 交互模式
1 2 3 4 5 6 7 8 9 zkCli.sh -server localhost:2181 &lt;&lt; EOF ls # 查看当前znode数据 ls2 # 查看当前znode数据并能看到更新次数等数据 create # 创建一个znode get # 得到一个znode包含数据和更新次数等数据 set # 修改znode delete # 删除一个znode quit # 退出交互模式 EOF 输出server相关信息
1 echo &lt;命令> | nc localhost 2181 命令列表:
命令 描述 conf zk服务配置的详细信息 stat 查看服务状态(包括选举信息) srvr zk服务的详细信息 cons 客户端与zk连接的详细信息 mntr zk服务目前的性能状况 dump 列出未经处理的会话和临时节点 envi 输出关于服务环境的详细信息 reqs 列出未经处理的请求 ruok 测试服务是否启动 kill 关闭服务 wchs watch的简要信息 wchc watch的详细信息. 客户端 -> watch的映射(线上环境要小心使用) wchp watch的详细信息. znode -> 客户端的映射(线上环境要小心使用) 常用API 相关工具 性能压测 https://github.com/phunt/zk-smoketest watch性能压测 https://github.com/kevinlynx/zk-benchmark 性能监控 https://github.com/phunt/zktop cli工具 https://github.com/let-us-go/zkcli 抓包工具 https://github.com/pyinx/zk-sniffer 数据同步 https://github.com/ksprojects/zkcopy proxy https://github.com/pyinx/zk-proxy 文章推荐 官方文档 Zookeeper系列文章 https://www.cnblogs.com/takumicx/p/9508706.html Zookeeper原理与优化 几句话了解Zookeeper工作原理 排障经验 数据大小不超过500M
风险: 数据过大会导致集群恢复时间过长、GC加重、客户端超时增多
单机连接数不超过2w
风险: 连接数过高会导致集群恢复时间过长(zookeeper在选举之前会主动关闭所有的连接, 如果这时候不断有新的连接进来会导致zookeeper一直在关闭连接, 无法进行选举)
watch数不超过100w
风险: watch数过高会影响集群的写入性能
不要维护一个超大集群
风险: 稳定性风险高、故障影响面大、运维不可控
Kafka 分布式流处理系统/消息队列
基本概念 Broker: 部署了Kafka实例的服务器节点, 各节点地位相同, 通过metadata API管理Broker之间的负载均衡, 增减集群Broker时需要手动进行分区副本重分配 Topic: 区分不同类型信息的主题, 每个主题都是同一类别消息记录(record)的集合 Partition: 每个topic可以有一个或多个partition(分区). 分区是在物理层面上的, 不同的分区对应着不同的数据文件. 分区可以分布在不同的服务器(broker)上. 同一主题下的不同分区包含的消息是不同的, 分区在存储层面可以看作一个可追加的日志(Log)文件, 消息在被追加到分区日志文件的时候都会分配一个特定的偏移量(offset). offset是消息在分区中的唯一标识, Kafka通过它来保证消息在分区内的顺序性, 不过offset并不跨越分区, 也就是说, Kafka保证的是分区有序而不是主题有序 Replica: 分区引入了多副本(Replica)机制, 通过增加副本数量可以提升容灾能力. 同一分区的不同副本中保存的是相同的消息(在同一时刻, 副本之间并非完全一样), 副本之间是"一主多从"的关系, 其中leader副本负责处理读写请求, follower副本只负责与leader副本的消息同步. 副本处于不同的broker中, 当leader副本出现故障时, 从follower副本中重新选举新的leader副本对外提供服务 Record: 实际写入Kafka中并可以被读取的消息记录. 每个record包含了key、value和timestamp Producer: 生产者. 用来向Kafka中发送数据(record), 将消息发送到特定的主题 Consumer: 消费者. 用来读取Kafka中的数据(record), 订阅主题并进行消费 Consumer Group: 消费者组是逻辑上的订阅者, 一个消费者组可以包含一个或多个消费者, 消费者组内每个消费者负责消费不同分区的数据. 使用多分区+多消费者方式可以极大提高数据下游的处理速度 Rebalance: Rebalance本质上是一种协议, 规定了一个Consumer Group下的所有Consumer如何达成一致, 来分配订阅Topic的每个Partition. 分区的分配的过程就叫Rebalance. 当出现Consumer Group成员数发生变更, 订阅Topic数发生变更或订阅Topic的Partiton数发生变更时都会触发Rebalance, Rebalance期间所有Consumer实例都会停止消费, 性能影响较大, 应尽量避免产生Rebalance Coordinator: Coordinator一般指的是运行在每个Broker上的Group Coordinator进程, 每个Broker启动的时候, 都会创建Group Coordinator实例, 用于管理Consumer Group中的各个成员, 主要用于offset位移管理和Rebalance. 一个Coordinator可以同时管理多个消费者组. 此外每个Consumer实例化时, 同时实例化一个Consumer Coordinator对象, 负责同一个消费组下各个消费者和服务端Group Coordinator之前的通信(心跳) Zookeeper: 分布式一致性协调器, 负责集群元数据的管理、控制器的选举等操作 架构特性 集群架构
数据模型
读写请求
消息数据的读写只发生在Leader上.
生产者向某Topic写入数据时, 自行决定向Topic下的哪个Partition写入(可以通过算法进行均衡负载), 确定Partition后从集群获取分区Leader, 将消息发送到Leader, 该分区的Follower主动从Leader拉取(pull)消息进行同步. 生产者通过push的方式向Topic下的Partition顺序追加消息数据, 所有分区的数据会顺序持久化到磁盘, 磁盘写入效率高
消息队列通信的两种模式是点对点模式和发布订阅模式, kafka采用的是点对点模式. 消费者主动向Kafka集群拉取消息, 消费者自行决定向Topic下的哪个Partition拉取消息(只会向Leader拉取), Kafka不关心消息是否被消费, 消费通过Partition ID和自行维护的偏移量(offset)进行消息消费(消费者的消费offset可以自动或手动提交, 维护在kafka集群的__consumer_offsets Topic中, 早期维护在zookeeper集群中)
多个消费者可以组成一个消费者组(consumer group), 每个消费者组都有一个组id. 同一个消费组者的消费者可以消费同一Topic下不同分区的数据, 但是不会组内多个消费者消费同一分区的数据
复制机制
Kafka在Partition层面采用副本机制实现数据的高可用, 每个Partition都是一主多从的架构(可配置副本数为零到多), Follower不对外提供服务, 所有的读写都发生在Leader上, Follower拉取Leader的消息数据维护数据一致性. Kafka引入In-sync Replicas(副本同步列表)机制, ISR中的都是与Leader数据同步的副本, 而OSR中的都是尚未与Leader完成数据同步的副本, 当Leader不可用时, 只有ISR中的副本能够被选举为新的Leader(可配置), ISR和OSR中的副本是根据副本的同步状态动态转移的
Leader接收Producer的消息后, 将消息写入本地Log, 并通知ISR的Follower, ISR的Follower从Leader中pull消息, 写入本地Log后向Leader发送ACK, Leader收到所有ISR中的Follower的ACK后, 增加HW并向Producer发生ACK, 表示消息写入成功. 对于ISR中的Follower的消息复制是同步的, 对于OSR中的Follower的消息复制是异步的
存储策略
Kafka会以顺序写入的方式将消息持久化到本地文件系统中, Kafka会长期保留消息(可以自定义消息有效期), 以便消费者能够重复消费消息. 默认会基于时间和大小自动删除旧数据, Kafka读取特定消息的时间复杂度是O(1), 所以这里删除过期的文件并不会提高Kafka的性能
Kafka中的Partition是以目录的形式存在于文件系统中的, 目录下会存在多组segment文件, 每组segment包含.log, .index和.timeindex三个文件. log文件就是实际存储消息的地方. 存储在log文件中的消息主要包含消息体、消息大小、offset、压缩类型……等等. index和timeindex文件为索引文件, 用于检索消息
应用场景
日志收集, 消息系统, 流量削峰, 流式处理, 事件源, 运营指标, 活动跟踪
配置文件 $ZOOKEEPER_HOME/config/server.properties: 服务端全局配置
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 # 每一个broker在集群中的唯一表示, 要求是正数, kafka及其根据id来识别broker机器. 当该服务器的IP地址发生改变时, broker.id没有变化, 则不会影响consumers的消息情况 broker.id =0 # kafka数据的存放地址, 多个地址的话用逗号分割/kafka/kafka-logs-1, /kafka/kafka-logs-2 log.dirs=/kafka/kafka-logs # broker server服务端口 port =9092 # 表示消息体的最大大小, 单位是字节 message.max.bytes =6525000 # broker处理消息的最大线程数, 一般情况下不需要去修改 num.network.threads =4 # broker处理磁盘IO的线程数, 数值应该大于你的硬盘数 num.io.threads =8 # 一些后台任务处理的线程数, 例如过期消息文件的删除等, 一般情况下不需要去做修改 background.threads =4 # 等待IO线程处理的请求队列最大数, 若是等待IO的请求超过这个数值, 那么会停止接受外部消息, 应该是一种自我保护机制 queued.max.requests =500 # broker的主机地址, 若是设置了, 那么会绑定到这个地址上, 若是没有, 会绑定到所有的接口上, 并将其中之一发送到ZK, 一般不设置 host.name # socket的发送缓冲区, socket的调优参数SO_SNDBUFF socket.send.buffer.bytes=100*1024 # socket的接受缓冲区, socket的调优参数SO_RCVBUFF socket.receive.buffer.bytes =100*1024 # socket请求的最大数值, 防止serverOOM, message.max.bytes必然要小于socket.request.max.bytes, 会被topic创建时的指定参数覆盖 socket.request.max.bytes =100*1024*1024 ##Kafka中log日志的参数配置 # topic的分区是以一堆segment文件存储的, 这个控制每个segment的大小, 会被topic创建时的指定参数覆盖 log.segment.bytes =1024*1024*1024 # 这个参数会在日志segment没有达到log.segment.bytes设置的大小, 也会强制新建一个segment, 会被 topic创建时的指定参数覆盖 log.roll.hours =24*7 # 日志清理策略选择有: delete和compact主要针对过期数据的处理, 或是日志文件达到限制的额度, 会被 topic创建时的指定参数覆盖 log.cleanup.policy = delete # 数据存储的最大时间超过这个时间会根据log.cleanup.policy设置的策略处理数据, 也就是消费端能够多久去消费数据 # log.retention.bytes和log.retention.minutes任意一个达到要求, 都会执行删除, 会被topic创建时的指定参数覆盖 log.retention.minutes=3days # topic每个分区的最大文件大小, 一个topic的大小限制 =分区数*log.retention.bytes. -1没有大小限log.retention.bytes和log.retention.minutes任意一个达到要求, 都会执行删除, 会被topic创建时的指定参数覆盖 log.retention.bytes=-1 # 文件大小检查的周期时间, 是否触发 log.cleanup.policy中设置的策略 log.retention.check.interval.ms=5minutes # 是否开启日志压缩 log.cleaner.enable=false # 日志压缩运行的线程数 log.cleaner.threads = 2 # 日志压缩时候处理的最大大小 log.cleaner.io.max.bytes.per.second=None # 日志压缩去重时候的缓存空间, 在空间允许的情况下, 越大越好 log.cleaner.dedupe.buffer.size=500*1024*1024 # 日志清理时候用到的IO块大小一般不需要修改 log.cleaner.io.buffer.size=512*1024 # 检查是否触发日志清理的间隔 log.cleaner.backoff.ms =15000 # 日志清理的频率控制, 越大意味着更高效的清理, 同时会存在一些空间上的浪费, 会被topic创建时的指定参数覆盖 log.cleaner.min.cleanable.ratio=0.5 # 对于压缩的日志保留的最长时间, 也是客户端消费消息的最长时间, 同log.retention.minutes的区别在于一个控制未压缩数据, 一个控制压缩后的数据. 会被topic创建时的指定参数覆盖 log.cleaner.delete.retention.ms =1day # 对于segment日志的索引文件大小限制, 会被topic创建时的指定参数覆盖 log.index.size.max.bytes =10*1024*1024 # 当执行一个fetch操作后, 需要一定的空间来扫描最近的offset大小, 设置越大, 代表扫描速度越快, 但是也更好内存, 一般情况下不需要搭理这个参数 log.index.interval.bytes =4096 # log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性"的必要手段,所以此参数的设置,需要在"数据可靠性"与"性能"之间做必要的权衡.如果此值过大,将会导致每次"fsync"的时间较长(IO阻塞),如果此值过小,将会导致"fsync"的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失 log.flush.interval.messages=None # 检查是否需要固化到硬盘的时间间隔 log.flush.scheduler.interval.ms =3000 # 仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制"fsync"的时间间隔,如果消息量始终没有达到阀值,但是离上一次磁盘同步的时间间隔达到阀值,也将触发 log.flush.interval.ms = None # 文件在索引中清除后保留的时间一般不需要去修改 log.delete.delay.ms =60000 # 控制上次固化硬盘的时间点, 以便于数据恢复一般不需要去修改 log.flush.offset.checkpoint.interval.ms =60000 # 是否允许自动创建topic, 若是false, 就需要通过命令创建topic auto.create.topics.enable =true # kafka保存消息的副本数 default.replication.factor =1 # 每个topic的分区个数, 若是在topic创建时候没有指定的话会被topic创建时的指定参数覆盖 num.partitions =1 ## Kafka中leader、replicas参数配置 # partition leader与replicas之间通讯时,socket的超时时间 controller.socket.timeout.ms =30000 # partition leader与replicas数据同步时,消息的队列尺寸 controller.message.queue.size=10 # replicas响应partition leader的最长等待时间, 若是超过这个时间, 就将replicas列入ISR(in-sync replicas), 并认为它是死的, 不会再加入管理中 replica.lag.time.max.ms =10000 # 如果follower落后与leader太多,将会认为此follower[或者说partition relicas]已经失效 # 通常,在follower与leader通讯时,因为网络延迟或者链接断开,总会导致replicas中消息同步滞后, 如果消息之后太多,leader将认为此follower网络延迟较大或者消息吞吐能力有限,将会把此replicas迁移到其他follower中. 在broker数量较少,或者网络不足的环境中,建议提高此值 replica.lag.max.messages =4000 # follower与leader之间的socket超时时间 replica.socket.timeout.ms=30*1000 # leader复制时候的socket缓存大小 replica.socket.receive.buffer.bytes=64*1024 # replicas每次获取数据的最大大小 replica.fetch.max.bytes =1024*1024 # replicas同leader之间通信的最大等待时间, 失败了会重试 replica.fetch.wait.max.ms =500 # fetch的最小数据尺寸,如果leader中尚未同步的数据不足此值,将会阻塞,直到满足条件 replica.fetch.min.bytes =1 # leader进行复制的线程数, 增大这个数值会增加follower的IO num.replica.fetchers=1 # 每个replica检查是否将最高水位进行固化的频率 replica.high.watermark.checkpoint.interval.ms =5000 # 是否允许控制器关闭broker ,若是设置为true,会关闭所有在这个broker上的leader, 并转移到其他broker controlled.shutdown.enable =false # 控制器关闭的尝试次数 controlled.shutdown.max.retries =3 # 每次关闭尝试的时间间隔 controlled.shutdown.retry.backoff.ms =5000 # leader的不平衡比例, 若是超过这个数值, 会对分区进行重新的平衡 leader.imbalance.per.broker.percentage =10 # 检查leader是否不平衡的时间间隔 leader.imbalance.check.interval.seconds =300 # 客户端保留offset信息的最大空间大小 offset.metadata.max.bytes ## kafka中zookeeper的参数配置 # 必须配置项: : : zookeeper集群的地址, 可以是多个, 多个之间用逗号分割, 一般端口都为2181；hostname1:port1,hostname2:port2,hostname3:port3 zookeeper.connect = localhost:2181 # ZooKeeper的最大超时时间, 就是心跳的间隔, 若是没有反映, 那么认为已经死了, 不易过大 zookeeper.session.timeout.ms=6000 # ZooKeeper的连接超时时间 zookeeper.connection.timeout.ms =6000 # ZooKeeper集群中leader和follower之间的同步时间 zookeeper.sync.time.ms =2000 producer.properties: 生产者配置文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # 指定节点列表 metadata.broker.list=kafka1:9092,kafka2:9092,kafka3:9092 # 指定分区处理类. 默认kafka.producer.DefaultPartitioner partitioner.class=kafka.producer.DefaultPartitioner # 是否压缩,0代表不压缩,1代表用gzip压缩,2代表用snappy压缩 compression.codec=0 # 指定序列化处理类 serializer.class=kafka.serializer.DefaultEncoder # 如果要压缩消息, 这里指定哪些topic要压缩消息, 默认是empty, 表示不压缩 compressed.topics= # 设置发送数据是否需要服务端的反馈, 有三个值0, 1, -1 # 0:producer不会等待broker发送ack # 1:当leader接收到消息后发送ack # -1:当所有的follower都同步消息成功后发送ack request.required.acks=0 # 在向producer发送ack之前, broker均需等待的最大时间 request.timeout.ms=10000 # sync同步（默认）, async异步可以提高发送吞吐量 producer.type=async # 在async模式下, 当message缓存超时后, 将会批量发送给broker,默认5000ms queue.buffering.max.ms=5000 # 在async模式下, Producer端允许buffer的最大消息量 queue.buffering.max.messages=20000 # 在async模式下, 指定每次批量发送的数据量, 默认200 batch.num.messages=500 # 当消息在producer端沉积的条数达到“queue.buffering.max.messages"后 # 阻塞一定时间后, 队列仍然没有enqueue（producer仍然没有发送出任何消息） # 此时producer可以继续阻塞, 或者将消息抛弃 # -1: 无阻塞超时限制, 消息不会被抛弃 # 0 : 立即清空队列, 消息被抛弃 queue.enqueue.timeout.ms=-1 consumer.properties: 消费者配置文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # Consumer归属的组ID, broker是根据group.id来判断是队列模式还是发布订阅模式, 非常重要 group.id # 消费者的ID, 若是没有设置的话, 会自增 consumer.id # 一个用于跟踪调查的ID , 最好同group.id相同 client.id = group id value # 对于zookeeper集群的指定, 可以是多个 hostname1:port1,hostname2:port2,hostname3:port3 必须和broker使用同样的zk配置 zookeeper.connect=localhost:2182 # zookeeper的心跳超时时间, 查过这个时间就认为是dead消费者 zookeeper.session.timeout.ms =6000 # zookeeper的等待连接时间 zookeeper.connection.timeout.ms =6000 # zookeeper的follower同leader的同步时间 zookeeper.sync.time.ms =2000 # 当zookeeper中没有初始的offset时候的处理方式 . smallest : 重置为最小值 largest:重置为最大值 anythingelse: 抛出异常 auto.offset.reset = largest # socket的超时时间, 实际的超时时间是: max.fetch.wait + socket.timeout.ms. socket.timeout.ms=30*1000 # socket的接受缓存空间大小 socket.receive.buffer.bytes=64*1024 #从每个分区获取的消息大小限制 fetch.message.max.bytes =1024*1024 # 是否在消费消息后将offset同步到zookeeper, 当Consumer失败后就能从zookeeper获取最新的offset auto.commit.enable =true # 自动提交的时间间隔 auto.commit.interval.ms =60*1000 # 用来处理消费消息的块, 每个块可以等同于fetch.message.max.bytes中数值 queued.max.message.chunks =10 # 当有新的consumer加入到group时,将会reblance,此后将会有partitions的消费端迁移到新 # 的consumer上,如果一个consumer获得了某个partition的消费权限,那么它将会向zk注册 #"Partition Owner registry"节点信息,但是有可能此时旧的consumer尚没有释放此节点, # 此值用于控制,注册节点的重试次数. rebalance.max.retries =4 # 每次再平衡的时间间隔 rebalance.backoff.ms =2000 # 每次重新选举leader的时间 refresh.leader.backoff.ms # server发送到消费端的最小数据, 若是不满足这个数值则会等待, 知道满足数值要求 fetch.min.bytes =1 # 若是不满足最小大小(fetch.min.bytes)的话, 等待消费端请求的最长等待时间 fetch.wait.max.ms =100 # 指定时间内没有消息到达就抛出异常, 一般不需要改 consumer.timeout.ms = -1 运维命令 kafka相关运维命令中, 低版本使用--zookeeper localhost:2181的地方在高版本中统一用--bootstrap-server localhost:9092代替
服务启停
1 2 3 4 5 6 # zookeeper启停 sh bin/zookeeper-server-start.sh -daemon config/zookeeper.properties sh bin/zookeeper-server-stop.sh # kafka启停 sh bin/kafka-server-start.sh config/server.properties sh bin/kafka-server-stop.sh 配置管理
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # 查看配置 ## 在zookeeper上查看 ## 节点目录一般是 /config/entityType/entityName ## entityType可以是brokers、topics、users、clients ## entityName表示具体的名称, 比如broker的id, topic的名称 sh bin/zookeeper-shell.sh &lt;&lt;EOF get /kafka/config/brokers/0 # /kafka 是命名空间 EOF ## 列出某个entityType的entityName的全部配置项 sh bin/kafka-configs.sh --describe --all --bootstrap-server localhost:9092 --entity-type topics --entity-name test # broker配置 ## 将0号broker的配置 log.cleaner.backoff.ms修改成1000,flush.ms 也修改成1000 ## --alter 表示要修改配置项 ## --add-config 后面跟着要修改的配置项 sh bin/kafka-configs.sh --alert --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --add-config log.cleaner.backoff.ms=1000,flush.ms=1000 ## 删除0号broker 对 log.cleaner.backoff.ms的配置 sh bin/kafka-configs.sh --alert --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --delete-config log.cleaner.backoff.ms ## 列出0号broker修改过的配置项 sh bin/kafka-configs.sh --describe --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 # topic配置 ## 将test这个topic的 delete.retention.ms修改成1000,flush.ms 也修改成1000 sh bin/kafka-configs.sh --alter --bootstrap-server localhost:9092 --entity-type topics --entity-name test --add-config delete.retention.ms=1000,flush.ms=1000 ## 删除test这个topic的 delete.retention.ms和flush.ms配置项 sh bin/kafka-configs.sh --alert --bootstrap-server localhost:9092 --entity-type topics --entity-name test --delete-config delete.retention.ms,flush.ms ## 列出test这个topic修改过的配置项 sh bin/kafka-configs.sh --describe --bootstrap-server localhost:9092 --entity-type topics --entity-name test # client配置 ## 设置客户端id为test的producer_byte_rate和consumer_byte_rate为1024 sh bin/kafka-configs.sh --alter --bootstrap-server localhost:9092 --add-config 'producer_byte_rate=1024,consumer_byte_rate=1024' --entity-type clients --entity-name test topic管理
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 创建topic sh bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test # 列出topic sh bin/kafka-topics.sh --list --zookeeper localhost:2181 # 描述topic信息 sh bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test # 修改topic sh bin/kafka-topics.sh --alert --zookeeper localhost:2181 --topic test --partitions 2 # 删除topic sh bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test # 查询topic最小偏移量(最大和最小偏移量相减是topic消息总量) sh bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 -topic test --time -2 # 查询topic最大偏移量 sh bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 -topic test --time -1 消费组管理
1 2 3 4 5 6 7 8 9 10 11 12 # 查询消费组(使用--bootstrap-server时可能需要--new-consumer参数) sh bin/kafka-consumer-groups.sh --list --bootstrap-server localhost:9092 # 查询消费组信息 sh bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9292 --group grp # 查看消费组成员信息 sh bin/kafka-consumer-groups.sh --describe --members --bootstrap-server localhost:9092 --group grp --verbose # 删除消费组 sh bin/kafka-consumer-groups.sh --delete --bootstrap-server localhost:9092 --group grp --group grp1 # 设置消费组的offset为最旧 sh bin/kafka-consumer-groups.sh --reset-offsets --bootstrap-server localhost:9092 --group grp --topic test --to-earliest --execute # 设置消费组的offset为最新 sh bin/kafka-consumer-groups.sh --reset-offsets --bootstrap-server localhost:9092 --group grp --topic test --to-latest 消息管理
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 产生消息 sh bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test # 消费消息 sh bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning # 查询消费信息 sh bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group grp --topic test # 删除消息 sh bin/kafka-delete-records.sh --bootstrap-server localhost:9092 --offset-json-file delete.json ## delete.json { "partitions": [ { "topic": "test", "partition": 0, "offset": 24 } ], "version": 1 } 分区副本重分配
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # gen.json (自动重分配gen文件) { "topics": [ { "topic": "foo" } ], "version": 1 } # assign.json (可通过自动重分配生成) { "partitions": [ { "topic": "test", "partition": 1, "replicas": [ 1002, 1003 ] }, { "topic": "test", "partition": 2, "replicas": [ 1003, 1002 ] } ], "version": 1 } 1 2 3 4 5 6 7 8 9 # 自动生成分区副本重分配文件 # --generate 表示生成重分配的json文件 # --topics-to-move-json-file 指定要重分配哪些topic # --broker-list 表示要分配到哪些broker上去 sh bin/kafka-reassign-partitions.sh --generate --zookeeper localhost:2181 --topics-to-move-json-file gen.json --broker-list 1001,1002,1003 # 执行分区副本重分配 sh bin/kafka-reassign-partitions.sh --execute --zookeeper localhost:2181 --reassignment-json-file assign.json # 查看分区副本重分配执行状态 sh bin/kafka-reassign-partitions.sh --verify --zookeeper localhost:2181 --reassignment-json-file assign.json 其他命令
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 生产性能测试(acks=-1) sh bin/kafka-producer-perf-test.sh --broker-list localhost:9092 --batch-size 1 --message-size 1024 --messages 10000 --sync --topics test # 消费性能测试 sh bin/kafka-consumer-perf-test.sh --topic-list localhost:9092 --message-size 200 --messages 50000 --topic test # 查看消息元数据 sh bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files /dfs5/kafka/data/secLog-2/00000000000110325000.log --print-data-log --deep-iteration > secLog.log # 集群镜像 sh bin/kafka-mirror-maker.sh --consumer.config config/consumer.properties --producer.config config/producer.properties --new.consumer -num.streams=2 --whitelist ".*" # 客户端限流 sh bin/kafka-configs.sh --alter --zookeeper localhost:2181 --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048' --entity-name ClientA --entity-type clients # 用户限流 sh bin/kafka-configs.sh --alert --zookeeper localhost:2181 --add-config 'producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200' --entity-type users --entity-name user1 # 查看限流 sh bin/kafka-configs.sh --describe --zookeeper localhost:2181 --entity-type users --entity-name user1 --entity-type clients --entity-name clientA # 查看broker限流配置 sh bin/kafka-configs.sh --describe --zookeeper localhost:2181 --entity-type brokers # 查看限流的副本 sh bin/kafka-configs.sh --describe --zookeeper localhost:2181 --entity-type topics # 查询 __consumer_offsets topic 所有内容 sh bin/kafka-console-consumer.sh --formatter --topic __consumer_offsets --bootstrap-server localhost:9092 "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --consumer.config /soft/kafka/config/consumer.properties --from-beginning # 分区选举 sh bin/kafka-preferred-replica-election.sh --zookeeper localhost:2181 --path-to-json-file prefered.json # prefered.json { "partitions": [ { "topic": "test", "partition": 0 } ] } 常用API 相关工具 集群管理 https://github.com/yahoo/CMAK kafka客户端 https://github.com/edenhill/kafkacat kafka运维管理 https://github.com/goops-top/gokafka 文章推荐 官方文档 kafka快速入门系列 kafka常用工具 kafka底层原理剖析 一文看懂kafka消息队列 kafka消息丢失问题 消息队列系列 kafka实战宝典 Awesome Kafka 排障经验 ElasticSearch 分布式搜索分析引擎
基本概念 NRT: Near Realtime近实时. 基于es执行搜索和分析可以达到秒级, 但从写入数据到数据可以被搜索到有一个小延迟(大概1秒) Cluster: ElasticSearch集群通过集群名称区分, 默认名称为elasticsearch. ElasticSearch集群是介于p2p和master-slave的自发现分布式系统, 支持高可用性和可扩展性 Node: 节点就是ElasticSearch实例, 每个节点都会生成一个随机ID作为节点名称, 节点默认会去加入一个名称为"elasticsearch"的集群(可配置), 若干节点会自动组成集群. 集群中的节点可以有多种角色, 集群会根据节点连通性自动将节点加入集群或从集群删除 Index: 索引可以理解为一个数据库(这个索引的概念不同于数据库索引的含义), 是具有相同结构的文档集合, 索引以名称作为标识, 每个集群中都可以有多个索引 Type: 类型相当于关系数据库中的表, 每个索引里都可以有一个或多个type, type是index中的一个逻辑数据分类, 一个type下的document, 都有相同的field. type是index和document之间的逻辑细分, 但是实际环境中一个索引下的文档不一定具有相同的结构, 自6.0.0版本开始每个索引下仅允许有一个type(默认为_doc), 7.0.0版本已不建议使用, 8.0.0版本将不再支持 Document: 文档相当于关系数据库中表中的行, 它是能够被索引的最小数据单元, 通常是结构化json数据, 同一索引下的文档结构并不要求相同. 文档中除了原始的json数据(_source)外, 还包括一些额外的元数据字段 Field: 字段相当于关系数据库中表的字段, 对于结构化的document, 每一层嵌套的key都是一个字段 Shard: 分片是对索引数据的切分, ElasticSearch可以将一个索引中的数据切分为多个分片, 分布在多台服务器上存储. 有了shard就可以横向扩展, 存储更多数据, 让搜索和分析等操作分布到多台服务器上去执行, 提升吞吐量和性能. 每个shard都是一个lucene index Replica: 每个分片可以有多个replica副本. replica可以在shard故障时提供备用服务, 保证数据不丢失, 多个replica还可以提升搜索操作的吞吐量和性能. 建立索引时可以指定primary shard主分片数量和replica shard副本分片数量, 主分片后续不允许修改, 但副本分片数量可以随时修改, 一个索引的主分片和副本分片不能存在于同一个节点上. 旧版本默认每个索引5个主分片, 每个主分片1个副本分片, 一共10个shard, 新版本后每个索引默认1个主分片 Allocation: 分配是指将分片分配给某个节点的过程, 包括分配主分片或者副本. 如果是副本, 还包含从主分片复制数据的过程. Allocation操作发生在故障恢复, 副本分配, Rebalancing, 节点的新增和删除等场景, master节点的主要职责就是决定分片分配到哪一个节点, 并且做分片的迁移来平衡集群 Rebalancing: 再平衡是在集群的不同节点之间移动分片的过程. 默认情况下, Elasticsearch会自动尝试把分片和副本在集群中均衡分布, 也允许用户进行手动再平衡控制 Lucene: Lucene是一个开源的全文检索引擎工具包, ElasticSearch是以Lucene为核心的封装 Analyzer: ElasticSearch借助各种类型的分词器来对文档内容进行分词处理, 以便于创建倒排索引, 这是搜索的核心. 同时也对搜索内容进行分词处理, 用以在倒排索引中索引文档. ElasticSearch内置一些简单的分词器, 也支持以插件的形式安装外部分词器 Segment: lucene内部的数据是由一个个segment组成的, 写入lucene的数据并不直接落盘, 而是先写在内存中, 经过了refresh间隔, lucene才将该时间段写入的全部数据refresh成一个segment, segment多了之后会进行merge成更大的segment. lucene查询时会遍历每个segment完成. 由于lucene写入的数据是在内存中完成, 所以写入效率非常高. Translog: lucene内存写入的特性虽然效率高, 但是也存在丢失数据的风险, 所以ElasticSearch基于此问题实现了translog预写日志机制, translog会在数据写入内存的同时进行落盘, 只有在segment数据落盘后, ElasticSearch才会删除对应的translog Term: term是lucene中索引的最小单位, 某个field对应的内容如果是全文检索类型, 会将内容进行分词, 分词的结果就是由term组成的. 如果是不分词的字段, 那么该字段的内容就是一个term InvertedIndex: 倒排索引是一种反向索引, 实现了term到doc list的映射(doc list即正排数据), 包含单词词典和倒排列表两部分. 区别于正排索引(ForwardIndex), 倒排索引不是通过文档ID去检索内容, 而是根据检索的内容找到对应的文档ID. 倒排索引广泛应用于搜索引擎中 Docvalues: ElasticSearch中的列式存储的名称, ElasticSearch除了存储原始存储、倒排索引, 还存储了一份docvalues, 用作分析和排序. FullTextSearch: 为了提高对非结构化数据的检索速度, 将非结构化数据中的一部分信息提取出来, 重新组织, 使其变得有一定结构, 然后对此有一定结构的数据进行搜索. 这部分从非结构化数据中提取出的然后重新组织的信息, 称之为索引. 全文检索是一种先建立索引, 再对索引进行搜索的检索过程. 架构特性 集群架构
数据模型
读写请求
ElasticSearch是一个 P2P 类型(使用 gossip 协议)的分布式系统, 除了集群状态管理以外, 其他所有的请求都可以发送到集群内任意一台节点上, 这个节点可以自己找到需要转发给哪些节点, 并且直接跟这些节点通信
集群中会有一个master负责当leader进行协调, 当leader宕机的时候会重现选举一个新的master. 宕机节点上如果存在主分片, 则其他正常节点上的副本分片将自动升级为主分片, 宕机节点恢复后, 其上的主分片将自动降级为副本分片
数据写入流程:
ElasticSearch在写入数据的时候, 采用内存buff+文件系统缓存+磁盘三级结构, 确保写入的数据能够近实时的被检索到, 大致过程如下:
数据首先写入到 Index buffer(内存) 和 Transaction log(落盘) 中, 即便内存数据丢失, 也可读取磁盘中的 Transaction log, 此时数据是检索不到的 默认 1s 一次的 refresh 操作将 Index buffer 中的数据写入文件系统缓存 segments(os cache), 清空Indexbuffer数据, 此时数据可检索到 默认每隔30分钟或者Transaction log 满(默认512M)会执行一次的 flush 操作, 首先将commit point写入磁盘文件, 标识这个commit point对应的所有的segment file, 同时强行将os cache中目前所有的数据都fsync到磁盘文件, 同时清空 Transaction log, 重启一个translog, 此时commit操作完成 merge 操作, 定期合并 segment ElasticSearch 中的每个索引操作首先使用路由解析到一个副本组, 通常基于文档ID. 一旦确定了副本组, 操作将在内部转发到组的当前主分片. 主分片负责验证数据格式并将其转发到其他副本
由于副本可以由主分片异步复制, 所以不需要主副本复制到所有副本. 相反, ElasticSearch 维护一个应该接收操作的副本分片列表. 这个列表称为同步副本, 由主节点维护. 顾名思义, 这些是一组保证处理了所有已向用户确认的索引操作和删除操作的分片副本. 主分片负责维护, 因此必须将所有操作复制到这个集合中的每个副本分片
主分片遵循以下基本流程:
验证传入操作并在结构无效时拒绝它(例如:插入时字段格式与 mapping 不匹配)
在本地执行操作, 即索引或删除相关文档. 将验证字段的内容, 并在需要时拒绝(例如:关键字值太长, 无法在Lucene中进行索引)
将操作转发到当前同步复制集中的每个副本分片. 如果有多个副本分片, 则并行执行
一旦所有同步复制集的副本分片都成功地执行了操作并响应了主分片, 主副本就会向客户端确认请求成功完成
数据读取流程:
ElasticSearch分片使用主备模型. 主备份模型的一个优点是, 主分片和其所有副本分片存有相同的数据. 因此, 一个同步副本就足以满足读请求
ElasticSearch中的读取可以直接使用 document ID, 也可以是非常复杂的搜索, 包含复杂的聚合, 这个操作会占用大量CPU资源
当节点接收到读请求时, 该节点负责将其转发给包含相关分片的节点、整合所有分片的返回值并响应客户端(类似于一个MapReduce), 我们将该节点称为请求的协调节点. 基本流程如下:
将读请求解析到相关分片. 由于大多数搜索将被发送到一个或多个索引, 因此它们通常需要从多个分片中读取, 每个分片表示数据的不同子集
在分片复制组中选择每个相关分片的活动副本. 这可以是主分片, 也可以是副本分片. 默认情况下, Elasticsearch只是在副本分片之间进行循环
将分片级别的读请求发送到所选副本
整合结果并做出响应. 在get by ID查找的情况下, 只有一个分片是相关的, 可以跳过这一步
存储结构
ElasticSearch可通过以下变量配置存储路径:
path.home: 运行Elasticsearch进程的用户的主目录. 默认为Java系统属性user.dir, 它是进程所有者的默认主目录 path.conf: 包含配置文件的目录. 这通常通过设置Java系统属性es.config来设置, 因为在找到配置文件之前它必然会被解析 path.plugins: 子文件夹为Elasticsearch插件的目录. 这里支持Sym-links, 当从同一个可执行文件运行多个Elasticsearch实例时, 可以使用它来有选择地启用/禁用某个Elasticsearch实例的一组插件 path.logs: 存储生成的日志的位置. 如果其中一个卷的磁盘空间不足, 则将它放在与数据目录不同的卷上可能是有意义的 path.data: 包含Elasticsearch存储的数据的文件夹的路径 由于Elasticsearch使用Lucene来处理分片级别的索引和查询, 因此数据目录(path.data)中的文件由Elasticsearch和Lucene写入. 两者的职责都非常明确:
Lucene负责写和维护Lucene索引文件 Elasticsearch在Lucene之上写与功能相关的元数据, 例如字段映射, 索引设置和其他集群元数据 ElasticSearch中每一个分片相当于Lucene中的一个索引
数据目录层级结构如下:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 0 # 节点编号 ├── node.lock # lock文件用于确保一次只能从一个数据目录读取/写入一个ES相关安装信息 ├── _state # 集群元数据信息目录 │ ├── global-8.st # 集群全局元数据 │ └── node-0.st # 节点全局元数据 └── indices # 索引目录 └── RMZHgey3SpmgtRbaXYY4Mg # 索引ID为名的索引数据目录 ├── _state # 索引元数据信息目录 │ └── state-2.st # 索引元数据 └── 0 # 索引分片编号 ├── _state # 分片元数据信息目录 │ ├── retention-leases-0.st # 分片历史存留期元数据(用于回放) │ └── state-0.st # 分片元数据 ├── translog # 分片事务(预写)日志目录 │ ├── translog-5.ckp │ ├── translog-5.tlog │ ├── translog-6.tlog # 分片事务日志 │ └── translog.ckp # 当前检查点 └── index # 分片数据目录, 为lucene记录的数据. lucene index相当于es shard ├── _1lj.si # segment元数据 ├── _1lj.cfs # segment数据数据量小时的数据内容 ├── _1lj.cfe # segment各个文件(以下皆是)在cfs文件中的位置信息 ├── _1lj.dii # 多维数据, 地理位置等信息, 用于处理数值型的查询 ├── _1lj.dim # 多维数据, 地理位置等信息, 用于处理数值型的查询 ├── _1lj.fnm # fields相关信息 ├── _1lj.fdt # field数据文件内容 ├── _1lj.fdx # field数据文件索引 ├── _1lj_Lucene50_0.doc # 每个term的doc id列表和term在doc中的词频 ├── _1lj_Lucene50_0.tim # 倒排索引元数据信息(term词典) ├── _1lj_Lucene50_0.tip # 倒排索引数据内容(term索引) ├── _1lj_Lucene70_0.dvd # 文档正排数据 ├── _1lj_Lucene70_0.dvm # 文档正排元数据 ├── segments_a # segment检查点信息 └── write.lock # 写锁防止多个IndexWriters写入同一个文件 节点组件
每个ElasticSearch节点都包含以下功能组件:
组件 模块 描述 存储网关 Gateway ES用来存储索引的文件系统. 支持多种类型, 包括本地文件系统(默认), HDFS, S3等 搜索引擎 Distributed Lucene Directory 分布式的lucene搜索引擎框架, 包含Lucene-core 核心模块 Index Module 索引模块. 控制与所有索引全局管理的与索引相关的设置, 而不是在每个索引级别上可配置 Search Module 执行分布式搜索查询并返回与查询匹配的搜索结果 Mapping 映射类似于数据库中的表结构定义schema, 用于定义索引中的字段名, 字段数据类型和字段倒排索引的相关配置, 支持自定义映射和动态映射 其他模块 Discovery ES的节点发现模块, 不同机器上的ES节点要组成集群需要进行消息通信, 集群内部需要选举master节点, 这些工作都是由Discovery模块完成. 支持多种发现机制, 如 Zen 、EC2、gce、Azure Scripting 用来支持在查询语句中插入javascript、python等脚本语言, scripting模块负责解析这些脚本, 使用脚本语句性能稍低. 预先定义好脚本内容, 然后在mapping阶段或者search指定需要的脚本, 相对于脚本语句查询来说提高性能 3rd Plugins 支持多种第三方插件 用户接口 Transport ES的传输模块, 支持多种传输协议, 如 Thrift、memecached、http. 默认使用http JMX java的管理框架, 用来管理ES应用 Restful API 通过RESTful接口和ES集群进行交互 Java(Netty) ES基于Java Netty开源网络框架作为节点之间以及客户端与服务器间TCP和HTTP通信协议的底层实现 节点角色
ElasticSearch中的节点分为多种角色, 除Tribe外, 节点默认拥有下述所有角色(Master
节点同时只有一个, 但所有节点都可以是Master候选节点).
Master: Master节点用于管理和控制Elasticsearch集群, 并负责在集群范围内创建删除索引, 跟踪哪些节点是集群的一部分, 并将分片分配给这些节点. 主节点一次处理一个集群状态, 并将状态广播到所有其他节点, 这些节点需要响应并确认主节点的信息. Master节点同一时刻只有一个, 但可以有多个Matesr候选节点(master-eligible) Data: Data节点保存数据并执行与数据相关的操作, 如CRUD、搜索和聚合等, 通常中大型集群中Master节点都会设置为非Data节点. Data节点又可以细分为data_content,data_hot, data_warm, data_cold, or data_frozen等角色 Remote: 能够作为远程客户端的节点 MachineLearn: 能够处理机器学习相关操作的节点 Transform: 处理数据转换工作的节点 Ingest: Ingest节点是预处理节点, 能够在索引操作之前对document进行增强或者丰富的预处理操作, 预处理类似于ETL操作, 该操作发生在bulk和index之前, 通过pipeline和processor的方式实现 Coordinating: Coordinating节点作为负载路由器, 将传入的请求路由到集群中的不同节点. coordinating节点处理客户端的请求一般分为两个阶段: 第一阶段, 收到客户端的请求并路由到合适的分片(包含请求数据的主分片), 第二阶段对结果做聚合. 所有节点都是coordinating节点且不可关闭 Tribe: Tribe节点一种特殊的coordinating节点, 它可以连接到多个集群, 并在多个集群上执行搜索或者其他操作, 对于涉及到多个集群之间的查询, 可以使用tribel node的方式, 但是tribel node是以coordinating node的方式加入到各个集群中, master的变更任务必须要等Tribe node的返回, tribe的问题显而易见, 所以elasticsearch在高版本引入了Cross Cluster Search 集群健康值
ElasticSearch以Green, Yellow和Red三个状态标识集群健康程度. 其中Green表示集群中所有的主分片和副本分片都是可用的. Yellow表示集群中所有主分片是可用的, 但存在不可用的副本分片. Red表示集群中存在不可用的主分片.
由于主分片不可用后副本分片会自动升级为主分片, 因此如果集群状态为Red, 表示保存了某些数据的主分片和副本分片都不存在了, 出现数据缺失. 但Red状态的集群仍然能够提供读写服务, 只是检索到的数据可能是不完整的
分词器
ElasticSearch借助各种类型的分词器来对文档内容进行分词处理, 以便于创建倒排索引, 这是搜索的核心. 同时也对搜索内容进行分词处理, 用以在倒排索引中索引文档
内置分词器
标准分词器(standard analyzer)(默认)
分析过程: 字符过滤器->字符处理->分词过滤(分词转换)
说明: 首先是字符过滤器过滤掉特殊符号以及量词(the、an、a等), 进一步将分词小写处理
英文分词器(english analyzer)
分析过程: 字符过滤器->字符处理->分词过滤(分词转换, 词干转化)
说明: 首先是字符过滤器过滤掉特殊符号以及量词(the、an、a等), 进一步将分词小写处理, 再次进行分词转换, 例如: eating -> eat, 其实它们两是一回事
简单分词器(simple analyzer)
先按照空格分词, 英文大写转小写
空格分词器(whitespace analyzer)
先按照空格分词, 英文不做大小写处理
外部分词器
ElasticSearch支持以插件的方式安装外部分词器以满足更多复杂的分词需求
中文分词器(ik_maxword)
会将文本做最细粒度的拆分, 尽可能多的拆分出词语, 例如: 如南京市长江大桥 &ndash;> 南京市/南京/市长/长江大桥/长江/大桥
中文分词器(ik_smart)
会做最粗粒度的拆分, 已被分出的词语将不会再次被其它词语占有, 如南京市长江大桥 &ndash;> 南京市/长江大桥
分片分配
Allocation是指将分片分配给某个节点的过程, 包括分配主分片或者副本. 如果是副本, 还包含从主分片复制数据的过程. Allocation操作发生在故障恢复, 副本分配, Rebalancing, 节点的新增和删除等场景. master节点的主要职责就是决定分片分配到哪一个节点, 并且做分片的迁移来平衡集群.
Shard allocation filters
allocation filters允许执行分片分配之前, 前置一些filter操作, 可以基于_name, _host_ip, _publish_ip, _ip, _host and _id 等属性.
例如计划下线一个node, 可以设置不允许给该node分配分片:
1 2 3 4 5 6 PUT _cluster/settings { "transient" : { "cluster.routing.allocation.exclude._ip" : "10.0.0.1" } } disk-based shard allocation
es在进行shard allocation的时候, 会充分考虑每一个node的可用磁盘空间, 具体有如下配置:
cluster.routing.allocation.disk.threshold_enabled: 默认是true, 如果是false会禁用基于disk的考虑 cluster.routing.allocation.disk.watermark.low: 控制磁盘使用率的低水位, 默认是85%, 如果一个节点的磁盘空间使用率已经超过了85%, 那么就不会分配shard给这个node了 cluster.routing.allocation.disk.watermark.high: 控制磁盘使用率的高水位, 默认是90%, 如果一个节点的磁盘空间使用率已经超过90%了, 那么就会将这个node上的部分shard移动走 cluster.info.update.interval: es检查集群中每个node的磁盘使用率的时间间隔, 默认是30s cluster.routing.allocation.disk.include_relocations: 默认是true, 意味着es在计算一个node的磁盘使用率的时候, 会考虑正在分配给这个node的shard 别名系统
ElasticSearch中可以为索引添加别名, 一个别名可以指向到多个索引中, 同时在添加别名时可以设置筛选条件, 指向一个索引的部分数据, 实现在关系数据库汇总的视图功能. 别名是一个非常实用的功能, 为我们使用索引提供了极大的灵活性, 许多ElasticSearch的API都支持用别名来代替真实索引名. 通过索引我们可以方便的进行以下操作:
实现正在运行的集群上的一个索引到另一个索引之间的无缝切换. 试想一下这种场景, 由于业务变换, 我们需要将业务数据有索引1变换到新的索引2上, 如果没有别名, 我们必须修改和中断业务系统, 但是有了别名, 只需要修改别名, 令其指向新的索引2即可, 这样的操作可以在用户无任何感知的情况下完成 使数据检索等操作更加方便. 假设有两个月的日志数据, 分别存放在index_202008和index_202009两个索引中, 没有使用别名进行检索时, 我们需要同时写上两个索引名称进行检索, 使用别名后, 我们可以令别名同时指向这两个索引, 检索时只需要使用这个别名就可以同时在两个索引中进行检索 为一个索引中的部分数据创建别名. 例如一个索引中存放了一整年的数据, 现在新增一个业务场景, 更多的是对其中某一个月的数据进行检索, 这时我们可以在创建别名时, 通过设置过滤条件filter, 可以单独令别名指向一个月的数据, 使得检索更加高效 ElasticSearch中别名可以指向一个索引, 也可以同时指向多个索引, 甚至可以通过配合过滤器filter指向索引中部分数据. 别名可以在创建索引时添加, 也可以在索引创建后进行添加. ElasticSearch中提供丰富的API对别名进行管理
此外, ElasticSearch也支持通过mapping的方式为字段创建别名
应用场景
全文检索, 搜索引擎, 数据分析, 日志存储, 商业智能, 可观察性
配置文件 $ES_HOME/config/elasticsearch.yml: ElasticSearch核心配置文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 # 配置的集群名称, 默认是elasticsearch, es服务会通过广播方式自动连接在同一网段下的es服务, 通过多播方式进行通信, 同一网段下可以有多个集群, 通过集群名称这个属性来区分不同的集群 cluster.name: elasticsearch # 手动设置初始的集群master候选节点集合 cluster.initial_master_nodes: ["node-a"] # 当前配置所在机器的节点名, 你不设置就默认随机指定一个name列表中名字, 该name列表在es的jar包中config文件夹里name.txt文件中, 其中有很多作者添加的有趣名字. node.name: "node-a" # 指定该节点是否有资格被选举成为master node(注意这里只是设置成有资格, 不代表该node一定就是master), 默认是true, es是默认集群中的第一台机器为master, 如果这台机挂了就会重新选举master node.master: true # 指定该节点是否存储索引数据, 默认为true node.data: true # 设置默认索引主分片个数, 默认为1片 index.number_of_shards: 1 # 设置默认索引副本个数, 默认为1个副本. 如果采用默认设置, 而你集群只配置了一台机器, 那么集群的健康度为yellow, 也就是所有的数据都是可用的, 但是某些复制没有被分配 # (健康度可用 curl 'localhost:9200/_cat/health?v' 查看, 分为绿色、黄色或红色. 绿色代表一切正常, 集群功能齐全, 黄色意味着所有的数据都是可用的, 但是某些复制没有被分配, 红色则代表因为某些原因, 某些数据不可用) index.number_of_replicas: 1 # 设置配置文件的存储路径, 默认是es根目录下的config文件夹 path.conf: /path/to/conf # 设置索引数据的存储路径, 默认是es根目录下的data文件夹, 可以设置多个存储路径, 用逗号隔开, 例如: # path.data: /path/to/data1,/path/to/data2 path.data: /path/to/data # 设置临时文件的存储路径, 默认是es根目录下的work文件夹 path.work: /path/to/work # 设置日志文件的存储路径, 默认是es根目录下的logs文件夹 path.logs: /path/to/logs # 设置插件的存放路径, 默认是es根目录下的plugins文件夹,, 插件在es里面普遍使用, 用来增强原系统核心功能 path.plugins: /path/to/plugins # 备份数据的存放路径 path.repo: /path/to/repo # 设置为true来锁住内存不进行swapping. 因为当jvm开始swapping时es的效率会降低, 所以要保证它不swap, 可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值, 并且保证机器有足够的内存分配给es. 同时也要允许elasticsearch的进程可以锁住内存, linux下启动es之前可以通过`ulimit -l unlimited`命令设置 # 确保 ES_MIN_MEM 和 ES_MAX_MEM 环境变量设置为相同的值, 以及机器有足够的内存分配给Elasticsearch # 注意: 内存也不是越大越好, 一般64位机器, 最大分配内存别才超过32G bootstrap.mlockall: true # 设置插件作为启动条件, 如果指定的插件没有安装, 则该节点服务不会启动 # plugin.mandatory: mapper-attachments,lang-groovy # 设置绑定的ip地址, 可以是ipv4或ipv6的, 默认为0.0.0.0, 绑定这台机器的任何一个ip network.bind_host: 192.168.0.1 # 设置其它节点和该节点交互的ip地址, 如果不设置它会自动判断, 值必须是个真实的ip地址 network.publish_host: 192.168.0.1 # 这个参数是用来同时设置bind_host和publish_host上面两个参数 network.host: 192.168.0.1 # 设置节点之间交互的tcp端口, 默认是9300 transport.tcp.port: 9300 # 设置是否压缩tcp传输时的数据, 默认为false, 不压缩 transport.tcp.compress: true # 是否使用http协议对外提供服务, 默认为true, 开启 http.enabled: true # 设置对外服务的http端口, 默认为9200 http.port: 9200 # 设置对外http服务是否允许跨域, 默认为false http.cors.enabled: true # 设置http服务跨域白名单 http.cors.allow-origin: "*" # 浏览器会发送一个"预检"的OPTIONS请求, 来检查CORS设置. max-age定义应该缓存多长时间的结果. 默认为1728000(20天) http.cors.max-age: 1728000 # 设置内容的最大容量, 默认100mb http.max_content_length: 100mb # HTTP请求URL的最大长度, 默认4kb http.max_initial_line_length: 4096 # 请求头的最大大小, 默认8kb http.max_header_size: 8196 # 是否支持压缩(使用Accept-Encoding), 默认false http.compression: false # 定义使用的压缩级别, 默认为6 http.compression_level: 6 # 定义了允许的请求方式, 默认允许OPTIONS, HEAD, GET, POST, PUT, DELETE http.cors.allow-methods: ["GET"] # 定义了允许的请求头信息. 默认允许X-Requested-With, Content-Type, Content-Length http.cors.allow-headers: ["Content-Type"] # 是否返回设置的Access-Control-Allow-Credentials头信息. 默认为false http.cors.allow-credentials: false # 是否输出详细的错误信息和堆栈. 默认为true http.detailed_errors.enabled: true # 是否启用HTTP管道支持. 默认为true http.pipelining: true # 在一个HTTP连接被关闭之前内存队列中允许的最大的事件数量, 默认为10000. 该模块也可使用一些公共的网络配置(见网络设置一节) http.pipelining.max_events: 10000 # 是否启用x-pack安全验证, 默认为false xpack.security.enabled: true # 免费版本license为basic xpack.license.self_generated.type: basic # 是否启用http对外服务加密通信, 默认为false xpack.security.http.ssl.enabled: true # 集群对外http服务加密通信验证模式 xpack.security.http.ssl.verification_mode: certificate # 集群对外http服务加密通信凭证文件(p12默认将私钥和证书整合在一起) xpack.security.http.ssl.keystore.path: elastic-certificates.p12 # 集群对外http服务加密通信ca凭证文件(p12默认将私钥和证书整合在一起) # http仅作服务端验证所以服务端可以不需要配置ca凭证 xpack.security.http.ssl.truststore.path: elastic-certificates.p12 # 集群节点间是否启用加密通信, 默认为false xpack.security.transport.ssl.enabled: true # 集群节点间加密通信验证模式 xpack.security.transport.ssl.verification_mode: certificate # 集群节点间加密通信凭证文件(p12默认将私钥和证书整合在一起) xpack.security.transport.ssl.keystore.path: elastic-certificates.p12 # 集群节点间加密通信ca凭证文件(p12默认将私钥和证书整合在一起) # 节点间需要相互验证(所有节点同时是客户端和服务端), 所以需要配置ca凭证 xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 # 另一种加密凭证配置方式 xpack.security.http.ssl.key: certs/node1.key xpack.security.http.ssl.certificate: certs/node1.crt xpack.security.http.ssl.certificate_authorities: certs/ca.crt xpack.security.transport.ssl.key: certs/node1.key xpack.security.transport.ssl.certificate: certs/node1.crt xpack.security.transport.ssl.certificate_authorities: certs/ca.crt # gateway的类型, 默认为local即为本地文件系统, 可以设置为本地文件系统, 分布式文件系统, hadoop的HDFS, 和amazon的s3服务器等 gateway.type: local # 设置集群中N个节点启动时进行数据恢复, 默认为1 gateway.recover_after_nodes: 1 # 设置初始化数据恢复进程的超时时间, 默认是5分钟 gateway.recover_after_time: 5m # 设置这个集群中节点的数量, 默认为2, 一旦这N个节点启动, 就会立即进行数据恢复 gateway.expected_nodes: 2 # 初始化数据恢复时, 并发恢复线程的个数, 默认为4 cluster.routing.allocation.node_initial_primaries_recoveries: 4 # 添加删除节点或负载均衡时并发恢复线程的个数, 默认为4 cluster.routing.allocation.node_concurrent_recoveries: 4 # 设置数据恢复时限制的带宽, 如100mb, 默认为0, 即无限制 indices.recovery.max_size_per_sec: 0 # 设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数, 默认为5 indices.recovery.concurrent_streams: 5 # 提供集群中其他主机列表以便更快的发现主机, 格式为ip/domain+可选的端口 discovery.seed_hosts: ["192.168.0.2:9300"] # 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点, 默认为1, 对于大的集群来说, 可以设置大一点的值(2-4) discovery.zen.minimum_master_nodes: 1 # 设置集群中自动发现其它节点时ping连接超时时间, 默认为3秒, 对于比较差的网络环境可以高点的值来防止自动发现时出错 discovery.zen.ping.timeout: 3s # 设置是否打开多播发现节点, 默认是true discovery.zen.ping.multicast.enabled: true # 设置集群中master节点的初始列表, 可以通过这些节点来自动发现新加入集群的节点 discovery.zen.ping.unicast.hosts: ["host1", "host2:port", "host3[portX-portY]"] ############## Memory(重点需要调优的部分) ################ # Cache部分: # es有很多种方式来缓存其内部与索引有关的数据. 其中包括filter cache # filter cache部分: # filter cache是用来缓存filters的结果的. 默认的cache type是node type. node type的机制是所有的索引内部的分片共享filter cache. node type采用的方式是LRU方式, 即:当缓存达到了某个临界值之后, es会将最近没有使用的数据清除出filter cache.使让新的数据进入es # 这个临界值的设置方法如下: indices.cache.filter.size 值类型: eg.:512mb 20%. 默认的值是10% # out of memory错误避免过于频繁的查询时集群假死 # 1.设置es的缓存类型为Soft Reference, 它的主要特点是据有较强的引用功能. 只有当内存不够的时候, 才进行回收这类内存, 因此在内存足够的时候, 它们通常不被回收. 另外,这些引用对象还能保证在Java抛出OutOfMemory异常之前, 被设置为null. 它可以用于实现一些常用图片的缓存, 实现Cache的功能, 保证最大限度的使用内存而不引起OutOfMemory. 在es的配置文件加上index.cache.field.type: soft即可 # 2.设置es最大缓存数据条数和缓存失效时间, 通过设置index.cache.field.max_size: 50000来把缓存field的最大值设置为50000, 设置index.cache.field.expire: 10m把过期时间设置成10分钟 # index.cache.field.max_size: 50000 # index.cache.field.expire: 10m # index.cache.field.type: soft # field data部分&amp;&amp;circuit breaker部分: # 用于fielddata缓存的内存数量, 主要用于当使用排序, faceting操作时, elasticsearch会将一些热点数据加载到内存中来提供给客户端访问, 但是这种缓存是比较珍贵的, 所以对它进行合理的设置 # 可以使用值: eg:50mb 或者 30％(节点 node heap内存量), 默认是: unbounded # indices.fielddata.cache.size: unbounded # field的超时时间. 默认是-1, 可以设置的值类型: 5m #indices.fielddata.cache.expire: -1 # circuit breaker部分: # 断路器是elasticsearch为了防止内存溢出的一种操作, 每一种circuit breaker都可以指定一个内存界限触发此操作, 这种circuit breaker的设定有一个最高级别的设定: indices.breaker.total.limit 默认值是JVM heap的70%. 当内存达到这个数量的时候会触发内存回收 # 另外还有两组子设置: # indices.breaker.fielddata.limit: 当系统发现fielddata的数量达到一定数量时会触发内存回收. 默认值是JVM heap的70% # indices.breaker.fielddata.overhead: 在系统要加载fielddata时会进行预先估计, 当系统发现要加载进内存的值超过limit * overhead时会进行进行内存回收. 默认是1.03 # indices.breaker.request.limit: 这种断路器是elasticsearch为了防止OOM(内存溢出), 在每次请求数据时设定了一个固定的内存数量. 默认值是40% # indices.breaker.request.overhead: 同上, 也是elasticsearch在发送请求时设定的一个预估系数, 用来防止内存溢出. 默认值是1 # Translog部分: # 每一个分片(shard)都有一个transaction log或者是与它有关的预写日志(write log), 在es进行索引(index)或者删除(delete)操作时会将没有提交的数据记录在translog之中, 当进行flush 操作的时候会将tranlog中的数据发送给Lucene进行相关的操作. 一次flush操作的发生基于如下的几个配置: # index.translog.flush_threshold_ops: 当发生多少次操作时进行一次flush. 默认是unlimited # index.translog.flush_threshold_size: 当translog的大小达到此值时会进行一次flush操作. 默认是512mb # index.translog.flush_threshold_period: 在指定的时间间隔内如果没有进行flush操作, 会进行一次强制flush操作. 默认是30m # index.translog.interval: 多少时间间隔内会检查一次translog, 来进行一次flush操作. es会随机的在这个值到这个值的2倍大小之间进行一次操作, 默认是5s # index.gateway.local.sync: 多少时间进行一次的写磁盘操作, 默认是5s # 以上的translog配置都可以通过API进行动态的设置 - See more at: http://bigbo.github.io/pages/2015/04/10/elasticsearch_config/#sthash.AvOSUcQ4.dpuf elasticsearch免费版本的license为basic, 只提供一个名为elastic的服务帐号, 密码通过bin/elasticsearch-setup-passwords interactive命令进行交互式的设置
$ES_HOME/config/jvm.options: ElasticSearch jvm参数配置文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # 设置年老代为并发收集. 配置这个以后, -XX:NewRatio=4的配置失效了. 所以, 此时年轻代大小最好用-Xmn设置 -XX:+UseConcMarkSweepGC #表示年老代空间到70%时就开始执行CMS, 确保年老代有足够的空间接纳来自年轻代的对象 -XX:CMSInitiatingOccupancyFraction=75 # 使用手动定义初始化定义开始CMS收集, 禁止hostspot自行触发CMS GC -XX:+UseCMSInitiatingOccupancyOnly # VM就会先访问所有分配给它的内存, 让操作系统把内存真正的分配给JVM. 后续JVM就可以顺畅的访问内存了 -XX:+AlwaysPreTouch # server模式运行 -server # 每个线程的堆栈大小1m -Xss1m # 对于一个Java服务器来说经常要处理一些图形元素, 这些API基本上总是需要运行一个X-server以便能使用AWT. 然而, 运行一个不必要的X-server并不是一种好的网络管理方式. 开启此配置可以禁用X-server -Djava.awt.headless=true # 编码为utf8编码 -Dfile.encoding=UTF-8 # 始终使用提供的JNA与系统之一 -Djna.nosys=true # 处理和存储path规范 -Djdk.io.permissionsUseCanonicalPath=true # 使用Heap堆内存创建ByteBuf -Dio.netty.noUnsafe=true # 没有密钥集 -Dio.netty.noKeySetOptimization=true # netty回收配置, 每个线程最大容量 -Dio.netty.recycler.maxCapacityPerThread=0 # log4j配置, 是否允许关闭hook -Dlog4j.shutdownHookEnabled=false # 是否禁用jmx -Dlog4j2.disable.jmx=true # ConsoleAppender不会尝试在Windows上使用Jansi输出流 -Dlog4j.skipJansi=true # 输出Heap Dump到指定文件 -XX:+HeapDumpOnOutOfMemoryError # 初始堆内存大小 -Xmx1g # 最大堆内存大小 -Xms1g 其他配置通常都使用默认值. 主要是调整JVM堆内存配置, 通常需要保持最大堆(xms)和最小堆(xmx)内存的一致, 默认值是1g 此参数也可以通过环境变量ES_JAVA_OPTS进行指定: ES_JAVA_OPTS="-Xms4g -Xmx4g"
最好将堆内存设置为ElasticSearch服务可用内存的一半(但不超过32g, 更多的内存反而影响性能), 剩下的可用内存会被Lucene消耗
堆内存和Lucene内存分配原则: 默认各占一半, 堆内存用于数据排序聚合等, 偏数据分析场景, Lucene内存用于分词和检索缓存, 偏全文检索场景. 根据使用场景调整二者内存分配
参考文档: https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html#heap-size-settings
$ES_HOME/config/log4j2.properties: ElasticSearch日志参数配置文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 status = error # log action execution errors for easier debugging logger.action.name = org.elasticsearch.action logger.action.level = debug appender.console.type = Console appender.console.name = console appender.console.layout.type = PatternLayout appender.console.layout.pattern = %d{ISO8601} %p [%t] %c - %m%n # 配置 RollingFile 附加器 appender.rolling.type = RollingFile # 集群日志的 appender 标签名称 appender.rolling.name = rolling # 日志输出路径: /home/es/logs/es/XX[集群名称]-cluster.log （路径从 elasticsearch.yml 配置文件中获取） appender.rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-cluster.log appender.rolling.layout.type = PatternLayout appender.rolling.layout.pattern = %d{ISO8601} %p [%t] %c:%M:%L - %m%n # 将日志滚动到 /home/es/logs/es/XX[集群名称]-yyyy-MM-dd-%i.log appender.rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.log appender.rolling.policies.type = Policies # 使用基于时间的滚动策略 appender.rolling.policies.time.type = TimeBasedTriggeringPolicy # 每天滚动日志 appender.rolling.policies.time.interval = 1 # 在天数边界上对齐滚动（而不是每24h滚动一次） appender.rolling.policies.time.modulate = true appender.rolling.policies.size.type = SizeBasedTriggeringPolicy # 日志文件每达到 1GB 大小进行一次滚动 appender.rolling.policies.size.size = 1GB # 当天日志文件最多保留 3 个 appender.rolling.strategy.max = 3 # 配置 DefaultRolloverStrategy appender.rolling.strategy.type = DefaultRolloverStrategy # 配置 Delete 用于处理翻转操作 appender.rolling.strategy.action.type = Delete # ES日志基本路径 appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path} # 如果超过指定天数的文件, 则仅删除5天以上的文件 appender.rolling.strategy.action.condition.type = IfFileName # 从与 glob 匹配的基本路径中删除文件 ${sys:es.logs.cluster_name}-*；这是日志文件滚动到的位置；仅删除滚动的es集群日志, 而不删除其他日志时才需要这样做 appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* # 处理过渡时适用的条件 appender.rolling.strategy.action.condition.nested_condition.type = IfLastModified # 日志保留5天 appender.rolling.strategy.action.condition.nested_condition.age = 5D # 日志级别 rootLogger.level = info rootLogger.appenderRef.console.ref = console rootLogger.appenderRef.rolling.ref = rolling # 可以加载多个配置文件（在这种情况下, 它们将被合并）, 只要它们被命名 log4j2.properties 并将 Elasticsearch config 目录作为祖先即可 appender.deprecation_rolling.type = RollingFile # deprecation 日志的 appender 标签名称 appender.deprecation_rolling.name = deprecation_rolling # deprecation 日志路径和日志格式 appender.deprecation_rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_deprecation.log appender.deprecation_rolling.layout.type = PatternLayout appender.deprecation_rolling.layout.pattern = %d{ISO8601} %p [%t] %c:%M:%L - %m%n # If you append .gz or .zip to appender.rolling.filePattern, then the logs will be compressed as they are rolled. appender.deprecation_rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_deprecation-%d{yyyy-MM-dd}-%i.log.gz appender.deprecation_rolling.policies.type = Policies appender.deprecation_rolling.policies.size.type = SizeBasedTriggeringPolicy appender.deprecation_rolling.policies.size.size = 1GB appender.deprecation_rolling.strategy.max = 3 appender.deprecation_rolling.strategy.type = DefaultRolloverStrategy appender.deprecation_rolling.strategy.action.type = Delete appender.deprecation_rolling.strategy.action.basepath = ${sys:es.logs.base_path} appender.deprecation_rolling.strategy.action.condition.type = IfFileName # 从与 glob 匹配的基本路径中删除文件 ${sys:es.logs.cluster_name}_deprecation-*； appender.deprecation_rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}_deprecation-* appender.deprecation_rolling.strategy.action.condition.nested_condition.type = IfLastModified appender.deprecation_rolling.strategy.action.condition.nested_condition.age = 5D logger.deprecation.name = org.elasticsearch.deprecation logger.deprecation.level = warn logger.deprecation.appenderRef.deprecation_rolling.ref = deprecation_rolling logger.deprecation.additivity = false appender.index_search_slowlog_rolling.type = RollingFile # index_search_slowlog 查询慢日志的 appender 标签名称 appender.index_search_slowlog_rolling.name = index_search_slowlog_rolling # index_search_slowlog 查询慢日志路径和日志格式 appender.index_search_slowlog_rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_index_search_slowlog.log appender.index_search_slowlog_rolling.layout.type = PatternLayout appender.index_search_slowlog_rolling.layout.pattern = %d{ISO8601} %p [%t] %c:%M:%L - %m%n appender.index_search_slowlog_rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_index_search_slowlog-%d{yyyy-MM-dd}-%i.log appender.index_search_slowlog_rolling.policies.type = Policies appender.index_search_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy appender.index_search_slowlog_rolling.policies.time.interval = 1 appender.index_search_slowlog_rolling.policies.time.modulate = true appender.index_search_slowlog_rolling.strategy.max = 3 appender.index_search_slowlog_rolling.policies.size.type = SizeBasedTriggeringPolicy appender.index_search_slowlog_rolling.policies.size.size = 1GB appender.index_search_slowlog_rolling.strategy.type = DefaultRolloverStrategy appender.index_search_slowlog_rolling.strategy.action.type = Delete appender.index_search_slowlog_rolling.strategy.action.basepath = ${sys:es.logs.base_path} appender.index_search_slowlog_rolling.strategy.action.condition.type = IfFileName # 从与 glob 匹配的基本路径中删除文件 ${sys:es.logs.cluster_name}_index_search_slowlog-* appender.index_search_slowlog_rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}_index_search_slowlog-* appender.index_search_slowlog_rolling.strategy.action.condition.nested_condition.type = IfLastModified appender.index_search_slowlog_rolling.strategy.action.condition.nested_condition.age = 5D logger.index_search_slowlog_rolling.name = index.search.slowlog logger.index_search_slowlog_rolling.level = trace logger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rolling logger.index_search_slowlog_rolling.additivity = false appender.index_indexing_slowlog_rolling.type = RollingFile # index_indexing_slowlog 写入慢日志的 appender 标签名称 appender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rolling # index_indexing_slowlog 写入慢日志路径和日志格式 appender.index_indexing_slowlog_rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_index_indexing_slowlog.log appender.index_indexing_slowlog_rolling.layout.type = PatternLayout appender.index_indexing_slowlog_rolling.layout.pattern = %d{ISO8601} %p [%t] %c:%M:%L - %m%n appender.index_indexing_slowlog_rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}_index_indexing_slowlog-%d{yyyy-MM-dd}-%i.log appender.index_indexing_slowlog_rolling.policies.type = Policies appender.index_indexing_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy appender.index_indexing_slowlog_rolling.policies.time.interval = 1 appender.index_indexing_slowlog_rolling.policies.time.modulate = true appender.index_indexing_slowlog_rolling.strategy.type = DefaultRolloverStrategy appender.index_indexing_slowlog_rolling.strategy.max = 3 appender.index_indexing_slowlog_rolling.policies.size.type = SizeBasedTriggeringPolicy appender.index_indexing_slowlog_rolling.policies.size.size = 1GB appender.index_indexing_slowlog_rolling.strategy.type = DefaultRolloverStrategy appender.index_indexing_slowlog_rolling.strategy.action.type = Delete appender.index_indexing_slowlog_rolling.strategy.action.basepath = ${sys:es.logs.base_path} appender.index_indexing_slowlog_rolling.strategy.action.condition.type = IfFileName # 从与 glob 匹配的基本路径中删除文件 ${sys:es.logs.cluster_name}_index_indexing_slowlog-* appender.index_indexing_slowlog_rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}_index_indexing_slowlog-* appender.index_indexing_slowlog_rolling.strategy.action.condition.nested_condition.type = IfLastModified appender.index_indexing_slowlog_rolling.strategy.action.condition.nested_condition.age = 5D logger.index_indexing_slowlog.name = index.indexing.slowlog.index logger.index_indexing_slowlog.level = trace logger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rolling logger.index_indexing_slowlog.additivity = false 日志配置通常不需要调整
运维命令 集群启停
1 2 bin/elasticsearch -d # 启动 kill -9 $(ps aux|grep elastic|awk '{print $2}') # 关闭 密码重置
1 bin/elasticsearch-setup-passwords interactive 凭证管理
1 2 3 4 5 6 7 8 9 10 11 12 # 创建ca凭证 bin/elasticsearch-certutil ca --days 3660 # 创建cert凭证 bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --ip {ip},127.0.0.1 --out config/certs/cert.p12 --days 3660 # 创建凭证库 bin/elasticsearch-keystore create # 设置cert pkcs12凭证密码 bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password # 设置ca pkcs12凭证密码 bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password # 查看密钥库凭证 bin/elasticsearch-keystore list 凭证批量生成
1 bin/elasticsearch-certgen -in instances.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 instances: - name: "node1" ip: - "192.0.2.1" dns: - "node1.mydomain.com" - name: "node2" ip: - "192.0.2.2" - "198.51.100.1" - name: "node3" - name: "node4" dns: - "node4.mydomain.com" - "node4.internal" - name: "CN=node5,OU=IT,DC=mydomain,DC=com" filename: "node5" 插件管理
1 2 3 4 5 6 # 插件安装 bin/elasticsearch-plugin install {plugin_name} # 插件查看 bin/elasticsearch-plugin list # 插件卸载 bin/elasticsearch-plugin remove {plugin_name} elasticsearch常用插件:
elasticsearch-head: 集群管理工具 bigdesk: 集群监控工具 kopf: 集群资源查看和查询工具 kibana常用插件:
conveyor: 图形化数据导入工具 kibana_markdown_doc_view: Kibana文档查看强化插件 indices_view: index查看插件 sentinl: 告警插件 常用API 查看集群状态
1 2 GET /_cluster/health?v GET /_cat/health 查看集群统计信息
1 2 3 GET /_cluster/stats?pretty GET /_cluster/state/{obj} GET /_nodes/stats/{obj}?pretty 查看可用API
1 GET /_cat 查看指定对象信息
1 2 3 4 5 6 7 8 9 10 11 GET /_cat/nodes?v # 查看节点 GET /_cat/tasks # 查看任务 GET /_cat/allocation # 查看分片分配 GET /_cat/plugins # 查看已安装的插件 GET /_cat/indices/{index} # 查看(指定)索引 GET /_cat/shards/{index} # 查看(指定索引的)分片 GET /_cat/aliases/{aliase} # 查看(指定)索引别名 GET /_cat/segments/{index} # 查看(指定索引的)segments GET /_cat/count/{index} # 查看(指定索引的)文档总数 GET /_cat/fielddata/{field} # 查看(指定)字段 GET /_cat/recovery/{index} # 查看(指定索引的)恢复 索引操作
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 创建索引 PUT /{index} # 查看索引 GET /{index} GET /_cat/indices?v&amp;health=yellow&amp;s=docs.count:desc # 查看每个索引包含的type GET /_mapping?pretty # 删除索引 DELETE /{index} DELETE /_all DELETE /* # 打开/关闭索引 POST /{index}/_open POST /{index}/_close 文档操作
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # 创建/更新文档 PUT /{index}/{type}/{doc_id} { "foo": "bar" } POST /{index}/{type}/{doc_id}/_update { "foo": "bar" } # 删除文档 DELETE /{index}/{type}/{doc_id} # 查看文档 GET /{index}/{type}/{doc_id} # 检索文档 GET /_search # 检索所有文档 GET /_all/{type}/_search # 检索指定类型的文档 { "query": {"match": { "foo": "bar"}} } GET /{index}/_search?pretty # 检索指定索引的文档 { "_source":["name","age"], # 指定返回字段 "query": {"match_all": {}} } GET /{index}/_search?pretty # 条件检索 { "query": { "bool": { "must":[ # 条件 and: must, or: should {"match":{"name":"hello"}}, {"match":{"name":"world"}} ] }, "sort": { # 排序 "timestamp": { "order": "desc" } } } } GET /{index}/_search?pretty # 聚合检索 { "aggs": { "avg_age": { "avg": { "field": "age" } } } } # 查询文档数量 GET /_all/_count GET /{index}/{type}/_count { "query": {"match_all": {}} } 别名操作
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # 查看别名 GET /_alias/{alias} # 指定索引(过滤)添加别名 PUT /{index}/_alias/{alias} { "filter": { "term": { "foo": "bar" } } } # 为同一索引添加多个别名 POST /_aliases { "actions": [ {"add": {"index": "index1", "alias": "index_alias1"}}, {"add": {"index": "index1", "alias": "index_alias2"}} ] } # 为多个索引添加同一别名 POST /_aliases { "actions": [ {"add": {"indices": ["index1", "index2", "idx*"], "alias": "index_alias"}} ] } # 删除别名 POST /_aliases { "actions": [ {"remove": {"index": "index1", "alias": "index_alias"}} ] } # 别名重新绑定 POST /_aliases { "actions" : [ { "remove" : { "index" : "index1", "alias" : "index_alias" } }, { "add" : { "index" : "index2", "alias" : "index_alias" } } ] } # 创建字段别名 PUT /{index} { "mappings": { "properties": { "username": { "type":"keyword" }, "uname": { "type": "alias", "path": "username" } } } } 用户管理
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # basic license仅允许一个elastic用户 # 添加用户 POST /_xpack/security/user/{user} { "password" : "my_user@123", "roles" : [ "superuser", "other_role1" ] } # 查看用户 GET /_xpack/security/user/{user} # 修改密码 PUT /_xpack/security/user/{user}/_password { "password": "q5f2qNfUJQyvZPIz57MZ" } # 启用/禁用用户 PUT /_xpack/security/user/{user}/_enable PUT /_xpack/security/user/{user}/_disable # 删除用户 DELETE /_xpack/security/user/{user} # 特权查询 GET _xpack/security/user/_has_privileges { "cluster": [ "monitor", "manage" ], "index" : [ { "names": [ "suppliers", "products" ], "privileges": [ "read" ] }, { "names": [ "inventory" ], "privileges" : [ "read", "write" ] } ] } 节点分片移动
1 2 3 4 5 6 7 8 9 10 11 12 13 POST /_cluster/reroute { "commands": [ { "move": { "index": "indexname", "shard": 1, "from_node": "nodename", "to_node": "nodename" } } ] } 节点优雅下线
1 2 3 4 5 6 PUT /_cluster/settings { "transient": { "cluster.routing.allocation.exclude._ip": "122.5.3.55" } } 索引数据强制刷新
1 2 POST /_flush POST /_flush/synced # 将废弃 更新集群设置
1 2 3 4 5 6 7 8 9 10 11 12 13 PUT /_cluster/settings { "transient": { # 更改并发分片数量以平衡集群 "cluster.routing.allocation.cluster_concurrent_rebalance": 2, # 更改每个节点同时恢复的分片数量 "cluster.routing.allocation.node_concurrent_recoveries": 6, # 调整恢复速度 "indices.recovery.max_bytes_per_sec": "80mb", # 调整断路器 "indices.breaker.total.limit": "40%" } } 清除节点缓存
1 POST /_cache/clear 索引数据迁移
1 2 3 4 5 6 7 8 9 POST _reindex { "source": { "index": "my-index-000001" }, "dest": { "index": "my-new-index-000001" } } 集群数据备份恢复
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 创建备份仓库 PUT /_snapshot/{backup_repo} { "type": "fs", "settings": { "location": "/path/to/repo", # 与path.repo相同 "max_snapshot_bytes_per_sec" : "50mb", # 数据从es到备份仓库的写入速度上限 "max_restore_bytes_per_sec" : "50mb" # 数据从备份仓库到es的写入速度上限 } } # 查看备份仓库 GET /_snapshot/{backup_repo} # 备份所有打开的索引的数据到指定快照 PUT _snapshot/{backup_repo}/{snapshot_name}?wait_for_completion=true # 备份指定数据到快照 PUT /_snapshot/{backup_repo}/{snapshot_name}?wait_for_completion=true { "indices": "hamlet_*", "ignore_unavailable": true, "include_global_state": false, "metadata": { "taken_by": "mingyi", "taken_because": "backup before upgrading" } } # 列出快照信息(监控进度) GET _snapshot/{backup_repo}/{snapshot_name} # 监控快照进度 GET _snapshot/{backup_repo}/{snapshot_name}/_status # 删除或取消快照 DELETE _snapshot/{backup_repo}/{snapshot_name} # 从快照恢复(可选择只恢复指定索引) POST /_snapshot/{backup_repo}/{snapshot_name}/_restore { "indices": "index_1", "rename_pattern": "index_(.+)", "rename_replacement": "restored_index_$1" } # 查看指定索引的恢复状态 GET /{index}/_recovery # 取消恢复(删除正在恢复的索引) DELETE /{index} 查看出现问题的索引或分片
1 2 3 GET /_cluster/health?level=indices GET /_cat/indices?v&amp;health=red GET /_cluster/health?level=shards 查看问题分析
1 GET /_cluster/allocation/explain 分片分配状态:
INDEX_CREATED: Unassigned as a result of an API creation of an index CLUSTER_RECOVERED: Unassigned as a result of a full cluster recovery INDEX_REOPENED: Unassigned as a result of opening a closed index DANGLING_INDEX_IMPORTED: Unassigned as a result of importing a dangling index NEW_INDEX_RESTORED: Unassigned as a result of restoring into a new index EXISTING_INDEX_RESTORED: Unassigned as a result of restoring into a closed index REPLICA_ADDED: Unassigned as a result of explicit addition of a replica ALLOCATION_FAILED: Unassigned as a result of a failed allocation of the shard NODE_LEFT: Unassigned as a result of the node hosting it leaving the cluster REROUTE_CANCELLED: Unassigned as a result of explicit cancel reroute command REINITIALIZED: When a shard moves from started back to initializing, for example, with shadow replicas REALLOCATED_REPLICA: A better replica location is identified and causes the existing replica allocation to be cancelled 相关工具 集群管理 http://mobz.github.io/elasticsearch-head 集群管理 https://www.elastic.co/products/kibana 集群管理 https://github.com/royrusso/elasticsearch-HQ 集群监控 https://github.com/lmenezes/cerebro 集群安全 https://www.elastic.co/downloads/x-pack 数据可视化 https://grafana.com/grafana 数据迁移 https://github.com/medcl/elasticsearch-migration 数据导出 https://github.com/mallocator/Elasticsearch-Exporter 数据备份 https://github.com/taskrabbit/elasticsearch-dump 数据保存期限 https://pypi.python.org/pypi/elasticsearch-curator 类SQL查询 https://github.com/NLPchina/elasticsearch-sql SQL转DSL https://github.com/360EntSecGroup-Skylar/ElasticHD 监控告警 http://elastalert.readthedocs.org/ 文章推荐 官方文档 Lucene介绍与入门 Lucene索引过程&amp;索引文件格式详解 Every shard deserves a home ElasticSearch简介 ElasticSearch分词与查询 ElasticSearch架构原理 ElasticSearch中数据是如何存储的 ElasticSearch安全配置 ElasticSearch内存配置优化 JVM调优总结 ElasticSearch最佳运维总结 Awesome ElasticSearch 排障经验 Prometheus Grafana Loki Redis 基于内存的KV数据库
基本概念 KV数据库: KV数据库即Key-Value数据库(键值数据库)，与关系数据库不同，它使用简单的键值方法来存储数据。键值数据库将数据存储为键值对集合，其中键作为唯一标识符。键和值都可以是从简单对象到复杂复合对象的任何内容。键值数据库是高度可分区的，并且允许以其他类型的数据库无法实现的规模进行水平扩展。 数据库: Redis是一个Key-Value存储系统，其数据库的概念与MySQL等数据库不大一样，Redis中的数据库更像是一个命名空间，Redis默认支持16个数据库(可修改），库名以db0，db1，&hellip;，db15命名且不可修改，如不指定则默认使用db0数据库。不同的库中的数据是相互独立的，但所有库都共用一套访问密码。Redis集群模式仅支持db0数据库。 实例: Redis分为服务端redis-server和客户端redis-cli，其中客户端为命令行工具，用于连接服务端，服务端则是Redis的核心。一个运行的Redis服务端进程就是一个实例(或称为一个节点)，每个实例支持多个数据库。 集群: Redis支持多种集群方式，多个Redis实例可以组成集群，集群是为了解决Redis的高可用、故障转移和高性能等需求的。集群方式不同则Redis实例的角色也不一样，实例可能作为另一个实例的副本，也可能作为其他实例的一个分片。 副本: Redis通过副本机制实现高可用，多个Redis实例之间形成主从关系，由master实例向slave实例同步数据实现数据的多副本和一致性 分区/分片: 分区即是分片，Redis通过分区/分片（partiton/shard）机制实现扩展能力和性能的提升，每一个Redis分片就是一个Redis实例，Redis分片就是把数据分割到多个 Redis 实例的处理过程，因此每个 Redis 实例只保存 key 的一个子集，Redis支持范围法分片和哈希法分片。 哨兵: Redis实例可以以哨兵(Sentinel)模式运行，哨兵实例不存储数据，而是监控主从实例是否正常运行，并自主实例出现故障时自动将从实例切换为主实例，保证集群的可用性。哨兵机制实现了Redis集群的自动故障转移。 Cluster: Redis支持3种集群方式，其中主从同步集群实现多副本高可用，哨兵模式支持自动故障转移，但对于海量数据和高性能的场景，则需要利用分片技术，而Redis Cluster则是基于分片技术的集群模式。 gossip: gossip又称流言协议，是一种实现分布式系统内消息扩散的通信协议，分布式系统中的各节点以广播的方式将消息扩散到其他节点，实现系统中各节点数据的最终一致性。Redis Cluster集群中使用此协议实现各分片的数据交换和消息通信。 一致性哈希: 实现分片时，一般通过哈希法将key哈希后对分片数量取模从而决定该key的数据映射到哪个实例上，但直接进行哈希映射会出现一旦分片发生增减时，分片数量发生变化，所有的映射都将失效。而一致性哈希算法则对2^32取模，值范围被抽象为圆环，并将所有分片映射到圆环上特定的点上，一旦key被映射到某个点，则顺时针寻找其后的第一个分片，从而完成到分片的映射且当ff怕数量变化时也不会影响其他分片上key的映射，此外为了保证key的均匀分布，一般还会引入虚拟节点机制。 哈希槽: Redis的Cluster进行哈希映射时，选择了类似一致性哈希的哈希槽算法，该算法对2^14取模，形成16384个哈希槽，这些槽分配到不同的分片上，每个分片上都维护完整的哈希槽映射信息，当出现分片增减时，哈希槽位将进行重新分片(reshard)，将槽位和对应的数据转移到其他分片上。哈希槽相比一致性哈希，算法更加简单，维护更加灵活。 主观下线/客观下线: Redis Sentinel集群的Sentinel节点之间或Sentinel节点到主从节点之间会发送心跳消息以确认节点是否存活，Cluster集群主分片节点间同样会发送心跳消息(PING -> PONG)，如果某个节点在规定的时间内未收到某个节点返回的心跳消息，则会认为该节点主观下线。如果quorum个哨兵或主分片节点(半数+1)均将某个节点标记为主观下线，则该节点被判定为客观下线。主观下线适用于主从节点，但客观下线仅适用于主节点，因为从节点下线不对集群本身状态产生影响，但主节点的下线将导致主节点的重新选举。 持久化:Redis是基于内存的数据库，所有的数据均存在于内存中，但由于内存具有易失性，因此Redis提供了RDB和AOF两种持久化机制将内存数据持久化到磁盘中。 RDB: RDB是一种Redis持久化机制，可理解为某个时刻的Redis内存中的数据快照，通过加载RDB文件中的内容实现内存数据的恢复。 AOF: AOF是一种Redis持久化机制，AOF文件中保存的是所有记录了所有修改内存数据的指令的集合，通过回放AOF文件中的指令实现内存数据的恢复。 数据类型: Redis作为Key-Value数据库，其Key仅支持字符串一种类型，但Value支持多种类型，基础的Value类型有String、List、Hash、Set和ZSet，此外还有一些不常用的Bitmap、HyperLogLog、GEO、Stream的数据类型。各种数据类型均有其合适的应用场景。Redis中String类型的概念包括integer、float和string。 架构特性 集群架构
主从同步
Redis主从同步集群中将Redis节点划分为master和slave节点，形成一主多从，slave对外提供读操作，而master负责写操作，形成一个读写分离的架构。master节点会主动向slave节点同步数据，同步过程分为同步和命令传播两个步骤：
slave节点向master节点发送sync命令 master收到sync命令之后会执行bgsave命令，Redis会fork出一个子进程在后台生成RDB文件，同时将同步过程中的写命令记录到缓冲区中 文件生成后，master会把RDB文件发送给slave，从服务器接收到RDB文件会将其载入内存 然后master将记录在缓冲区的所有写命令发送给slave，slave对这些命令进行重放，将其数据库的状态更新至和master一致 Redis2.8版本之后，使用psync命令代替了sync命令，实现通过主从双方共同维护的offset完成主从之间数据的增量同步。
主从同步模式实现了高可用和读写分离，但当主节点故障后，无法自动产生新的主节点，集群需要人工干预才能重新提供服务。
Sentinel
Redis哨兵集群是在主从同步集群的基础上，额外分配哨兵节点，由哨兵节点监控主从集群中各节点的状态，并在主节点故障后自动从从节点中选举新的主节点，此外，哨兵节点还负责向管理员或其他应用报告集群状态，以及给客户端提供最新的master地址。
哨兵节点之间本身也组成一个分布式集群，用于进行集群决策，如决定新的主节点等，哨兵执行故障转移需要大部分哨兵节点同意才行，哨兵节点会利用Redis的发布订阅机制自动发现主从集群中的其他节点和其他哨兵节点。哨兵节点发现主从同步集群的主节点下线后，会询问其他哨兵节点，当大部分哨兵节点都将主节点标记为下线后，主节点客观下线，哨兵节点之间通过选举算法选出leader哨兵，执行故障转移操作，产生新的主节点。
启动并初始化Sentinel节点，并获取主从节点信息 Sentinel节点向主从节点发送消息并接收来自主从节点的频道信息 Sentinel节点检测主观下线和客观下线状态 选举Leader Sentinel节点执行故障转移 执行故障转移，在已下线的主节点的下属从节点中选举一个作为新的主节点，将所有从节点改为复制新主节点，将已下线主节点设置为新主节点的从节点 哨兵模式在主从同步的基础上，解决了自动故障转移的问题，但哨兵节点本身不能保存数据，且存在主节点单点写入和节点扩容困难的问题，难以应对海量数据Redis集群的需求。
Cluster
Cluster集群模式是一个多主集群，多个主节点维护不同分片的数据，构成一个分布式集群，由于每个主节点都只维护集群中的部分数据，因此为了应对主节点故障，每个主节点都至少需要挂载一个从节点，作为主节点的数据备份，主节点故障时会被提升为新的主节点。但集群中的读写操作均在主节点上完成。
Cluster集群中主节点之间通过gossip协议实现消息通信和数据交换，采用类似与哨兵模式的方式实现自动故障转移，客户端连接集群中任意主节点即可，无需中间代理层。
Cluster集群采用哈希槽算法进行数据分片，增减节点需要对哈希槽进行重分配。
Cluster集群模式同时满足高可用，读写分离，故障转移和横向扩展等需求，是比较理想的集群模式，但不支持多数据库。
数据类型
Redis为C语言开发，针对其支持的几种类型作了底层数据结构的优化，以保证对各数据类型操作的搞性能。几种基础数据类型的底层数据结构对应关系如下：
String：String类型的内部编码有3种：int、raw和embstr，其中int用于保存整型int和长整型long，后两者为redis定义的简单动态字符串结构（SDS），用于保存字符串类型，浮点数在底层被转换为字符串值，然后再对应到这3种编码规则。
List：List类型保存数组，可实现简单的消息队列。List类型底层数据结构在3.2版本之前由双向链表或压缩链表实现。之后则统一由quicklist实现。
Hash：Hash类型是一个键值对集合，其底层数据结构是由压缩列表或哈希表(字典)实现的。在7.0版本之后压缩列表已经废弃，交由listpack数据结构实现。
Set：Set类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储，其底层数据结构是由哈希表或整数集合实现的。
![redis-set-intset ](redis-set-intset .png)
ZSet： ZSet类型相比于Set类型多了一个排序属性score(分值)，对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。其底层数据结构是由压缩列表或跳表实现的。在7.0版本之后压缩列表已经废弃，交由listpack数据结构实现。
Bitmap：Bitmap类型即位图类型，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。Bitmap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。Bitmap本身是用String类型作为底层数据结构实现的一种统计二值状态的数据类型。
HyperLogLog：HyperLogLog类型是Redis2.8.9 版本新增的数据类型，是一种用于统计基数的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。HyperLogLog提供低内存消耗下不精确的去重计数，其统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。
GEO：GEO类型是Redis 3.2版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。其本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。
Stream：Stream类型是Redis 5.0版本新增加的数据类型，是专门为消息队列设计的数据类型。其底层数据结构为RaxTree。Stream 保存的消息数据，按照 key-value 形式来看的话，消息 ID 就相当于 key，而消息内容相当于是 value。也就是说，Stream 会使用 Radix Tree 来保存消息 ID，然后将消息内容保存在 listpack 中，并作为消息 ID 的 value，用 raxNode 的 value 指针指向对应的 listpack。
整体的数据类型与数据结构对应关系如下：
Redis 五种数据类型的应用场景：
String：缓存对象、常规计数、分布式锁、共享session信息等 List：消息队列（有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等 Hash：缓存对象、购物车等 Set：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等 Zset：排序场景，比如排行榜、电话和姓名排序等 Redis 后续版本又支持四种数据类型，它们的应用场景如下：
BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等 HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等 GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车 Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据 针对 Redis 是否适合做消息队列，关键看你的业务场景：
如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的 如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧 持久化
RDB
在Redis中生成RDB快照的方式有两种，一种是使用save指令，另一种是bgsave指令，但是底层实现上，其调用的是同一个函数，叫rdbsave，只是其调用的方式不同而已。save指令生成RDB快照过程中会阻塞Redis主进程，直至快照文件生成，而bgsave指令会fork出一个子进程，由fork出来的子进程调用rdbsave，父进程会继续响应来自客户端的读写请求，子进程完成RDB文件生成之后会给父进程发送信号，通知父进程保存完成。
RDB支持灵活的备份配置策略，非常适合作冷备份，且数据恢复速度快。但如果内存数据量太大，使用RDB进行备份可能会占用大量服务器资源，也可能会发生很多的也异常中断，造成整个Redis停止响应几百毫秒，此外其备份时间长，存在备份过程中断电而备份失败的风险，也无法对备份过程中新增的数据进行备份。
AOF
AOF备份的是Redis指令(也称为AOF日志)，Redis不断将写指令以特定的协议格式记录到AOF文件在内存的写缓冲区aof_buf中，Redis进程中的ServerCron函数会定期调用flushAppendOnlyFile函数，该函数会调用write函数将aof_buf中的数据写入os cache中，而操作系统会根据自身策略，调用fsync或sdatasync将os cache中的数据写入磁盘。
AOF支持always、everysec和no三种落盘策略，always策略下每个命令都会写入aof_buff并同步到磁盘，everysec策略下每秒钟回同步一次数据到磁盘，no策略下则不关心落盘事件，而是完全交由操作系统决定。
AOF由于记录的是每个写操作的指令，因此文件会较大，且越来越大，为应对此问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令 bgrewriteaof 来重写。AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件，重写操作也是fork子进程异步执行的。
AOF能够频繁地进行数据备份，最大限度避免数据丢失，且可灵活调整备份频率，对Redis性能影响小，但此方式备份文件较大，且恢复过程较RDB慢不少。
RDB+AOF
在Redis4.0之后，Redis新增了RDB-AOF混合持久化方式，这种方式结合了RDB和AOF的优点，既能快速加载又能避免丢失过多的数据，通过设置aof-use-rdb-preamble为yes后即可开启，当开启混合持久化时，主进程先fork出子进程将现有内存副本全量以RDB方式写入AOF文件中，然后将缓冲区中的增量命令以AOF方式写入AOF文件中，写入完成后通知主进程更新相关信息，并将新的含有 RDB和AOF两种格式的AOF文件替换旧的AOF文件。简单来说：混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式，这种方式无法兼容Redis4.0之前版本的备份文件。
持久化总结
redis提供几种持久化机制：
a). RDB持久化
工作方式 ：根据时间的间隔将redis中数据快照（dump）到dump.rdb文件
优势 ：备份恢复简单。RDB通过子进程完成持久化工作，相对比AOF启动效率高
劣势 ：服务器故障会丢失几分钟内的数据
b). AOF持久化
工作方式 ：以日志的形式记录所有更新操作到AOF日志文件，在redis服务重新启动时会读取该日志文 件来重新构建数据库，以保证启动后数据完整性。
优势 ：AOF提供两种同步机制，一个是fsync always每次有数据变化就同步到日志文件和fsync everysec每秒同步一次到日志文件，最大限度保证数据完整性。
劣势：日志文件相对RDB快照文件要大的多
AOF日志重写功能 ：AOF日志文件过大，redis会自动重写AOF日志，append模式不断的将更新记录写入到老日志文件中，同时redis还会创建一个新的日志文件用于追加后续的记录。
c). 同时应用AOF和RDB
对于数据安全性高的场景，可同时使用AOF和RDB，这样会降低性能。
d). 无持久化
禁用redis服务持久化功能。
发布订阅与stream
发布订阅
Redis能够通过List列表数据类型配合lpush和rpop操作实现消息队列，但是却很难执行消息多播功能，为此Redis单独添加了发布订阅模块实现消息队列的多播。
在发布订阅模式中，Redis引入频道channel的概念关联生产者和消费者，消费者除了可以订阅频道channel外，还可以通过模式匹配pattern一次性订阅多个频道，这两种订阅方式分别称为频道订阅和模式订阅。生产者向频道发送的消息同时也会被发送到该频道匹配的模式中。
订阅频道的原理是Redis服务端在内存中维护着一个pubsub_channels频道的字典，字典中key为频道的名称，耳每个value都是一个包含订阅了该频道的消费者的链表。
订阅模式的原理是Redis服务端同时在内存中维护一个pubsub_patterns模式的链表，链表中每一项都是一个客户端和模式的组合。
Redis的发布订阅机制虽然满足多播消息队列的需求，但其缺点也很明显，它没有ack机制，无法确保消息的正确发送和接收，且消息一旦消费失败就不能再次被消费，不能保证数据连续性，此外，发布订阅机制中的消息队列不会持久化到磁盘，一旦Redis故障消息都将丢失。
Stream
为了解决发布订阅机制存在的问题，Redis推出了更为强大的Stream数据类型。Redis Stream从概念上来说，就像是一个 仅追加内容的 消息链表，把所有加入的消息都一个一个串起来，每个消息都有一个唯一的 ID 和内容，这很简单，让它复杂的是从 Kafka 借鉴的另一种概念：消费者组(Consumer Group)(思路一致，实现不同)：
这是一个典型的 Stream结构。每个 Stream 都有唯一的名称，它就是 Redis 的key，在我们首次使用xadd指令追加消息时自动创建。Stream相关概念解释如下：
Consumer Group：消费者组，可以简单看成记录流状态的一种数据结构。消费者既可以选择使用XREAD命令进行 独立消费，也可以多个消费者同时加入一个消费者组进行组内消费。同一个消费者组内的消费者共享所有的Stream信息，同一条消息只会有一个消费者消费到，这样就可以应用在分布式的应用场景中来保证消息的唯一性。 last_delivered_id：用来表示消费者组消费在Stream 消费位置的游标信息。每个消费者组都有一个Stream内唯一的名称，消费者组不会自动创建，需要使用XGROUP CREATE指令来显式创建，并且需要指定从哪一个消息 ID 开始消费，用来初始化last_delivered_id这个变量。 pending_ids：每个消费者内部都有的一个状态变量，用来表示已经被客户端获取，但是还没有 ack的消息。记录的目的是为了保证客户端至少消费了消息一次，而不会在网络传输的中途丢失而没有对消息进行处理。如果客户端没有 ack，那么这个变量里面的消息 ID 就会越来越多，一旦某个消息被 ack，它就会对应开始减少。这个变量也被 Redis 官方称为PEL(Pending Entries List)。 配置文件 /etc/redis.conf: Redis主配置文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 # 是否以后台进程运行 daemonize yes # pid文件位置 pidfile /var/run/redis/redis-server.pid # 监听端口 port 6379 # 绑定地址，如需远程连接，设置0.0.0.0 bind 127.0.0.1 # 连接超时时间，单位秒 timeout 300 # 设置redis公开哪个IP给访问者(在nat网络环境下使用) cluster-announce-ip "192.168.0.8" # 日志级别，分别有： # debug ：适用于开发和测试 # verbose ：更详细信息 # notice ：适用于生产环境 # warning ：只记录警告或错误信息 loglevel notice # 日志文件位置 logfile /var/log/redis/redis-server.log # 是否将日志输出到系统日志 syslog-enabled no #设置数据库数量，默认数据库为0 databases 16 ############### RDB持久化 ############### # 在900s（15m）之后，至少有1个key发生变化，则快照 save 900 1 # 在300s（5m）之后，至少有10个key发生变化，则快照 save 300 10 # 在60s（1m）之后，至少有1000个key发生变化，则快照 save 60 10000 # dump时是否压缩数据 rdbcompression yes # 本地数据库的磁盘中的文件名 dbfilename dump.rdb # 数据库(dump.rdb)文件存放目录 dir /var/lib/redis # 从版本RDB版本5开始，一个CRC64的校验就被放在了文件末尾。 # 这会让格式更加耐攻击，但是当存储或者加载rbd文件的时候会有一个10%左右的性能下降， # 所以，为了达到性能的最大化，你可以关掉这个配置项。 # 没有校验的RDB文件会有一个0校验位，来告诉加载代码跳过校验检查。 rdbchecksum yes # 如果配置 yes 当后台持久化失败，Redis会停止接受更新操作。如果持久化进程再次工作则会恢复允许更新操作 # 如果配置 no 当后台持久化失败，Redis更新操作仍然继续处理 stop-writes-on-bgsave-error yes ############### AOF持久化 ############### # AOF持久化，是否记录更新操作日志，默认redis是异步(快照)把数据写入本地磁盘 appendonly yes # 指定AOF日志文件名 appendfilename appendonly.aof # AOF持久化三种同步策略： # appendfsync always #每次有数据发生变化时都会写入appendonly.aof # appendfsync everysec #默认方式，每秒同步一次到appendonly.aof # appendfsync no #不同步，数据不会持久化 appendfsync everysec # 当AOF日志文件即将增长到指定百分比时，redis通过调用BGREWRITEAOF是否自动重写AOF日志文件 no-appendfsync-on-rewrite no # 当AOF文件大小超过上次rewrite后的100%(一倍)并且文件大于64M时触发rewrite auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # redis在恢复时忽略最后一条可能存在问题的指令，默认值yes。在aof写入时突然断电可能会出现指令写错(写了一半)，这种情况下yes会log并继续，而no会直接恢复失败 aof-load-truncated yes # 是否启用rdb+aof混合持久化 aof-use-rdb-preamble no ############### 安全 ############### # 配置redis连接认证密码 requirepass foobared # 保护模式是一个避免你在互联网(外网)访问redis的机制，默认开启 # 当启用保护模式，而且没有密码时，服务器只接受来自IPv4地址(127.0.0.1)、IPv6地址(::1)或Unix套接字本地连接(没密码+保护模式启动=本地访问) protected-mode yes #将危险的命令重命名或者禁用 #例如禁用FLUSHALL rename-command FLUSHALL "" #重命名FLUSHDB，重命名后必须用新命令来操作，否则服务器会报错 unknown command rename-command FLUSHDB qf69aZbLAX3cf3ednHM3SOlbpH71yEXLAX3cf3e ############### 限制 ############### # 为了防止某个脚本执行时间过长导致Redis无法提供服务(比如陷入死循环),Redis提供了lua-time-limit参数限制脚本的最长运行时间，默认为5秒钟。当脚本运行时间超过这一限制后，Redis将开始接受其他命令但不会执行(以确保脚本的原子性，因为此时脚本并没有被终止),而是会返回"BUSY"错误 lua-time-limit 5000 # 设置最大连接数，0为不限制 maxclients 128 # 内存清理策略，如果达到此值，将采取以下动作： # volatile-lru #默认策略，只对设置过期时间的key进行LRU算法删除 # allkeys-lru #删除不经常使用的key # volatile-random #随机删除即将过期的key # allkeys-random #随机删除一个key # volatile-ttl #删除即将过期的key # noeviction #不过期，写操作返回报错 # 允许使用的最大内存(需要配合maxmemory-policy使用),设置为0表示不限制 maxmemory &lt;bytes> # 如果达到maxmemory值，采用此策略 maxmemory-policy volatile-lru # 默认随机选择3个key，从中淘汰最不经常用的 maxmemory-samples 3 ################ 慢查询 ################ # 单位为微秒，当命令执行时间超过该值则会被redis记录为慢查询 # 配置为负数则禁用慢查询日志 # 配置为0则记录所有命令 slowlog-log-slower-than 10000 # 设置慢查询日志的长度，如果已满则会删掉最旧的保留最新的 # 可以用命令 SLOWLOG RESET 来释放内存 slowlog-max-len 128 ############### 主从复制 ############### # 主从复制使用，用于本机redis作为slave去连接主redis slaveof &lt;masterip> &lt;masterport> # 当master设置密码认证，slave用此选项指定master认证密码 masterauth &lt;master-password> # 作为从服务器，默认情况下是只读的(yes),可以修改成no用于写(不建议) slave-read-only yes # 当slave与master之间的连接断开或slave正在与master进行数据同步时，如果有slave请求，当设置为yes时，slave仍然响应请求，此时可能有问题，如果设置no时，slave会返回"SYNC with master in progress"错误信息。但INFO和SLAVEOF命令除外。 slave-serve-stale-data yes # Redis部署为Replication模式后，slave会以预定周期（默认10s）发PING包给master，该配置可以更改这个默认周期 repl-ping-slave-period 10 # 有2种情况的超时均由该配置指定：1) Bulk transfer I/O timeout; 2) master data or ping response timeout。 # 需要特别注意的是：若修改默认值，则用户输入的值必须大于repl-ping-slave-period的配置值，否则在主从链路延时较高时，会频繁timeout。 repl-timeout 30 # 当配置yes时会禁用NO_DELAY，TCP协议栈会合并小包统一发送，这样可以减少主从节点间的包数量并节省带宽，但会增加数据同步到slave的时间 # 当配置no时启用NO_DELAY，TCP协议栈不会延迟小包的发送时机，这样数据同步的延时会减少，会消耗更多带宽 # 在带宽充足的情况下建议配置为no，以降低同步时延 repl-disable-tcp-nodelay no # 存在多个slave的情况下，当master宕机时Redis seninel将选拔priority值最小的slave提升为master # 如果该配置为 0 则永远不会被sentinel提升为master slave-priority 4 ############# Cluster模式 ############# # 开启集群模式 cluster-enabled yes # 集群的配置文件存放路径 cluster-config-file "nodes.conf" # 集群的超时时间 cluster-node-timeout 5000 ############# Sentinel模式 ############# # master数据库的ip与端口号，当master发生变化时sentinel会自动修改该配置 # 末尾的2代表执行故障恢复操作前至少需要几个哨兵节点同意，一般设置为N/2+1(N为哨兵总数) sentinel monitor redis-master 192.168.1.51 7000 2 # 指定了 Sentinel 认为服务器已经断线所需的毫秒数 sentinel down-after-milliseconds redis-master 5000 # 等待该配置内的时间后master还没有恢复响应，则sentinel会排除掉故障的实例，一段时间后再探测如果已恢复则把之前故障的master作为slave处理 sentinel failover-timeout redis-master 900000 # 选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。 sentinel parallel-syncs redis-master 2 # master的访问密码 sentinel auth-pass redis-master 123456 ############### 虚拟内存 ############### # 是否启用虚拟内存机制，虚拟内存机将数据分页存放，把很少访问的页放到swap上，内存占用多，最好关闭虚拟内存 vm-enabled no # 虚拟内存文件位置 vm-swap-file /var/lib/redis/redis.swap # redis使用的最大内存上限，保护redis不会因过多使用物理内存影响性能 vm-max-memory 0 # 每个页面的大小为32字节 vm-page-size 32 # 设置swap文件中页面数量 vm-pages 134217728 # 访问swap文件的线程数 vm-max-threads 4 ############## 缓冲区 ############### # redis为了解决输出缓冲区消息大量堆积的隐患，设置了一些保护机制，主要采用两种限制措施 # 大小限制: 当某一客户端缓冲区超过设定值后直接关闭连接； # 持续性限制: 当某一客户端缓冲区持续一段时间占用过大空间时关闭连接。 # 缓冲区配置项格式如下： # client-output-buffer-limit &lt;class> &lt;hard limit> &lt;soft limit> &lt;soft seconds> # 具体参数含义如下： # class: 客户端种类，normal、slave、pubsub。 # mormal: 普通的客户端 # slave: 从库的复制客户端 # pub/sub: 发布与订阅的客户端的 # hard limit: 缓冲区大小的硬限制。 # soft limit: 缓冲区大小的软限制。 # soft seconds: 缓冲区大小达到了（超过）soft limit值的持续时间，单位秒。 client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # master与slave作psync同步时，master会维护一个FIFO复制缓冲区 # 复制缓冲区大小 repl-backlog-size 1mb # 当master不再与任何slave保持连接时，复制缓冲区可能被清空 # repl-backlog-ttl 用于配置从断开连接到清空缓冲区间隔的秒数 # 0 表示永不清除缓冲区 repl-backlog-ttl 3600 ############### 高级配置 ############### # 哈希表中元素（条目）总个数不超过设定数量时，采用线性紧凑格式存储来节省空间 hash-max-zipmap-entries 512 # 哈希表中每个value的长度不超过多少字节时，采用线性紧凑格式存储来节省空间 hash-max-zipmap-value 64 # list数据类型多少节点以下会采用去指针的紧凑存储格式 list-max-ziplist-entries 512 # list数据类型节点值大小小于多少字节会采用紧凑存储格式 list-max-ziplist-value 64 # set数据类型内部数据如果全部是数值型，且包含多少节点以下会采用紧凑格式存储 set-max-intset-entries 512 # 有序序列也可以用一种特别的编码方式来处理，可节省大量空间。这种编码只适合长度和元素都符合下面限制的有序序列： zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # 是否激活重置哈希 activerehashing yes 运维命令 服务启停
1 2 3 4 5 6 7 8 9 10 11 # redis服务端启停 ./redis-server # 前台进程，配置daemonize yes后可后台常驻 ./redis-server &amp; # 后台进程 ./redis-server --sentinel # 哨兵模式启动 ./redis-server ./redis.conf --daemonize yes --port 1123 # 指定配置文件并后台启动且端口是1123 kill $(ps -ef|grep redis-server|grep -v grep|awk '{print $2}') #杀死redis进程 ./redis-cli shutdown # 通过客户端停止服务端 # redis客户端 ./redis-cli ping # 直接执行redis命令 ./redis-cli -a 'password' ping # 密码验证 ./redis-cli -h 127.0.0.1 -p 6379 # 进入交互模式 交互模式
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 redis-cli &lt;&lt;EOF 交互式命令(不区分大小写) EOF # 显示帮助 > HELP # 显示命令的帮助 > COMMAND # 反正所有命令的帮助 > COMMAND COUNT # 返回服务器支持的命令的个数 > COMMAND INFO &lt;commands> # 返回指定命令的帮助 # 显示命令参数中的key > COMMAND GETKEYS &lt;command> # 检查到服务端的连接状态 > PING # 回显消息 > ECHO &lt;message> # 查看当前服务器时间 > TIME # 显示当前实例所属角色 > ROLE # 调试 > DEBUG OBJECT &lt;key> # 返回key的调试信息 > DEBUG SEGFAULT # 让redis服务崩溃 # 关闭redis > SHUTDOWN # 数据会同步到磁盘 # 关闭连接 > QUIT # 查看配置 > CONFIG GET 配置项名称 # 查看单个配置 > CONFIG GET * # 查看所有配置 例: CONFIG GET requirepass # 获取密码 # 更新配置 > CONFIG SET 配置项名称 配置项参数值 # 更新配置项 > CONFIG REWRITE # 配置更新持久化到配置文件 > CONFIG RESETSTAT # 重置info命令中的某些统计数据 例: CONFIG SET requirepass "" # 取消密码 # 显示redis服务器统计信息 > INFO [section] # Server Cluster Clients CPU Memory Stats Persistence Replication # 客户端 > CLIENT LIST # 显示所有客户端连接 > CLIENT GETNAME # 获取连接名称 > CLIENT SETNAME &lt;name> # 设置当前连接名称 > CLIENT PAUSE &lt;timeout> # 在指定时间内终止运行来自客户端的命令 > CLIENT KILL &lt;ip:port> # 关闭指定客户端 # 实时打印redis服务端接收的指令 > MONITOR # 密码认证 > AUTH &lt;passwd> # 进行密码认证 > REQUIREPASS &lt;passwd> # 设置认证密码 > MASTERAUTH # 设置master的认证密码 # 慢日志 > SLOWLOG RESET # 重置慢日志记录 > SLOWLOG GET &lt;int> # 查询前N条慢日志内容 > SLOWLOG LEN # 查询慢日志条数 # 数据库 > SELECT &lt;int> # 选择编号为N的数据库 > DBSIZE # 查询当前库键总数 > KEYS &lt;pattern> # 查询匹配的所有key > KEYS * # 查询当前库所有key > EXISTS &lt;key> # 确认key是否存在 > DEL &lt;key> # 删除一个key > TYPE &lt;key> # 查看key的值类型 > RENAME &lt;key> &lt;newkey># 重命名key > RENAMENX &lt;key> &lt;newkey> # 被重命名的新名称不存在的时候才有效 > MOVE &lt;key> &lt;dbindex> # 将当前库中的key移动到指定库中 > RANDOMKEY # 随机返回一个key > FLUSHDB # 清空当前库所有key > FLUSHALL # 清空所有库所有key > DUMP &lt;key> # 迁出指定key(value采用rdb格式序列化) > RESTORE &lt;key> &lt;ttl> &lt;serialized-value> [replace] # 迁入指定key > MIGRATE &lt;host> &lt;port> &lt;key> [ key ......] &lt;dest-db> &lt;timeout> [replace] # migrate整合数据迁移 # 事务 > MULTI # 标记一个事务块的开始 > DISCARD # 取消事务，放弃执行事务块内的所有命令 > EXEC # 执行所有事务块内的命令 > WATCH &lt;keys> # 监视一个(或多个)key,如果在事务执行之前这个(或这些)key被其他命令所改动，那么事务将被打断 > UNWATCH # 取消WATCH命令对所有key的监视 # 脚本 > EVAL &lt;script> &lt;numkeys> [keys] [args] # 执行Lua脚本 > EVALSHA &lt;sha1> &lt;numkeys> [keys] [args] # 执行Lua脚本 > SCRIPT EXISTS &lt;scripts> # 查看指定的脚本是否已经被保存在缓存当中 > SCRIPT FLUSH # 从脚本缓存中移除所有脚本 > SCRIPT KILL # 杀死当前正在运行的Lua脚本 > SCRIPT LOAD &lt;script> # 将脚本添加到脚本缓存中但并不立即执行这个脚本 # 持久化 > SAVE # 将数据以rdb快照方式同步保存到磁盘 > BGSAVE # 将数据以rdb快照方式异步保存到磁盘 > LASTSAVE # 返回上次成功将数据rdb快照保存到磁盘的Unix时间戳 > BGREWRITEAOF # 手动触发aof日志重写 # 主备 > SLAVEOF # 将当前实例作为某个示例的slave > SLAVEOF no one # 将当前实例提升为master # sentinel > INFO # 哨兵集群信息 > SENTINEL MASTERS # 列出所有被监视的主服务器，以及这些主服务器的当前状态 > SENTINEL SLAVES &lt;master-name> # 列出指定主redis的从节点状态情况 > SENTINEL SENTINELS &lt;master-name> # 列出指定主redis的监控哨兵信息，不包含他自己 > SENTINEL GET-MASTER-ADDR-BY-NAME &lt;master-name> # 返回给定名字的主服务器的 IP 地址和端口号 > SENTINEL &lt;master-name> # 重置所有名字和给定模式pattern相匹配的主服务器。重置操作清除主服务器目前的所有状态，包括正在执行中的故障转移，并移除目前已经发现和关联的主服务器的所有从服务器和sentinel > SENTINEL FAILOVER &lt;master-name> # 当主服务器失效时 在不询问其他sentinel意见的情况下，强制开始一次自动故障迁移，但是它会给其他sentinel发送一个最新的配置，其他sentinel会根据这个配置进行更新 > SENTINEL CKQUORUM &lt;master-name> # 检查当前在线的哨兵节点。如果一共有5个节点，设置4票，但检查后只有3节点在线，那一直无法进行监控切换 > SENTINEL REMOVE &lt;master name> # 取消当前哨兵对某主节点的监控 > SENTINEL FLUSHCONFIG # 将配置强制刷新到本地文件 # cluster > CLUSTER INFO # 查看集群状态数据 > CLUSTER NODES # 查看集群节点信息 > CLUSTER FORGET &lt;nodeid> # 将节点从集群移除 > CLUSTER MEET &lt;ip> &lt;port> # 将节点加入集群 > CLUSTER REPLICATE &lt;nodeid> # 将当前节点设置为指定节点的slave节点 > CLUSTER SAVECONFIG # 将节点的配置文件持久化到磁盘 > CLUSTER ADDSLOTS &lt;slots> # 将一个或多个slot槽指派给当前节点 > CLUSTER DELSLOTS &lt;slots> # 移除一个或多个槽对当前节点的指派 > CLUSTER FLUSHSLOTS # 移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点 > CLUSTER SETSLOT &lt;slot> node &lt;nodeid> # 将槽指派给指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽，然后再进行指派 > CLUSTER SETSLOT &lt;slot> MIGRATING &lt;nodeid> # 将本节点的槽迁移到指定的节点中 > CLUSTER SETSLOT &lt;slot> IMPORTING &lt;nodeid> # 从指定的节点中导入槽到本节点 > CLUSTER SETSLOT &lt;slot> STABLE # 取消对槽的导入或者迁移 > CLUSTER KEYSLOT &lt;key> # 计算键应该被放置在哪个槽上 > CLUSTER COUNTKEYSINSLOT &lt;slot> # 返回槽目前包含的键值对数量 > CLUSTER GETKEYSINSLOT &lt;slot> &lt;count> # 返回指定槽中指定个数的键 # 键值过期 > EXPIRE &lt;key> &lt;seconds> # 设置key在n秒后过期 > PEXPIRE &lt;key> &lt;milliseconds> # 设置key在n毫秒后过期 > EXPIREAT &lt;key> &lt;timestamp> # 设置key在某个时间戳(精确到秒)之后过期 > PEXPIREAT &lt;key> &lt;millisecondsTimestamp> # 设置key在某个时间戳(精确到毫秒)之后过期 > TTL &lt;key> # 以秒为单位获取key的剩余时间 > PTTL &lt;key> # 以毫秒为单位获取key的剩余时间 > PERSIST &lt;key> # 将有过期时间的key转换为无过期的key # 发布订阅 > SUBSCRIBE &lt;channels> # 订阅给定的一个或多个频道 > PSUBSCRIBE &lt;patterns> # 订阅一个或多个符合给定模式的频道 > UNSUBSCRIBE &lt;channels> # 指示客户端退订给定的频道 > PUNSUBSCRIBE &lt;patterns> # 指示客户端退订所有给定模式的频道 > PUBLISH &lt;channel> &lt;message> # 将信息发送到指定的频道 > PUBSUB CHANNELS &lt;patterns> # 列出当前的活跃频道 > PUBSUB NUMSUB &lt;channels> # 返回给定频道的订阅者数量 > PUBSUB NUMPAT # 返回客户端订阅的所有模式的数量总和 数据类型
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 ################## String ################## String(字符串): (1) SET :是定义值的时候用的 (2) GET :获取键的值时候用的 (3) EXISTS :判断键是否存在 (4) INCR :整数+1 (5) DECR :整数减-1 127.0.0.1:6379> HELP SET #查看SET的用法 127.0.0.1:6379> SET name test #定义一个键名为name,而name对应的值为test OK 127.0.0.1:6379> GET name #可以换取name这个键的值 "test" 127.0.0.1:6379> SET name centos #如果再次定义的话,新的值就会覆盖旧的值,所以同一个名称空间中键不允许重复 OK 127.0.0.1:6379> GET name "centos" 127.0.0.1:6379> APPEND name rhel #追加新的值到name键中 (integer) 10 #显示了追加后的name键对应值的字符串长度 127.0.0.1:6379> GET name "centosrhel" 127.0.0.1:6379> STRLEN name #手动获取name键对应值的字符串长度 (integer) 10 127.0.0.1:6379> SET count 0 #定义名为count的键,值为0 OK 127.0.0.1:6379> INCR count #使count的值加1,执行一次加一次1,你可以多执行几次再看看值,此处就不再重复演示 (integer) 1 127.0.0.1:6379> DECR count #使count的值减1,执行一次减一次1,也会达到负数,多执行几次看一下 (integer) 2 #我上面执行了三遍INCR所以执行一次DECR就是2,在执行就是1,在执行就是0 127.0.0.1:6379> SET name centos NX #执行会失败,NX的意思是当键中没有值的时候才会设定键,否则不会设定 (nil) 127.0.0.1:6379> SET name2 centos XX #执行会失败,XX的意思就是当键中有值的时候才会设定键,否则不会设定 (nil) 127.0.0.1:6379> SET name centos XX EX 10 #表示name键有值的时候才会赋值,并且赋值完成后过10秒后自动过期 ################## List ################## List(列表): (1) RPUSH :从右侧添加一个值到列表中 (2) LPUSH :从左侧添加一个值到列表中 (3) LPOP :从左侧逐一删除值 (4) RPOP :从右侧逐一删除值 (5) LINDEX :指明索引位置并且获取值 (6) LSET :修改列表中的值 127.0.0.1:6379> HELP @list #查看list数组中的相关帮助 127.0.0.1:6379> LPUSH l1 mon #从左侧生成一个名为l1的列表 (integer) 1 127.0.0.1:6379> LINDEX l1 0 #查看名为l1的列表,并且指定第一个值的位置 "mon" 127.0.0.1:6379> LPUSH l1 sun #从左侧新添加一个值为sun到l1列表中 (integer) 2 127.0.0.1:6379> LINDEX l1 1 #此时原本在0这个位置的mon位置就会变成了1,因为前面挤了一个sun "mon" 127.0.0.1:6379> LINDEX l1 0 #获取的就是sun的值,因为从左侧新添加的,所以第一个必定是新添加的值 "sun" 127.0.0.1:6379> RPUSH l1 tue #从右侧新添加一个值为tue到l1列表中 (integer) 3 127.0.0.1:6379> LINDEX l1 2 #查看到的结果就是tue,因为从左侧添加,则0必定是新添加的值,而从右侧添加,则最后一个值必定是新添加的值 "tue" 127.0.0.1:6379> LSET l1 1 fri #修改l1列表中位置在1上的值为fri,那么原本在1上面的mon就会被替换为fri OK 127.0.0.1:6379> RPOP l1 #删除从右侧开始的第一个值,执行后会删除tue "tue" ################## Hash ################## Hash(哈希): (1) HSET :定义一个hash (2) HGET :获取键中子键对应的值 (3) HDEL :删除键中子键 (4) HKEYS :获取h1键中所有的子键名称 (5) HVALES :获取h1键中所有子键对应的值 (6) HLEN :获取h1键中拥有的hash个数 127.0.0.1:6379> HELP @hash #查看Hash数组的相关帮助 127.0.0.1:6379> HSET h1 a mon #创建一个h1键,定义当中有名为a对应mon的hash (integer) 1 127.0.0.1:6379> HGET h1 a #获取h1键中a对应的值,定义的时候对应的是什么这里显示就会是什么 "mon" 127.0.0.1:6379> HSET h1 b tue #在h1键中重新添加一个名为b对应tue的hash (integer) 1 127.0.0.1:6379> HDEL h1 b #删除某一个键下的子键对应的值 "tue" 127.0.0.1:6379> HKEYS h1 #能够获取h1键中所有的子键名称 1) "a" 127.0.0.1:6379> HVALS h1 #能够获取h1键中所有的子键对应的值 1) "mon" 127.0.0.1:6379> HLEN h1 #获取h1键中拥有的hash个数 (integer) 1 ################## Set ################## Set(集合): (1) SADD :创建新的集合 (2) SINTER :求两个集合的交集 (3) SUNION :求两个集合的并集,就是两个集合中都存在的,并且打印出来一份 (4) SISMEMBER:判断集合中指定的元素是否存在 (5) SPOP :从集合中随机删除一个元素 127.0.0.1:6379> HELP @set #查看set数组中的相关帮助 127.0.0.1:6379> SADD v1 mon tue wen thu fri sat sun #创建一个名为v1的集合,并且包含的内容为"mon,tue,wen...sun" (integer) 7 127.0.0.1:6379> SADD v2 tue thu day #创建一个名为v2的集合,并且包含的内容为"tue,thu,day" (integer) 3 127.0.0.1:6379> SINTER v1 v2 #对比两个集合中是否存在交集 1) "thu" #如果两个集合中有相同的值,那么会显示在屏幕上 2) "tue" 127.0.0.1:6379> SUNION v1 v2 #对比两个集合中的并集 1) "sun" 2) "mon" 3) "tue" 4) "thu" 5) "wed" 6) "fri" 7) "sat" #这个值只在v1中,但是还是打印出来了,就是v1中存在的打印出来 8) "day" #这个值只在v2中,但是还是打印出来了,就是v2中存在的也打印出来 127.0.0.1:6379> SPOP v1 #删除并弹出v1中的其中一个值,这个值是随机的 "wed" 127.0.0.1:6379> SISMEMBER v1 wed #判断集合中的wed是否还是一个元素 (integer) 0 #因为上面SPOP随机在v1中删除了一个元素,所以此时判断则为0 ################## ZSet ################## ZSet(有序集合): (1) ZADD :添加一个有序集合 (2) ZCARD :查看有序集合的元素个数 (3) ZRANK :查看指定元素对应的SCORE号 (4) ZRANGE :按照内置索引显示从"min-max"之间的索引 127.0.0.1:6379> HELP @sorted_set #查看sorted_set中的相关帮助 127.0.0.1:6379> ZADD weekday1 1 mon 2 tue 3 wed #添加名为weekday1的集合,值用(1,2,3)来指定SCORE,SCORE后面跟值 (integer) 3 127.0.0.1:6379> ZCARD weekday1 #获取有序集合的元素个数 (integer) 3 127.0.0.1:6379> ZRANK weekday1 tue #查看weekday1中tue元素对应的索引号 (integer) 1 127.0.0.1:6379> ZRANK weekday1 mon #SCORE数字大小决定了你的排序(因为我们有内置索引),如果从1开始定义,那么1对应的mon就会是0 (integer) 0 127.0.0.1:6379> ZSCORE weekday1 tue #根据元素来获取SCORE "2" 127.0.0.1:6379> ZRANGE weekday1 0 1 #显示weekday1中按照内置索引从0到1之间的所有元素 0)"mon" 1)"tue" 持久化管理
1 2 3 4 5 6 # AOF日志文件出错后修复方法 redis-check-aof --fix appendonly.aof # --fix参数为修复日志文件，不加则对日志检查 # 不重启redis从RDB持久化切换到AOF持久化 redis-cli> CONFIG SET appendonly yes # 启用AOF redis-cli> CONFIG SET save "" # 关闭RDB Cluster集群
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # 查询cluster集群状态 ./redis-cli cluster info cluster_state:ok # ok: 集群可正常接受查询请求；fail：至少有一个哈希槽未被绑定或集群处于错误状态 cluster_slots_assigned:16384 # 已分配到集群节点的哈希槽数量 cluster_slots_ok:16384 # 哈希槽状态不是FAIL和PFAIL的数量 cluster_slots_pfail:0 # 哈希槽状态是PFAIL的数量(临时错误状态，当前不能和节点交互) cluster_slots_fail:0 # 哈希槽状态是FAIL的数量(错误状态，集群节点无法提供查询服务) cluster_known_nodes:6 # 群中节点数量，包括处于握手状态还没有成为集群正式成员的节点 cluster_size:3 # 至少包含一个哈希槽且能够提供服务的master节点数量 cluster_current_epoch:6 # 集群本地Current Epoch变量的值 cluster_my_epoch:1 # 当前正在使用的节点的Config Epoch值 cluster_stats_messages_ping_sent:243 # 通过node-to-node二进制总线发送的消息数量 cluster_stats_messages_pong_sent:235 cluster_stats_messages_sent:478 cluster_stats_messages_ping_received:230 # 通过node-to-node二进制总线接收的消息数量 cluster_stats_messages_pong_received:243 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:478 # 查看集群节点信息 ./redis-cli cluster nodes ID IP:PORT FLAGS MASTER PING-SENT PONG-RECV CONFIG-EPOCH LINK-STATE SLOT 0f972c205a469c25aad28790dfdc43989b5dcca3 127.0.0.1:7003@17003 slave 4e0062198602ae83f8981b1da12b37017ac7d1d0 0 1592989019686 4 connected b6b367d00e42026e0edc0e7725695a1dddc385ed 127.0.0.1:7000@17000 myself,master - 0 1592989017000 1 connected 0-5460 ID: 节点ID,是一个40字节的随机字符串，这个值在节点启动的时候创建，并且永远不会改变（除非使用CLUSTER RESET HARD命令）。 IP:PORT: 客户端与节点通信使用的地址. FLAGS: 逗号分割的标记位，可能的值有: myself, master, slave, fail?, fail, handshake, noaddr, noflags MASTER: 如果节点是slave，并且已知master节点，则这里列出master节点ID,否则的话这里列出”-“。 PING-SENT: 最近一次发送ping的时间，这个时间是一个unix毫秒时间戳，0代表没有发送过. PONG-RECV: 最近一次收到pong的时间，使用unix时间戳表示. CONFIG-EPOCH: 节点的epoch值（or of the current master if the node is a slave）。每当节点发生失败切换时，都会创建一个新的，独特的，递增的epoch。如果多个节点竞争同一个哈希槽时，epoch值更高的节点会抢夺到。 LINK-STATE: node-to-node集群总线使用的链接的状态，我们使用这个链接与集群中其他节点进行通信.值可以是 connected 和 disconnected. SLOT: 哈希槽值或者一个哈希槽范围. 从第9个参数开始，后面最多可能有16384个 数(limit never reached)。代表当前节点可以提供服务的所有哈希槽值。如果只是一个值,那就是只有一个槽会被使用。如果是一个范围，这个值表示为起始槽-结束槽，节点将处理包括起始槽和结束槽在内的所有哈希槽。 各flags的含义 myself: 当前连接的节点. master: 节点是master. slave: 节点是slave. fail?: 节点处于PFAIL 状态。 当前节点无法联系，但逻辑上是可达的 (非 FAIL 状态). fail: 节点处于FAIL 状态. 大部分节点都无法与其取得联系将会将改节点由 PFAIL 状态升级至FAIL状态。 handshake: 还未取得信任的节点，当前正在与其进行握手. noaddr: 没有地址的节点（No address known for this node）. noflags: 连个标记都没有（No flags at all） 性能测试
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # redis性能测试是通过同时执行多个命令实现的 # redis自带redis-benchmark命令用于性能测试，该命令是在redis的目录下执行的，而不是redis客户端的内部指令 ./redis-benchmark -n 10000 -q # redis-benchmark参数： -h: 指定服务器主机名,默认127.0.0.1 -p: 指定服务器端口,默认6379 -s: 指定服务器socket -c: 指定并发连接数,默认50 -n: 指定请求数,默认10000 -d: 以字节的形式指定SET/GET值的数据大小,默认2 -k: 是否保持连接,0每次重连接,1保持连接,默认1 -r: SET/GET/INCR使用随机key,SADD使用随机值 -P: 通过管道传输&lt;numreq>请求,默认1 -q: 强制退出redis,仅显示query/sec值 -l: 生成循环,永久执行测试 -t: 仅运行以逗号分隔的测试命令列表 -I: idle模式,仅打开N个idle连接并等待 --csv: 以csv格式输出 常用API 相关工具 文章推荐 一致性哈希与哈希槽对比 Redis数据结构-简单动态字符串SDS Redis数据结构-压缩列表 Redis数据结构-链表 Redis数据结构-字典 Redis数据结构-quicklist Redis数据结构-整数集合 Redis数据结构-跳表 Redis对象-HyperLogLog Redis基础-剖析基础数据结构及其用法 Redis基础-了解Redis是如何做数据持久化的 跟随杠精的视角一起来了解Redis的主从复制 Redis Sentinel-深入浅出原理和实践 深度图解Redis Cluster原理 细说Redis九种数据类型和应用场景 Redis发布/订阅与Stream Redis Cluster集群扩容缩容原理及实战 排障经验 MySQL PostgreSQL MongoDB Etcd Kubernetes Harbor Kerberos 基于加密票证的网络身份认证协议
基本概念 Kerberos: Kerberos源于古希腊神话中守护地狱之门的三头犬Cerberus, 是一种认证协议, 其核心技术是对称加密和第三方认证中心. Kerberos仅作认证之用, 并不支持权限控制, 其定位与TLS有部分相似. 基于Kerberos协议实现的网络身份认证系统也被称为Kerberos, 这些系统通常包含KDC, Server和Client三个部分 KDC: KDC全称Key Distribution Center, 即密钥分发中心, 是Kerberos的核心, 包含Account Database, Authentication Service和Ticket Granting Service三大组件, 负责对Client身份的存储校验和票证的分发, 在Windows域环境中个, KDC的角色由Domain Controller(DC)来担当 Server: Server是被访问的网络对象, 通常是服务器或者提供某种服务的应用程序, 也称作Service Client: Client是发出访问请求的网络对象, 通常是客户端应用程序, Server访问其他Server时也是Client AD: AD全称Account Database, 也称Kerberos Database, 是存储Client及其密码的数据库. AD类似于SAM的数据库, 存储所有Client的白名单, 只有处于白名单中的Client才可以成功申请Ticket Granting Ticket(TGT) AS: AS全称Authentication Service, 即身份验证服务, 负责根据AD和Client传入的密钥验证Client身份并发放Ticket Granting Ticket(TGT) TGS: TGS全称Ticket Granting Service, 即票证授权服务, 它通过验证Ticket Granting Ticket(TGT)与Authenticator, 为Client发放Server Ticket Ticket: Ticket即票证(票据), 是网络对象(即KDC, Client和Server)之间相互访问的凭证, 凭证是对服务的主体名称、用户的主体名称、用户主机的ip地址、时间标记、会话密钥、定义票证生命周期的时间戳等信息的加密, 凭证接受者解密凭证后可据此判断请求者是否合法 TGT: TGT全称Ticket Granting Ticket, 即票证授予票证, 也就是入场券, 通过入场券能够获得Server Ticket Principal: principal即主体, 是Kerberos体系中的用户名, 用于标识Client或Server的身份. Principal主要由三部分组成: primary, instance(可选)和realm. 包含instance的principal一般会作为server端的principal, 如NameNode, HiverServer2, Presto Coordinator等; 不含有instance的principal, 一般会作为Client的principal, 用于身份认证 Realm: realm表示包含KDC和若干Client与Service的网络域, 可以认为是命名空间, Kerberos服务端KDC可以管理多个realm, 不同realm之间的Client Principal不通用 Authenticator: authenticator即验证者, 是Server用于验证Client主体的信息. 验证者包含Client的主体名称、时间标记和其他数据. 与票证不同, Authenticator只能使用一次, 通常在请求访问Server时使用 Password: password就是Principal的密码, 与Master Key对应, password可被存储在keytab文件中 Credential: credential是"证明某个人确定是他自己/某一种行为的确可以发生"的凭据. 在不同的使用场景下, credential的具体含义也略有不同: 对于某个principal个体而言, 他的credential就是他的password; 在kerberos认证的环节中, credential就意味着各种各样的ticket Keytab: keytab即密码本, 是包含多个Principal及其密码的文件(kerberos使用对称加密, 密码可等同于密钥). keytab文件对于每个host是唯一的, 因为key中包含hostname, Client和Server可以利用该文件进行非交互式的身份认证, 因此keytab文件应当妥善保存 Master Key: master key即长期密钥, 是被hash加密的Principal密码 Session Key: session key即短期会话密钥, 仅在一段时间内有效 架构特性 集群架构
认证原理
kerberos认证整个流程的基本前提:
Kerberos基于Ticket实现身份认证, 而非密码. 如果Client无法利用本地密钥解密出KDC返回的加密Ticket, 认证将无法通过 Client将依次与Authentication Service, Ticket Granting Service以及目标Server/Service进行交互, 共三次交互 Client与其他组件交互时, 都将获取到两条信息, 其中一条可以通过本地密钥解密出, 另外一条将无法解密出 Client想要访问的目标Server, 将不会直接与KDC交互, 而是通过能否正确解密出Client的请求来进行认证 KDC的Account Database包含有所有principal对应的密码, 包括Client和Server的 Kerberos中信息加密方式一般是对称加密(可配置成非对称加密) Kerberos的认证流程可分为三个阶段:
Client与Authentication Service
Client通过kinit PRINCIPAL或其他方式, 将ClientID, 目标ServerID, 网络地址)可能是多个机器的IP地址列表, 如果想在任何机器上使用, 则可能为空), 以及TGT有效期的寿命等信息发送给Authentication Service Authentication Service将检查客户端ID是否在KDC Account Database中. 如果Authentication Service检查操作没有异常, 那么KDC将随机生成一个 key, 用于客户端与 Ticket Granting Service(TGS) 通信. 这个Key, 一般被称为 TGS Session Key. 随后 Authentication Service将发送两条信息给Client. 其中一条信息被称为TGT(也就是入场券), 由TGS的密钥加密, Client无法解密, 包含ClientID, TGS Session Key等信息. 另一条信息由Client密钥加密, Client可以正常解密, 包含目标ServerID, TGS Session Key等信息 Client利用本地的密钥解密出第二条信息, 如果本地密钥无法解密出信息, 那么认证失败 Client与Ticket Granting Service
Client完成与Authentication Service的通信后, 就得到了TGT(入场券), 由于本地没有TGS的密钥, 导致无法解密出其数据)与TGS Session Key
将Authentication Service发送过来的TGT(由TGS密钥加密)和包含自身信息的Authenticator(由TGS Session Key加密)转发给Ticket Granting Service(TGS)
Ticket Granting Service(TGS)将利用自身的密钥从TGT(入场券)中解密出TGS Session Key, 然后利用TGS Session Key从Authenticator中解密出Client的信息
Ticket Granting Service(TGS)解密出所有信息后, 将进行身份检查, 进行认证:
将ClientID与TGT(入场券)的ClientID进行比较 比较来自Authenticator的时间戳和TGT(入场券)的时间戳(典型的Kerberos系统的时间差容忍度是2分钟, 但也可以另行配置) 检查TGT(入场券)是否过期 检查Authenticator是否已经在Ticket Granting Service(TGS)的缓存中(为了避免重放攻击) 当所有检查都通过后, Ticket Granting Service(TGS)随机生成一个Key用于后续Client与 目标Server交互时进行通信加密使用, 即Server Session Key. 同样地, TGS将发送两条信息给Client: 其中一条是 Server Ticket, 由目标Server的密钥进行加密; 另一条则由TGS Session Key加密, 包含了客户端信息与时间戳
Client将利用TGS Session Key解密出其中一条信息, 另一条信息由于是由目标Server加密, 无法解密
Client与目标Server
Client完成与Ticket Granting Service的通信后, 就有了Server Ticket(由于本地没有目标Server的密钥, 导致无法解密出其数据)与Server Session Key
将TGS发送过来的Server Ticket(由目标Server的密钥加密)和包含自身信息的Authenticator(由Server Session Key加密)转发给目标Server 目标Server首先利用自身的密钥解密出Server Ticket的信息, 得到Server Session Key; 随后利用Server Session Key解密出Client的Authenticator信息 信息解密完成后, 目标Server同样需要做一些信息检查: 将Authenticator中的ClientID与Server Ticket中的ClientID进行比较 比较来自Authenticator的时间戳和Server Ticket的时间戳(典型的Kerberos系统对时间差容忍度是 2 分钟, 但也可以另行配置) 检查Ticket是否过期 检查Authenticator是否已经在目标Server的缓存中(为了避免重播攻击) 至此, 所有的认证过程通过, Client与远程Server完成了身份认证, 可以进行后续的信息通信
Kerberos与TLS
Kerberos和TLS都具有身份认证的作用, 但二者的实现机制和侧重点截然不同.
Kerberos专注于身份认证, 认证完成后的Client与Server的通信并不要求数据加密; TLS兼顾身份认证和加密通信 Kerberos使用的加密技术为对称加密(可配置为非对称); TLS在身份认证和密钥协商阶段使用非对称加密, 在加密通信阶段则使用的是对称加密 Kerberos依赖第三方的认证中心KDC进行用户密钥的分发和认证; TLS利用非对称密钥和数字证书机制, 只需要虚拟的根证书颁发机构的CA证书, 无需依赖单独的认证服务, 当然如果需要, 也可以使用单独的证书管理服务进行证书的签发 Kerberos是双向认证的, Client和Server相互验证; TLS可配置为单向验证Server或双向验证 Kerberos的认证需要Client和Server保留各自的keytab并配置KDC信息; TLS单向认证只要求Client持有CA证书, Server持有自身的证书和私钥, 双向验证要求Client和Server均持有CA证书和各自的证书和私钥 Kerberos是高性能的, 一旦Client获得过访问某个Server的Ticket, 该Server就能根据这个Ticket实现对Client的验证, 而无须KDC的再次参与; TLS也是高性能的, 只在Client和Server连接建立阶段需要进行身份验证和密钥协商, 后续通信只需要使用对称密钥进行加解密 Kerberos高级用法
Kerberos可以配置主从高可用, 借助kpropd实现主KDC到备KDC数据的定时同步, 但无法做到自动切换 Kerberos可以结合KeepAlived+Rsync实现可自动切换的高可以, KeepAlived负责进行主从切换, Rsync负责主备数据同步 Kerberos可与LDAP结合, 将LDAP配置为Kerberos的帐号数据库(kdb5_ldap_util), 由LDAP提供帐号管理, Kerberos负责服务认证 基于Hadoop的大数据生态圈软件基本都支持Kerberos认证, 可通过配置大数据各组件启用Kerberos实现统一认证 Kerberos不提供细粒度权限控制, 可通过与Ranger结合, 由Ranger通过各种插件实现大数据组件的权限控制, Ranger后端对接Kerberos实现用户认证 Hadoop启用Kerberos的Docker镜像
Hadoop Base Dockfile:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 FROM centos:7 ARG HADOOP_DOWNLOAD=https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz ARG HADOOP_GROUP=hadoop ARG HADOOP_VERSION=3.2.1 ENV JAVA_HOME /usr/lib/jvm/jre-1.8.0-openjdk ENV HADOOP_HOME /opt/hadoop-$HADOOP_VERSION ENV HADOOP_USER_HDFS hdfs ENV HADOOP_USER_YARN yarn ENV HADOOP_USER_MAPRED mapred RUN yum -y update \ &amp;&amp; yum install -y wget openssl net-tools \ &amp;&amp; yum install -y openssh-server openssh-clients \ &amp;&amp; yum install -y krb5-workstation \ &amp;&amp; yum install -y java-1.8.0-openjdk \ &amp;&amp; groupadd -g 1001 $HADOOP_GROUP \ &amp;&amp; useradd -d /home/$HADOOP_USER_HDFS -m -u 1001 -g $HADOOP_GROUP -s /bin/bash -p $HADOOP_USER_HDFS $HADOOP_USER_HDFS \ &amp;&amp; useradd -d /home/$HADOOP_USER_YARN -m -u 1002 -g $HADOOP_GROUP -s /bin/bash -p $HADOOP_USER_YARN $HADOOP_USER_YARN \ &amp;&amp; useradd -d /home/$HADOOP_USER_MAPRED -m -u 1003 -g $HADOOP_GROUP -s /bin/bash -p $HADOOP_USER_MAPRED $HADOOP_USER_MAPRED \ &amp;&amp; echo 'export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk' > /etc/profile.d/hadoop.sh \ &amp;&amp; echo 'export HDFS_NAMENODE_USER=$HADOOP_USER_HDFS' >> /etc/profile.d/hadoop.sh \ &amp;&amp; echo 'export HDFS_DATANODE_USER=$HADOOP_USER_HDFS' >> /etc/profile.d/hadoop.sh \ &amp;&amp; echo 'export HDFS_SECONDARYNAMENODE_USER=$HADOOP_USER_HDFS' >> /etc/profile.d/hadoop.sh \ &amp;&amp; source /etc/profile.d/hadoop.sh \ # config kerberos &amp;&amp; sed -i 's/EXAMPLE.COM/DEV/' /etc/krb5.conf \ &amp;&amp; sed -i 's/example.com/dev/' /etc/krb5.conf \ &amp;&amp; sed -i '/default_realm/s/^#//' /etc/krb5.conf \ &amp;&amp; sed -i '/DEV/s/^#//' /etc/krb5.conf \ &amp;&amp; sed -i '/dev/s/^#//' /etc/krb5.conf \ &amp;&amp; sed -i '/ }/s/^#//' /etc/krb5.conf \ &amp;&amp; sed -i '/default_ccache_name/s/^ /# /' /etc/krb5.conf \ # config ssh &amp;&amp; ssh-keygen -t rsa -P '' -f /etc/ssh/ssh_host_rsa_key \ &amp;&amp; ssh-keygen -t rsa -P '' -f /etc/ssh/ssh_host_ecdsa_key \ &amp;&amp; ssh-keygen -t rsa -P '' -f /etc/ssh/ssh_host_ed25519_key \ &amp;&amp; su - $HADOOP_USER_HDFS -c "ssh-keygen -t rsa -P '' -f /home/$HADOOP_USER_HDFS/.ssh/id_rsa" \ &amp;&amp; su - $HADOOP_USER_YARN -c "ssh-keygen -t rsa -P '' -f /home/$HADOOP_USER_YARN/.ssh/id_rsa" \ &amp;&amp; su - $HADOOP_USER_MAPRED -c "ssh-keygen -t rsa -P '' -f /home/$HADOOP_USER_MAPRED/.ssh/id_rsa" \ &amp;&amp; cp /home/$HADOOP_USER_HDFS/.ssh/id_rsa.pub /home/$HADOOP_USER_HDFS/.ssh/authorized_keys \ &amp;&amp; cp /home/$HADOOP_USER_YARN/.ssh/id_rsa.pub /home/$HADOOP_USER_YARN/.ssh/authorized_keys \ &amp;&amp; cp /home/$HADOOP_USER_MAPRED/.ssh/id_rsa.pub /home/$HADOOP_USER_MAPRED/.ssh/authorized_keys \ &amp;&amp; echo 'StrictHostKeyChecking no' >> /etc/ssh/ssh_config \ # ADD hadoop-3.2.1.tar.gz /opt/ # config hadoop &amp;&amp; wget -P /tmp $HADOOP_DOWNLOAD \ &amp;&amp; tar -zxvf /tmp/hadoop-3.2.1.tar.gz -C /opt/ \ &amp;&amp; chown -R $HADOOP_USER_HDFS:$HADOOP_GROUP $HADOOP_HOME \ &amp;&amp; mkdir /mnt/data \ &amp;&amp; chown $HADOOP_USER_HDFS:$HADOOP_GROUP /mnt/data \ &amp;&amp; mkdir /mnt/name \ &amp;&amp; chown $HADOOP_USER_HDFS:$HADOOP_GROUP /mnt/name \ &amp;&amp; echo export JAVA_HOME=$JAVA_HOME >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh \ &amp;&amp; echo export HDFS_NAMENODE_USER=$HADOOP_USER_HDFS >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh \ &amp;&amp; echo export HDFS_DATANODE_USER=$HADOOP_USER_HDFS >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh \ &amp;&amp; echo export HDFS_SECONDARYNAMENODE_USER=$HADOOP_USER_HDFS >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh \ # core-site.xml &amp;&amp; sed -i '19a\ &lt;property>&lt;name>hadoop.security.authentication&lt;/name>&lt;value>kerberos&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/core-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>hadoop.security.authorization&lt;/name>&lt;value>true&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/core-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>hadoop.tmp.dir&lt;/name>&lt;value>/tmp&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/core-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>fs.defaultFS&lt;/name>&lt;value>hdfs://master.dev:9000&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/core-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>hadoop.security.auth_to_local&lt;/name>&lt;value>RULE:[2:$1](namenode)s/.*/hdfs/ RULE:[2:$1](secondary)s/.*/hdfs/ RULE:[2:$1](datanode)s/.*/hdfs/ RULE:[2:$1](http)s/.*/hdfs/ RULE:[2:$1](resourcemanager)s/.*/yarn/ RULE:[2:$1](nodemanager)s/.*/yarn/ RULE:[2:$1](jobhistory)s/.*/mapred/ &lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/core-site.xml \ # yarn-site.xml &amp;&amp; sed -i '15a\ &lt;property>&lt;name>yarn.nodemanager.keytab&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/yarn-site.xml \ &amp;&amp; sed -i '15a\ &lt;property>&lt;name>yarn.nodemanager.principal&lt;/name>&lt;value>nodemanager/slave.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/yarn-site.xml \ &amp;&amp; sed -i '15a\ &lt;property>&lt;name>yarn.resourcemanager.keytab&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/yarn-site.xml \ &amp;&amp; sed -i '15a\ &lt;property>&lt;name>yarn.resourcemanager.principal&lt;/name>&lt;value>resourcemanager/master.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/yarn-site.xml \ &amp;&amp; sed -i '15a\ &lt;property>&lt;name>yarn.resourcemanager.hostname&lt;/name>&lt;value>master.dev&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/yarn-site.xml \ # ssl &amp;&amp; cp $HADOOP_HOME/etc/hadoop/ssl-client.xml.example $HADOOP_HOME/etc/hadoop/ssl-client.xml \ &amp;&amp; sed -i '23c &lt;value>/mnt/keytab/truststore.jks&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-client.xml \ &amp;&amp; sed -i '31c &lt;value>123456&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-client.xml \ &amp;&amp; sed -i '53c &lt;value>/mnt/keytab/keystore.jks&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-client.xml \ &amp;&amp; sed -i '61c &lt;value>123456&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-client.xml \ &amp;&amp; sed -i '68c &lt;value>123456&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-client.xml \ &amp;&amp; cp $HADOOP_HOME/etc/hadoop/ssl-server.xml.example $HADOOP_HOME/etc/hadoop/ssl-server.xml \ &amp;&amp; sed -i '23c &lt;value>/mnt/keytab/truststore.jks&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-server.xml \ &amp;&amp; sed -i '30c &lt;value>123456&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-server.xml \ &amp;&amp; sed -i '52c &lt;value>/mnt/keytab/keystore.jks&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-server.xml \ &amp;&amp; sed -i '59c &lt;value>123456&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-server.xml \ &amp;&amp; sed -i '66c &lt;value>123456&lt;/value>' $HADOOP_HOME/etc/hadoop/ssl-server.xml \ # config startup script &amp;&amp; echo '/usr/sbin/sshd -D &amp;' > /opt/startup.sh \ &amp;&amp; chmod +x /opt/startup.sh Hadoop Master Dockerfile:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 FROM hadoop ARG HADOOP_VERSION=3.2.1 ENV HADOOP_HOME /opt/hadoop-$HADOOP_VERSION ENV HADOOP_USER_HDFS hdfs RUN sed -i '19a\ &lt;property>&lt;name>dfs.http.policy&lt;/name>&lt;value>HTTPS_ONLY&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.principal&lt;/name>&lt;value>http/master.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.keytab&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.webhdfs.enabled&lt;/name>&lt;value>true&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.principal&lt;/name>&lt;value>http/master.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.keytab&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.keytab&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.principal&lt;/name>&lt;value>http/master.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.keytab.file&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.kerberos.https.principal&lt;/name>&lt;value>http/slave.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.kerberos.principal&lt;/name>&lt;value>datanode/slave.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.data.dir&lt;/name>&lt;value>file:/mnt/data/&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.secondary.namenode.keytab.file&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.secondary.namenode.kerberos.principal&lt;/name>&lt;value>secondary/master.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.namenode.keytab.file&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.namenode.kerberos.https.principal&lt;/name>&lt;value>http/master.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.namenode.kerberos.principal&lt;/name>&lt;value>namenode/master.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.namenode.name.dir&lt;/name>&lt;value>file:/mnt/name/&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.permissions.supergroup&lt;/name>&lt;value>hadoop&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.block.access.token.enable&lt;/name>&lt;value>true&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.replication&lt;/name>&lt;value>3&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; printf "slave1.dev\nslave2.dev\nslave3.dev\nslave4.dev\n" > $HADOOP_HOME/etc/hadoop/workers \ &amp;&amp; echo 'su - $HADOOP_USER_HDFS -c "$HADOOP_HOME/bin/hdfs namenode -format"' >> /opt/startup.sh \ &amp;&amp; echo 'su - $HADOOP_USER_HDFS -c $HADOOP_HOME/sbin/start-dfs.sh' >> /opt/startup.sh \ &amp;&amp; echo '/bin/sh -c "while true; do sleep 60; done"' >> /opt/startup.sh EXPOSE 8088 EXPOSE 9871 CMD /opt/startup.sh Hadoop Slave Dockerfile:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM hadoop RUN sed -i '19a\ &lt;property>&lt;name>dfs.data.transfer.protection&lt;/name>&lt;value>integrity&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.http.policy&lt;/name>&lt;value>HTTPS_ONLY&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.keytab&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.web.authentication.kerberos.principal&lt;/name>&lt;value>http/slave.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.keytab.file&lt;/name>&lt;value>/mnt/keytab/hadoop.keytab&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.kerberos.https.principal&lt;/name>&lt;value>http/slave.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.kerberos.principal&lt;/name>&lt;value>datanode/slave.dev@DEV&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.datanode.data.dir&lt;/name>&lt;value>file:/mnt/data/&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.block.access.token.enable&lt;/name>&lt;value>true&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml \ &amp;&amp; sed -i '19a\ &lt;property>&lt;name>dfs.replication&lt;/name>&lt;value>3&lt;/value>&lt;/property>' $HADOOP_HOME/etc/hadoop/hdfs-site.xml EXPOSE 9865 CMD /usr/sbin/sshd -D 使用docker-compose build 构建完成后, 要先启动slave节点, 然后启动master节点(需要启动多少个slave节点, 就执行多少次启动slave命令):
1 2 3 4 5 6 7 8 9 10 11 docker-compose build docker run --network br0 --ip 192.168.1.5 -p53:53 -p123:123 --hostname gate --name gate -d gate docker run --network br0 --ip 192.168.1.7 -p88:88 -p750:750 --hostname kerberose --dns 192.168.1.5 --name kerberos -v keytab:/mnt/keytab -d kerberos docker run --network br0 --ip 192.168.1.21 -p 9865:9865 --hostname slave1 --dns 192.168.1.5 --name slave1 -v keytab:/mnt/keytab:ro -d slave docker run --network br0 --ip 192.168.1.22 -p 9866:9865 --hostname slave2 --dns 192.168.1.5 --name slave2 -v keytab:/mnt/keytab:ro -d slave docker run --network br0 --ip 192.168.1.23 -p 9867:9865 --hostname slave3 --dns 192.168.1.5 --name slave3 -v keytab:/mnt/keytab:ro -d slave docker run --network br0 --ip 192.168.1.24 -p 9868:9865 --hostname slave4 --dns 192.168.1.5 --name slave4 -v keytab:/mnt/keytab:ro -d slave docker run --network br0 --ip 192.168.1.25 -p 9869:9865 --hostname slave5 --dns 192.168.1.5 --name slave5 -v keytab:/mnt/keytab:ro -d slave docker run --network br0 --ip 192.168.1.26 -p 9870:9865 --hostname slave6 --dns 192.168.1.5 --name slave6 -v keytab:/mnt/keytab:ro -d slave docker run --network br0 --ip 192.168.1.10 -p 9871:9871 -p 8088:8088 --hostname master --dns 192.168.1.5 --name master -v keytab:/mnt/keytab:ro -d master 配置文件 运维命令 常用API 相关工具 文章推荐 官方文档 Kerberos系列 Kerberos简介 一文搞定Kerberos Kerberos配置 Kerberos认证原理 Kerberos基本原理与安装部署 HTTPS详解 Kerberos高可用配置 基于Kerberos的大数据安全解决方案 Kerberos整合LDAP Kerberos+LDAP集成 Hadoop集群开启kerberos并集成Ranger 排障经验 HDFS Hadoop生态分布式文件系统
基本概念 HDFS: HDFS全称Hadoop Distributed File System, 是一个可扩展、容错、高性能的分布式文件系统, 异步复制, 一次写入多次读取. 是Hadoop核心组件之一, 负责Hadoop大数据存储 NameNode: 名字节点是HDFS中的元数据节点, 负责管理整个文件系统的命名空间, 节点信息, 文件信息和数据分块映射等元数据信息. NameNode是客户端访问HDFS的入口. 在Hadoop 2.0版本的HA方案中, NameNode分为Active NameNode和Standby NameNode, 二者维护相同的元数据, 但只有Active NameNode提供服务, 当其故障时Standby NameNode会自动切换为Active NameNode. 在Hadoop 2.0版本的Federation联邦方案中, 多个NameNode可共同提供服务, 每个NameNode负责不同的命名空间 Second NameNode: Second NameNode是NameNode的辅助节点(并不是NameNode的备机), 它定期从NameNode拉取fsimage和editlog文件, 并对两个文件进行合并, 形成新的fsimage文件并传回NameNode, 从而减轻NameNode压力, 辅助NameNode快速恢复, 可以认为是NameNode的检查点节点. 在Hadoop 1.0版中, NameNode存在单点问题, Second NameNode也不能解决此问题. 在Hadoop 2.0版本中, HDFS的高可用得到改善, 官方提供了基于QJM/NFS共享存储和ZookeeperFailoverController的HA主备机制(Active NameNode和Standby NameNode), 还提供了用于横向扩展的NameNode Federatoin联邦机制, Second NameNode不再需要了 DataNode: 负责数据块的实际存储和读写工作, 并汇报存储信息给NameNode Block: 客户端向HDFS写入数据的时候, 会将数据拆分为固定大小的Block, Block 默认是64MB(HDFS2.0改成了128MB), 根据NameNode返回的DataNode列表, 客户端选择一个DataNode并向其发送写入请求, Block写入完成后会被后续DataNode流式转发实现多副本存储, 实现数据的高可用, 默认的副本数是3 架构特性 集群架构
NameNode元数据高可用
HDFS文件系统的元数据保存在NameNode中, 这些元数据包括:
目录树结构 文件到数据库 Block 的映射关系 Block 副本及其存储位置等管理数据 DataNode 的状态监控, 两者通过段时间间隔的心跳来传递管理信息和数据信息, 通过这种方式的信息传递, NameNode 可以获知每个 DataNode 保存的 Block 信息、DataNode 的健康状况、命令 DataNode 启动停止等(如果发现某个 DataNode 节点故障, NameNode 会将其负责的 block 在其他 DataNode 上进行备份) 这些信息全量存在于内存中, 除此之外, NameNode还会在磁盘中持久化保存两个文件:
fsimage: 内存命名空间元数据在磁盘上的镜像文件, 即元数据快照 editlog: 各种元数据操作的 write-ahead-log 预写日志文件. 在操作体现到内存数据变化前首先会将操作记入 editlog 中, 以防止数据丢失 这两个文件相结合就可以构造出完整的内存元数据内容
NameNode启动时会合并这两个文件将HDFS元数据写入内存中, NameNode运行过程中会不断向editlog中追加元数据操作记录, 只有在NameNode重启时, editlog才会合并到fsimage文件中, 从而得到一个最新的元数据快照. 但由于NameNode通常是很少重启的, 因此editlog文件会变得很大, 对该文件的管理成为问题, 此外editlog中的操作记录太多会导致NameNode重启后需要花费很长时间完成fsimage文件的合并.
为了解决fsimage和editlog合并的问题, Hadoop 1.0版本中引入了Second NameNode, 它会定期查询NameNode上的editlog, 将editlog中的改动合并到本地的fsimage中, 形成新的元数据快照, 然后将新的fsimage推送到NameNode中, NameNode收到新的fsimage后更新本地fsimage文件并重置editlog文件
但NameNode依然存在单点故障问题. 一方面如果 NameNode 宕机, 数据读写都会受到影响, HDFS 整体将变得不可用. 另一方面随着集群规模的扩大, 会导致整个集群管理的文件数目达到上限, 因为 NameNode 要管理整个集群 block 元信息、数据目录信息等. 为了解决这两个问题, Hadoop 2.0版本提供了一套统一的解决方案:
NameNode High Availability: NameNode主备高可用, 解决单点问题 NameNode Federation: NameNode联邦集群, 解决横向扩展问题 NameNode High Availability
Hadoop2.0的HA机制有两个NameNode, 一个是Active状态, 另一个是Standby状态. 两者的状态可以切换, 但同时最多只有1个是Active状态. 只有Active Namenode提供对外的服务. Active NameNode和Standby NameNode之间通过NFS或者QJM(JournalNode)来同步数据
Active NameNode会把最近的操作记录写到本地的editlog文件中, 并传输到NFS或者QJM JN中. Standby NameNode定期的检查, 从NFS或者JN把最近的editlog文件读过来, 然后把editlog文件和fsimage文件合并成一个新的fsimage, 合并完成之后会通知Active NameNode获取这个新fsimage. Active NameNode获得这个新的fsimage文件之后, 替换原来旧的fsimage文件并重置本地的editlog文件
Active NameNode和Standby NameNode之间通过Zookeeper集群和独立运行于NameNode节点上的ZookeeperFailoverController(ZKFC)进程实现故障自动切换. ZKFC监听所负责的NameNode的状态并在Zookeeper集群注册选举信息(选举锁争抢), 当ZKFC获得或失去选举锁时, 会向所负责的NameNode发送Active或Standby命令实现NameNode的主从自动切换
这样, 保持了Active NameNode和Standby NameNode的数据实时同步, Standby NameNode可以随时切换成Active NameNode. 而且还保持了原来Hadoop1.0的SecondaryNameNode/CheckpointNode/BackupNode的功能: 合并editlog文件和fsimage文件, 使fsimage文件一直保持更新. 所以启动了hadoop2.0的HA机制之后, SecondaryNameNode/CheckpointNode/BackupNode就不需要了
NameNode Federation
Hadoop 2.0提供的联邦机制解决了命名空间和性能可扩展性差和隔离性差的问题, 其核心思想是将一个大的 namespace 划分多个子 namespace, 并且每个 namespace 分别由单独的 NameNode 负责, 这些 NameNode 之间互相独立, 互不影响, 不需要做任何协调工作(类似集群拆分, 分库架构), 集群的所有 DataNode 会被多个 NameNode 共享
每个子 namespace 和 DataNode 之间会由数据块管理层作为中介建立映射关系, 数据块管理层由若干数据块池(Pool)构成, 每个数据块只会唯一属于某个固定的数据块池, 而一个子 namespace 可以对应多个数据块池. 每个 DataNode 需要向集群中所有的 NameNode 注册, 且周期性地向所有 NameNode 发送心跳和块报告, 并执行来自所有 NameNode 的命令
一个 block pool 由属于同一个 namespace 的数据块组成, 每个 DataNode 可能会存储集群中所有 block pool 的数据块 每个 block pool 内部自治, 也就是说各自管理各自的 block, 不会与其他 block pool 交流, 如果一个 NameNode 挂掉了, 不会影响其他 NameNode 某个 NameNode 上的 namespace 和它对应的 block pool 一起被称为 namespace volume, 它是管理的基本单位. 当一个 NameNode/namespace 被删除后, 其所有 DataNode 上对应的 block pool 也会被删除, 当集群升级时, 每个 namespace volume 可以作为一个基本单元进行升级 磁盘平衡
DataNode 将数据块存储到本地文件系统目录中, 具体的目录可以通过配置 hdfs-site.xml 里面的 dfs.datanode.data.dir 参数. 在典型的安装配置中, 一般都会配置多个目录, 并且把这些目录分别配置到不同的设备上, 比如分别配置到不同的HDD(HDD的全称是Hard Disk Drive)和SSD(全称Solid State Drives, 即固态硬盘)上
当往HDFS上写入新的数据块时, DataNode 将会使用volume选择策略来为这个块选择存储的位置. 目前Hadoop支持两种volume选择策略: round-robin 和 available space(详情参见: HDFS-1804), 我们可以通过 dfs.datanode.fsdataset.volume.choosing.policy 参数来设置. 循环(round-robin)策略将新块均匀分布在可用磁盘上, 而可用空间( available-space )策略优先将数据写入具有最大可用空间的磁盘(按百分比计算)
默认情况下, DataNode 是使用基于round-robin策略来写入新数据块. 然而在一个长时间运行的集群中, 由于大规模文件删除或者通过往 DataNode 中添加新的磁盘会导致不同磁盘存储的数据很不均衡. 即使你使用的是基于可用空间的策略, 卷(volume)不平衡仍可导致较低效率的磁盘I/O. 比如所有新增的数据块都会往新增的磁盘上写, 在此期间, 其他的磁盘会处于空闲状态, 这样新的磁盘将会是整个系统的瓶颈
DiskBalancer是一个命令行工具, 可以在DataNode的所有磁盘上均匀分配数据. 此工具与Balancer不同, 后者负责集群范围的数据平衡. 由于多种原因, 数据在节点上的磁盘之间可能存在不均匀的扩散. 这可能是由于大量写入和删除或由于磁盘更换造成的. 此工具针对给定的DataNode运行, 并将块从一个磁盘移动到另一个磁盘
读写请求
客户端向HDFS发起数据读写请求时, 都需要首先访问NameNode获取相应的DataNode列表, 然后直接请求DataNode以进行实际的数据读写. 由于HDFS中所有文件的元数据信息都存在于NameNode中, 因此不存在读写不一致的问题
数据写入
客户端通过调用创建新文件的DistributedFileSystem对象的create()方法来启动写操作 DistributedFileSystem对象使用RPC调用连接到NameNode并启动新文件创建. 此文件创建操作不会将任何块与该文件关联. NameNode负责验证文件(正在创建)尚不存在, 并且客户端具有创建新文件的正确权限. 如果文件已经存在或客户端没有足够的权限来创建新文件, 则向客户端抛出IOException异常. 否则操作将成功, 并且NameNode将创建该文件的新记录 NameNode创建文件新记录后, 将向客户端返回FSDataOutputStream类型的对象. 客户端通过它调用数据写入方法将数据写入HDFS FSDataOutputStream包含DFSOutputStream对象, 该对象负责与DataNodes和NameNode的通信. 在客户端继续写入数据的同时, DFSOutputStream继续使用此数据创建数据包. 这些数据包入队到称为DataQueue的队列中 名为DataStreamer的组件使用此DataQueue, DataStreamer还要求NameNode分配新块, 从而选择要用于复制的所需DataNode DataStreamer创建由所有需要写入该块数据的DataNode组成的Pipeline(DataNode数量取决于Block设置的副本数), 开始进行数据写入 DataStreamer将数据包写入管道中的第一个DataNode中 管道中的每个DataNode都存储它接收到的数据包, 并将其转发到管道中的第二个DataNode DFSOutputStream维护另一个队列Ack Queue, 以存储正在等待来自DataNode的确认的数据包 一旦从管道中的所有DataNode接收到队列中数据包的确认, 便将其从Ack Queue中删除. 如果任何DataNode发生故障, 则使用来自此队列的数据包来重新启动该操作 客户端完成写入数据后, 它将调用close()方法. 对close()的调用导致将剩余的数据包刷新到管道中, 然后等待确认 客户端收到最终确认后, 将与NameNode联系, 以告知其文件写入操作已完成 数据读取
客户端通过调用 FileSystem对象的open()方法来启动读取请求 , 它是DistributedFileSystem类型的对象 该对象使用RPC连接到NameNode并获取文件块位置等元数据信息 NameNode响应该元数据请求, 向客户端返回具有该块的副本的数据节点的地址 客户端接收到DataNodes的地址后, 会将FSDataInputStream类型的对象返回给客户端. FSDataInputStream包含 DFSInputStream, 它负责与DataNode和NameNode的交互. 客户端调用read()方法,实现DFSInputStream与文件的第一个块的第一个DataNode建立连接 数据以流的形式读取, 客户端反复调用read()方法. 重复此读操作直到它到达块的末尾, 完成块的读取 一旦完成一个块的读取, DFSInputStream将关闭连接并继续查找下一个块的下一个DataNode, 再次对数据进行流式读取 客户端完成读取后, 将调用close()方法关闭连接 应用场景
海量数据存储、大文件存储、流式文件访问、大数据批处理
配置文件 $HADOOP_HOME/etc/hadoop/hdfs-site.xml: hadoop中hdfs配置文件. default
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 &lt;configuration> &lt;property> &lt;name>dfs.namenode.datanode.registration.ip-hostname-check&lt;/name> &lt;value>false&lt;/value> &lt;description>datanode地址是主机名并可成功进行dns解析&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.webhdfs.enabled&lt;/name> &lt;value>true&lt;/value> &lt;description>启用webhdfs通过http restful api读写hdfs&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.permissions.enabled&lt;/name> &lt;value>false&lt;/value> &lt;description>是否启用权限控制&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.namenode.name.dir&lt;/name> &lt;value>file:///hadoop/dfs/name&lt;/value> &lt;description>namenode元数据存储路径&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.datanode.data.dir&lt;/name> &lt;value>file:///hadoop/dfs/data&lt;/value> &lt;description>datanode数据存储路径&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.namenode.rpc-bind-host&lt;/name> &lt;value>0.0.0.0&lt;/value> &lt;description>namenode rpc通信绑定地址&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.namenode.http-bind-host&lt;/name> &lt;value>0.0.0.0&lt;/value> &lt;description>namenode http服务绑定地址&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.namenode.https-bind-host&lt;/name> &lt;value>0.0.0.0&lt;/value> &lt;description>namenode https服务绑定地址&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.client.use.datanode.hostname&lt;/name> &lt;value>true&lt;/value> &lt;description>客户端使用datanode主机名进行请求&lt;/description> &lt;/property> &lt;property> &lt;name>dfs.datanode.use.datanode.hostname&lt;/name> &lt;value>true&lt;/value> &lt;description>datanode使用datanode主机名进行请求&lt;/description> &lt;/property> &lt;/configuration> 运维命令 节点启停
1 2 3 # 运行指定类型的节点 bin/hdfs &lt;nodetype> # 可选类型: namenode, secondarynamenode, journalnode, zkfc, datanode, dfsadmin, haadmin, fsck, balancer # 停止服务使用ps命令找到进程id后使用kill命令杀死 状态检查
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 命令帮助 bin/hadoop -usage # hdfs健康状态报告 bin/hadoop dfsadmin -report # namenode节点状态 bin/hadoop haadmin -getServiceState &lt;namenode> # 安全模式(只读) bin/hdfs dfsadmin -safemode get bin/hdfs dfsadmin -safemode enter bin/hdfs dfsadmin -safemode leave # 目录统计信息 bin/hdfs dfsadmin -metasave &lt;path> # 目录可用空间统计 bin/hadoop fs -df -h &lt;path> # 目录大小统计 bin/hadoop fs -du -s -h &lt;path> # 目录文件数量和大小统计 bin/hadoop fs -count &lt;path> 节点扩缩容
1 2 3 4 5 6 7 # 仅datanode # 扩容 ## 先复制已存在的datanode上的配置文件和包 sbin/hadoop-daemon.sh start datanode # 缩容 ## 先在namenode中将datanode加入dfs.hosts.exclude黑名单 bin/hadoop dfsadmin -refreshNodes 文件操作
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # bin/hadoop fs命令和bin/hdfs dfs命令多数情况下功能和参数相同 # bin/hdfs dfs命令只能进行hdfs文件系统相关操作 # 目录创建 bin/hadoop fs -mkdir &lt;path> # 如: /hdfs/data # 列出目录下的文件 bin/hadoop fs -ls -R &lt;path> # 文件上传 bin/hadoop fs -copyFromLocal &lt;localpath> &lt;path> bin/hadoop fs -put &lt;localpath> &lt;path> # 文件内容追加 bin/hadoop fs -appendToFile &lt;localpath> &lt;path> # 文件下载 bin/hadoop fs -copyToLocal &lt;localpath> &lt;path> bin/hadoop fs -get &lt;localpath> &lt;path> bin/hadoop fs -getmerge &lt;path>/log.* log.sum # 合并下载 # 文件在hdfs中复制/移动 bin/hadoop fs -cp &lt;path1> &lt;path2> bin/hadoop fs -mv &lt;path1> &lt;path2> # 文件/目录(递归)删除 bin/hadoop fs -rm -r &lt;path> # 文件内容查看 bin/hadoop fs -cat &lt;filepath> # 显示文件末尾 bin/hadoop fs -tail &lt;filepath> # 以字符形式打印文件内容 # 文件内容查看 bin/hadoop fs -text &lt;filepath> # 文件信息查看与健康状态检查 bin/hadoop fsck -files -blocks -locations &lt;filepath> 权限控制
1 2 3 # 启用权限控制功能dfs.namenode.acls.enabled: true bin/hdfs dfs -setfacl -m user:tom:rw- &lt;path> bin/hdfs dfs -setfacl -m group:team:r-- &lt;path> 快照管理
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 快照是只读的, 位置为&lt;path>/.snapshot/&lt;snapshotName> # 允许目录生成快照 bin/hdfs dfsadmin -allowSnapshot &lt;path> # 禁止目录生成快照 bin/hdfs dfsadmin -disallowSnapShot &lt;path> # 列出所有可快照的目录 bin/hdfs lsSnapshottableDir # 创建快照 bin/hdfs dfs -createSnapshot &lt;path> &lt;snapshotName> # 重命名快照 bin/hdfs dfs -renameSnapshot &lt;path> &lt;oldSnapshotName> &lt;newSnapshotName> # 删除快照 bin/hdfs dfs -deleteSnapshot &lt;path> &lt;snapshotName> # 对比快照 bin/hdfs snapshotDiff &lt;path> &lt;fromSnapshotName> &lt;toSnapshotName> 元数据查看
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 查看namenode列表 bin/hdfs getconf -namenodes # 查看secondary namenode列表 bin/hdfs getconf -secondaryNameNodes # 查看backupnode列表 bin/hdfs getconf -backupNodes # 查看journalnode列表 bin/hdfs getconf -journalNodes # 查看允许加入集群的datanode白名单 bin/hdfs getconf -includeFile # 查看不允许加入集群的datanode黑名单 bin/hdfs getconf -excludeFile # 查看namenode rpc地址 bin/hdfs getconf -nnRpcAddresses # 查看配置文件中指定的key bin/hdfs getconf -confKey &lt;key> 数据均衡分布
1 2 3 4 5 sbin/start-balancer.sh -threshold &lt;percentage of disk capacity> # percentage of disk capacity: # HDFS达到平衡状态的磁盘使用率偏差值 # 值越低各节点越平衡, 但消耗时间也更长 bin/hdfs dfsadmin -setBalancerBandwidth 67108864 目录配额设置
1 2 3 4 5 6 # 容量配额 bin/hadoop dfsadmin -setSpaceQuota 1t &lt;path> # 目录和文件数配额 bin/hadoop dfsadmin -setQuota 10000 &lt;path> # 清空配额 bin/hadoop dfsadmin -clrSpaceQuota &lt;path> 其他命令
1 2 3 4 5 6 7 8 9 # 检查本地安装的压缩库 bin/hadoop checknative # 格式化namenode bin/hdfs namenode bin/hadoop namenode -format # 查看hadoop fsimage文件 bin/hdfs oiv -i ./hadoop/dfs/name/current/fsimage_0000000000000000767 -o output.xml -p XML # 查看hadoop editlog文件 hdfs oev -i ./hadoop/dfs/name/current/edits_0000000000000001007-0000000000000001008 -o output.xml -p XML 常用API hdfs默认开启web api, 请求格式如:
1 curl -i "http://&lt;HOST>:&lt;PORT>/webhdfs/v1/&lt;PATH>?OP=..." 可选OP和其他参数参考官方文档
相关工具 文章推荐 官方文档 HDFS架构 HDFS Tutorial HDFS架构与运维 HDFS Disk Balancer 排障经验 MapReduce Hadoop生态大规模数据集分布式并行计算框架
基本概念 MapReduce: mapreduce上一种分而治之的编程模型, 包含map(映射)和 reduce(归约)过程. Hadoop基于此模型实现了一套分布式计算框架, 也称为MapReduce, 是Hadoop核心组件之一, 负责在 HDFS 上进行计算. MapReduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序, 并发运行在一个 hadoop 集群上 Map: 映射阶段负责将复杂的任务分解为若干简单的任务处理, 将输入的KV数据进行处理后产生新的KV数据. 多个Mapper可以启动新的maptask进程并行处理各自的map任务. map任务运行的节点会优先选择在所需数据所在的节点 Reduce: 归约阶段负责对map阶段的结果进行汇总, Map阶段并行计算输出的汇总前的KV数据经由Reducer汇总后产生新的KV数据, 多个Reducer可以启动新的reducetask进程并行执行, 但Reduce阶段必须在Map阶段完成之后进行. reduce任务需要先将所要处理的数据拉取到执行reduce任务的节点 Shuffle: 混排描述的上数据从Map端到Reduce端的过程, 每一个map任务的输出是独立和分散的, 因此必须有一个中间过程将所有map任务的输出整合为可供reduce任务使用的输入, 这个过程是横跨Map阶段和Reduce阶段的, 这个过程是由框架自行处理的 Task: 任务是Map阶段或Reduce阶段具体完成map处理逻辑或reduce处理逻辑的进程. 由于Task有可能执行失败, 或者Hadoop有推测执行的机制, 一个Task可能被执行多次, 每一次的执行就是一个task attempt Job: 作业是指一个完整的计算工作, 包含MapReduce的全流程内容, 由Map阶段和Reduce阶段的各个任务(Task)组成. 在Hadoop的YARN管理体系中, 作业就是其中的Application的概念, 也就是运行在集群中的完成整个计算工作的程序 架构特性 集群架构
MapReduce阶段工作
MapReduce整体分为Map阶段和Reduce阶段, 在这两个阶段中, 又分别包含对Map的输出处理和Reduce的输入处理, 这些处理称为Shuffle混排, Shuffle大致分为排序(sort)、溢写(spill)、合并(merge)、拉取拷贝(fetch copy)、合并排序(merge sort)几个过程, 其核心作用就是对key进行全局聚合
Map阶段
MapReduce中的每个map任务可以细分4个阶段: record reader、mapper、combiner和partitioner. map任务的输出被称为中间键和中间值, 会被发送到reducer做后续处理
record reader: record reader通过输入格式将输入split解析成记录. record reader的目的只是将输入数据解析成记录, 但不负责解析记录本身. 它将数据转化为键/值(key/value)对的形式, 并传递给mapper处理. 通常键是数据在文件中的位置, 值是组成记录的数据块 map: 在mapper中, 用户定义的map代码通过处理record reader解析的每个键/值对来产生0个或多个新的键/值对结果. 键/值的选择对MapReduce作业的完成效率来说非常重要. 键是数据在reducer中处理时被分组的依据, 值是reducer需要分析的数据 combiner: combiner是一个可选的本地reducer, 可以在map阶段聚合数据. combiner通过执行用户指定的来自mapper的中间键对map的中间结果做单个map范围内的聚合. 例如, 一个聚合的计数是每个部分计数的总和, 用户可以先将每个中间结果取和, 再将中间结果的和相加, 从而得到最终结果. 在很多情况下, 这样可以明显地减少通过网络传输的数据量. 通过combiner可以产生特别大的性能提升, 并且没有副作用, 因此combiner的应用非常广泛 partitioner: partitioner的作用是将mapper(如果使用了combiner的话就是combiner)输出的键/值对拆分为分片(shard), 每个reducer对应一个分片. 默认情况下, partitioner先计算目标的散列值(通常为md5值), 然后通过reducer个数执行取模运算key.hashCode()%(reducer的个数). 这种方式不仅能够随机地将整个键空间平均分发给每个reducer, 同时也能确保不同mapper产生的相同键能被分发至同一个reducer. 用户可以定制partitioner的默认行为, 并可以使用更高级的模式, 如排序. 当然, 一般情况下是不需要改写partitioner的. 对于每个map任务, 其分好区的数据最终会写入本地文件系统, 等待其各自的reducer拉取 Reduce阶段
MapReduce中的reduce任务可以分为3个阶段: shuffle、reduce和record write
map任务运行的节点会优先选择在数据所在的节点, 因此一般可以通过在本地机器上进行计算来减少数据的网络传输
shuffle: reduce任务开始于shuffle这一步骤(此shuffle仅指Reduce端的shuffle部分). 该步骤主要是将所有partitioner写入的输出文件拉取到运行reducer的本地机器上, 然后将这些数据按照键排序并写到一个较大的数据列表中. 排序的目的是将相同键的记录聚合在一起, 这样其所对应的值就可以很方便地在reduce任务中进行迭代处理. 这个过程完全不可定制, 而且是由框架自动处理的. 开发人员只能通过自定义Comparator对象来确定键如何排序和分组 reduce: reducer将已经分好组的数据作为输入, 并依次为每个键对应分组执行reduce函数. reduce函数的输入是键以及包含与该键对应的所有值的迭代器. 这些数据可以被聚合、过滤或以多种方式合并. 当reduce函数执行完毕后, 会将0个或多个键/值对发送到最后的处理步骤&ndash;输出格式. 和map函数一样, 因为reduce函数是业务处理逻辑的核心部分, 所以不同作业的reduce函数也是不相同的 record write: record write获取reduce函数输出的最终键/值对, 并通过输出格式将它写入到输出文件中. 每条记录的键和值默认通过tab分隔, 不同记录通过换行符分隔. 虽然一般情况下可以通过自定义实现非常多的输出格式, 但是不管什么格式, 最终的结果都将写到HDFS上 Shuffle各阶段
Map端sort(排序)
Map端的输出数据, 先写环形缓存区kvbuffer, 当环形缓冲区到达一个阀值(可以通过配置文件设置, 默认80), 便要开始溢写, 但溢写之前会有一个sort操作, 这个sort操作先把Kvbuffer中的数据按照partition值和key两个关键字来排序, 移动的只是索引数据, 排序结果是Kvmeta中数据按照partition为单位聚集在一起, 同一partition内的按照key有序
spill(溢写)
当排序完成, 便开始把数据刷到磁盘, 刷磁盘的过程以分区为单位. 一个分区写完, 写下一个分区, 分区内数据有序, 最终实际上会多次溢写, 然后生成多个文件
merge(合并)
spill会生成多个小文件, 对于Reduce端拉取数据是相当低效的, 那么这时候就有了merge的过程, 合并的过程也是同分片的合并成一个片段(segment), 最终所有的segment组装成一个最终文件, 那么合并过程就完成了
Reduce端fetch copy(拉取拷贝)
Reduce任务通过向各个Map任务拉取对应分片. 这个过程都是以Http协议完成, 每个Map节点都会启动一个常驻的HTTP server服务, Reduce节点会请求这个Http Server拉取数据, 这个过程完全通过网络传输, 所以是一个非常重量级的操作
merge sort(合并排序)
Reduce端拉取到各个Map节点对应分片的数据之后, 会进行再次排序, 排序完成, 结果丢给Reduce函数进行计算
MapReduce运行流程
了解MapReduce各阶段的工作细节后, 我们跳出细节看看MapReduce的整体运行流程
Map任务流程 读取HDFS中的文件. 每一行解析成一个&lt;k,v>, 每一个键值对调用一次map函数. &lt;0,hello you> &lt;10,hello me> 覆盖map(), 接收上一步产生的&lt;k,v>, 进行处理, 转换为新的&lt;k,v>输出. &lt;hello,1> &lt;you,1> &lt;hello,1> &lt;me,1> 对上一步输出的&lt;k,v>进行分区. 默认分为一个区 对不同分区中的数据按照k进行排序、分组. 分组指的是相同key的value放到一个集合中. 排序后: &lt;hello,1> &lt;hello,1> &lt;me,1> &lt;you,1>, 分组后: &lt;hello,{1,1}>&lt;me,{1}>&lt;you,{1}> (可选)对分组后的数据进行本地Reduce归约 Reduce任务处理 多个map任务的输出, 按照不同的分区, 通过网络copy到不同的reduce节点上 对多个map的输出进行合并、排序. 覆盖reduce函数, 接收的是分组后的数据, 实现自己的业务逻辑. &lt;hello,2> &lt;me,1> &lt;you,1>处理后, 产生新的&lt;k,v>输出 对reduce输出的&lt;k,v>写到HDFS中 MapReduce作业流程
MapReduce流程是整个Job(作业)流程中的核心内容, 此外作业还包括诸如作业提交, 作业调度等其他流程
作业提交 client 调用 job.waitForCompletion 方法, 向整个集群提交 MapReduce 作业 client 向 ResourceManager 申请一个作业 ID (jobid) ResourceManager 给 client 返回该 job 资源的提交路径和作业 id client 提交 jar 包、切片信息和配置文件到指定的资源提交路径 client 提交完资源后, 向 ResourceManager 申请运行 MrAppMaster 作业初始化 当 ResourceManager 收到 client 申请请求后, 将该 job 添加到容量调度器中 某一个空闲的 NodeManager 领取到该 job 该 NodeManager 创建 Container, 并产生 MRAppmaster MRAppmaster下载 client 提交的资源到本地 任务分配 MrAppMaster 向 ResourceManager 申请运行多个 maptask 任务的资源 ResourceManager 将运行 maptask 的任务分配给另外的一个或多个 NodeManager, 这些 NodeManager 分别领取任务并创建容器 任务运行 MrAppMaster 向接收到任务的各个 NodeManager 发送程序启动脚本, 这些NodeManager 分别通过YarnChild程序启动 maptask, maptask 对数据分区排序 MrAppMaster 等待 maptask 运行完毕后, 向 ResourceManager 申请容器, 运行 reducetask, reducetask同样像maptask一样被分配到NodeManager并由其YarnChild程序启动运行 reduce task 向 maptask 获取相应分区的数据, 将数据拷贝到本地后执行reduce任务 程序运行完毕, Job完成后, MrAppMaster 会向 ResourceManager 申请注销自己 maptask的请求优先于reducetask, 且在maptask完成5%之前, 不会创建reducetask的请求. 注意reducetask并不需要等待job内的所有maptask都运行完成才启动, 每个reducetask都只需要等待其所分配的分片相关的maptask执行完成即可
Task运行过程中会将其进度和状态返回给MrAppMaster, 对于maptask, 进度就是其处理的输入百分比, 对于reducetask, 就需要估算. client通过定期查询MrAppMaster可以获取进度更新
Client除了向MrAppMaster请求任务进度外, 也会周期性检查作业是否完成. 作
业完成之后, MrAppMaster和 container 会清理工作状态. 作业的信息会被JobHistory存储
以备之后用户核查
失效问题
task失效
最常见的失效情况是task代码里抛出了运行时异常, 执行task的jvm在其退出之前向application master报告错误, application master会标记该task是失败状态, 释放对应的容器, 该容器所占用的资源会被其他task所利用
类似jvm突然停止工作的异常, node manager会通知application master执行task的jvm进程退出了, task也将被application master置为失败状态
对于挂起状态的task通过超时来处理, application master在很久没有收到task的进度更新后, 会将其置为失效, 超时时间可以设置. 当然也可以设置为永不超时
application master将重新调度失败的task, 重新调度将避免选择先前失效时所在的node manager. 默认情况下, 一个task失败达到4次, 该task不再尝试执行, job也将失败. 对于一些不希望task失败就直接导致job失败的应用来说, 需要设置一个参数来控制task失效在某百分比以内时不会触发job失败
task可能会被杀死, 这种状况有别于失败, 例如node manager在失效状态下, 运行其中的所有task都将被杀死, 当然用户也可以自己通过工具将其杀死, 被杀死的task, 不计入尝试次数范围
application master失效
MapReduce application master的默认失败尝试次数是2, 所以达到2次时就认为job失败, 也可以自行设置. Yarn框架也提供了application master的最大尝试次数, 同时默认也是2
application master定期向resource manager发送心跳, resource manager一旦检测到application master失败, 就会在一个新的容器中启动新的application master实例. 在这种状况下, MapReduce application master使用job的执行历史来恢复task的运行状态, 已经运行的不会再重新运行
MapReduce客户端会不断从application master那里获取job的进度, application master失效后, 客户端将自动重新定位到新的application master
node manager失效
node manager定期向resource manager发送心跳, 默认超时为10分钟. 一旦失效, 将被移出节点池. 任何运行于失效node manager所在机器上的task或application master都将得到恢复
如果一个应用在某node manager 上发生失败过多, 该node manager将被application master加入黑名单(资源管理器并不跨应用维护黑名单, 所以新job的task可能会运行于一个被某application master列入黑名单的节点), 即使其本身并没有失效. 如果超过三个task失败, MapReduce application master将在不同的节点上重新调度task
resource manager失效
resource manager一旦失效, job以及task容器无法启动, 是一件很严重的故障, 所以很有必要做HA. 应用的信息被存储在HA的状态存储中(ZooKeeper或HDFS)
新的resource manager启动时, 从状态存储中读取应用的信息, 重启application master
客户端和node manager必须处理resource manager失效问题, 因为可能和两个resource manager交互
配置文件 $HADOOP_HOME/etc/hadoop/mapred-site.xml: hadoop中mapreduce配置文件. default
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 &lt;configuration> &lt;property> &lt;name>mapreduce.map.java.opts&lt;/name> &lt;value>-Xmx3072m&lt;/value> &lt;description>map任务的jvm最大堆内存&lt;/description> &lt;/property> &lt;property> &lt;name>mapreduce.reduce.java.opts&lt;/name> &lt;value>-Xmx6144m&lt;/value> &lt;description>reduce任务的jvm最大堆内存&lt;/description> &lt;/property> &lt;property> &lt;name>mapreduce.reduce.memory.mb&lt;/name> &lt;value>8192&lt;/value> &lt;description>每个reduce任务可申请的内存总量&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.app.mapreduce.am.env&lt;/name> &lt;value>HADOOP_MAPRED_HOME=/home/xshrim/bigdata/hadoop&lt;/value> &lt;description>传递给MrAppMaster的额外环境变量&lt;/description> &lt;/property> &lt;property> &lt;name>mapreduce.map.memory.mb&lt;/name> &lt;value>4096&lt;/value> &lt;description>每个map任务可申请的内存总量&lt;/description> &lt;/property> &lt;property> &lt;name>mapred.child.java.opts&lt;/name> &lt;value>-Xmx4096m&lt;/value> &lt;description>yarnChild的jvm最大堆内存&lt;/description> &lt;/property> &lt;property> &lt;name>mapreduce.reduce.env&lt;/name> &lt;value>HADOOP_MAPRED_HOME=/home/xshrim/bigdata/hadoop&lt;/value> &lt;description>传递给reduce任务的额外环境变量&lt;/description> &lt;/property> &lt;property> &lt;name>mapreduce.framework.name&lt;/name> &lt;value>yarn&lt;/value> &lt;description>执行mapreduce job运行时框架(local/classic/yarn)&lt;/description> &lt;/property> &lt;property> &lt;name>mapreduce.map.env&lt;/name> &lt;value>HADOOP_MAPRED_HOME=/home/xshrim/bigdata/hadoop&lt;/value> &lt;description>传递给map任务的额外环境变量&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.bind-host&lt;/name> &lt;value>0.0.0.0&lt;/value> &lt;description>nodemanager绑定的地址&lt;/description> &lt;/property> &lt;/configuration> 运维命令 执行mapreduce job
1 2 3 4 5 bin/hadoop jar &lt;jar-path> &lt;jar-args> &lt;raw-path> &lt;out-path> # jar-path: 本地jar包路径 # jar-args: main函数所在类名 # raw-path: 原始输入数据的hdfs路径 # out-path: 输出数据的hdfs路径 Job管理
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 列出所有job bin/hadoop job -list # 杀死job bin/hadoop job -kill &lt;jobid> # 查看指定路径下的job日志 bin/hadoop job -history &lt;path> # job的详细信息 bin/hadoop job -history all &lt;path> # 打印map和reduce完成百分比和计数器 bin/hadoop job -status &lt;jobid> # 杀死任务(被杀死的任务不会重试) bin/hadoop job -kill-task &lt;taskid> # 使任务失败(被失败的任务不会重试) bin/hadoop job -fail-task &lt;taskid> 常用API 相关工具 文章推荐 官方文档 MapReduce Tutorial 剖析hadoop和Spark的Shuffle过程差异 MapReduce Sample 排障经验 YARN Hadoop生态大数据资源调度管理器
基本概念 Container: 容器是Yarn对主机资源的抽象, CPU, 内存, 磁盘和网络等计算资源被封装成容器供作业任务使用, 容器不能跨主机, 一个主机上的资源可以抽象出多个容器, 容器之间是隔离的, 由NodeManager启动和管理并由ResourceManager动态调度生成和删除. Yarn中的容器与流行的Docker 容器类似, 但Docker 容器的隔离性更好一些. Yarn支持自定义容器执行器以使用Docker 创建Container Application: Yarn中的Application就是MapReduce中的Job(作业), 是运行在集群中的完成一整个计算工作的程序. 在Hadoop中Application和Job的ID是一致的 ResourceManager: 资源管理器(简称RM)是Yarn的三大核心组件之一, 负责计算资源的全局调度分配和管理. ResourceManager由Scheduler(调度器)和ApplicationManager(应用管理器, 简称ASM)组成, 前者负责根据节点容量, 队列情况等为Application分配资源, 后者接受用户提交的请求, 在节点中启动ApplicationMaster, 并监控ApplicationMaster的状态, 进行必要的重启和清除 ApplicationMaster: 应用主控器(简称AM)是Yarn的三个核心组件之一, 负责处理Application的执行调度, 也就是MapReduce中的MrAppMaster. ApplicationMaster是动态创建和销毁的, 且仅服务于一个具体的Application. 每当 Client 提交一个 Application 时候, 就会由ApplicationManager新建一个 ApplicationMaster , 由这个 ApplicationMaster 根据Application任务去与 ResourceManager 申请各个任务的容器资源, 获得资源后会将要运行的程序发送到容器上启动, 然后进行分布式计算, 同时监控任务的执行情况. Application执行完成后, ApplicationMaster会向ApplicationManager请求自销毁 NodeManager: 节点管理器(简称NM)是Yarn的三个核心组件之一, Hadoop集群中的每个DataNode上都会运行一个NodeManager, 作为代理监控节点的资源使用情况并向ResourceManager上报节点和节点上的容器信息, 同时负责响应ApplicationMaster的请求执行容器的启停 Timeline Server: 时间线服务器是Yarn的可选组件, 在Yarn中通过Timeline Server用一种通用的形式解决对application的当前和历史信息的存储和检索 架构特性 集群架构
工作流程
客户端向ResourceManager提交Application ResourceManager的ApplicationManager组件指示NodeManager(运行在每一个工作节点的其中一个)为应用程序启动一个新的ApplicationMaster容器 ApplicationMaster首先向ResourceManager注册, 这样用户可以直接通过NodeManager查看应用程序的运行状态 ApplicationMaster计算应用完成所需要的资源, 然后向ResourceManager申请需要的资源(容器). ApplicationMaster在应用程序的整个生命周期内与ResourceManager保持联系, 确保其所需要资源的列表被ResourceManager严格遵守, 并且发送一些必要的Kill请求杀死任务 申请到资源后, ApplicationMaster指示NodeManager在对应的节点上创建容器 NodeManager创建容器, 设置好运行环境, 然后启动容器 各个容器定时向ApplicationMaster发送任务的运行状态和进度, 这样ApplicationMaster随时掌握各个任务的运行状态, 从而可以在任务失败时重新启动任务 应用程序完成后, ApplicationMaster会通知ResourceManager该作业已经完成并注销关闭自己 容器运行是NodeManager执行的, 容器调度则是由ResourceManager的Scheduler组件完成的, 它决定容器在哪个节点上运行
NodeManager会将节点状态和健康状况发送到ResourceManager, ResourceManager拥有全局资源视图才能分配资源
时间线服务器
在hadoop2.4版本之前对任务执行的监控只开发了针对MapReduce的 Job History Server, 它可以提供给用户用户查询已经运行完成的作业的信息, 但是随着在YARN上面集成的越来越多的计算框架, 比如spark、Tez, 也有必要为基于这些计算引擎的技术开发相应的作业任务监控工具, 所以hadoop的开发人员就考虑开发一款更加通用的Job History Server. 即YARN Timeline Server
职责
持久化Applicatoin的具体信息
收集并检索Applicatoin或者框架的具体信息. 例如, hadoop MapReduce框架里面的与分片相关的信息, 诸如map tasks、reduce tasks、counters等. Applicatoin开发者可以在App Master端或者Applicatoin的containers中通过TimelineClient将这些信息发送给Timeline Server. 这些信息都可以通过REST API在具体App或者执行框架的UI界面查询到
持久化已完成的应用程序的Generic information
关于这一点, 在Application history server中, 显然只支持MapReduce框架的job. Generic information包括了像queue-name, 用户信息等用户程序级别的数据, 还有设置在 ApplicationSubmissionContext中的信息, 用于运行应用程序的application-attempts 列表, 关于每个application-attempt的信息, container列表以及运行在每个 application-attempt 下的每个container的信息
结构
Timeline Domain
Timeline Domain首先存储属主信息, 读写的ACL信息, 创建和修改时间戳. 每个Domain通过ID标识, ID必须是在YARN 集群全局唯一的
Timeline Domain为Timeline server提供了一个命名空间, 允许用户管理多个Entities, 将它们与其他用户和application隔离开来. Timeline server 安全机制定义在这一层级
Timeline Entity
Timeline Entity 包含了概念实体和它的相关event的元信息. Entity可以是一个application、application attempt、容器或者任意用户自定义的对象. 它包含 Primary filters, 用于索引timeline Store中的entities. 因此, 用户/application 应该谨慎选择他们想要存储为primary filters的信息. 其他的数据可以存储为非索引信息. 每个Entity通过EntityId和EntityType作为唯一标识
Timeline Events
Timeline Event描述了一个application相关的特定Timeline Entity的事件. 用户可以自由定义一个event的含义, 比如启动一个application, 获得一个容器分配, 操作失败或者其他用户和集群操作相关的信息
批处理和流处理
批处理
批处理在大数据世界有着悠久的历史. 批处理主要操作大容量静态数据集, 并在计算过程完成后返回结果
批处理模式中使用的数据集通常符合下列特征:
有界: 批处理数据集代表数据的有限集合 持久: 数据通常始终存储在某种类型的持久存储位置中 大量: 批处理操作通常是处理极为海量数据集的唯一方法 批处理非常适合需要访问全套记录才能完成的计算工作. 例如在计算总数和平均数时, 必须将数据集作为一个整体加以处理, 而不能将其视作多条记录的集合. 这些操作要求在计算进行过程中数据维持自己的状态 需要处理大量数据的任务通常最适合用批处理操作进行处理. 无论直接从持久存储设备处理数据集, 或首先将数据集载入内存, 批处理系统在设计过程中就充分考虑了数据的量, 可提供充足的处理资源. 由于批处理在应对大量持久数据方面的表现极为出色, 因此经常被用于对历史数据进行分析 大量数据的处理需要付出大量时间, 因此批处理不适合对处理时间要求较高的场合
流处理
流处理系统会对随时进入系统的数据进行计算. 相比批处理模式, 这是一种截然不同的处理方式. 流处理方式无需针对整个数据集执行操作, 而是对通过系统传输的每个数据项执行操作.
流处理中的数据集是"&ldquo;无边界"&ldquo;的, 这就产生了几个重要的影响:
完整数据集只能代表截至目前已经进入到系统中的数据总量 工作数据集也许更相关, 在特定时间只能代表某个单一数据项 处理工作是基于事件的, 除非明确停止否则没有"尽头&rdquo;. 处理结果立刻可用, 并会随着新数据的抵达继续更新 流处理系统可以处理几乎无限量的数据, 但同一时间只能处理一条(真正的流处理)或很少量(微批处理, Micro-batch Processing)数据, 不同记录间只维持最少量的状态. 虽然大部分系统提供了用于维持某些状态的方法, 但流处理主要针对副作用更少, 更加功能性的处理(Functional processing)进行优化 功能性操作主要侧重于状态或副作用有限的离散步骤. 针对同一个数据执行同一个操作会或略其他因素产生相同的结果, 此类处理非常适合流处理, 因为不同项的状态通常是某些困难、限制, 以及某些情况下不需要的结果的结合体. 因此虽然某些类型的状态管理通常是可行的, 但这些框架通常在不具备状态管理机制时更简单也更高效
此类处理非常适合某些类型的工作负载. 有近实时处理需求的任务很适合使用流处理模式. 分析、服务器或应用程序错误日志, 以及其他基于时间的衡量指标是最适合的类型, 因为对这些领域的数据变化做出响应对于业务职能来说是极为关键的. 流处理很适合用来处理必须对变动或峰值做出响应, 并且关注一段时间内变化趋势的数据
计算框架
鉴于这两种数据特性和处理方式的不同, 出现了一系列针对某种特定数据处理的计算框架, 这些框架主要包括:
MapReduce: 仅批处理
MapReduce是Hadoop内置的计算框架. MapReduce将计算过程分为Map和Reduce, 每个任务需要多次执行读取和写入操作, 磁盘开销大, 依赖持久存储, 速度相对较慢, 但是MapReduce可以处理海量的数据集, 且依赖的硬件可以非常廉价, 具备极高的缩放潜力, 适合处理对时间要求不高的非常大规模数据集
Storm: 仅流处理
Apache Storm是一种侧重于极低延迟的流处理框架. Storm的流处理可对框架中名为Topology(拓扑)的DAG(Directed Acyclic Graph, 有向无环图)进行编排. 这些拓扑描述了当数据片段进入系统后, 需要对每个传入的片段执行的不同转换或步骤. Storm可以用极低延迟处理数据, 可用于希望获得最低延迟的工作负载, 与Trident配合可以支持微量批处理
Samza: 仅流处理
Apache Samza是一种与Apache Kafka消息系统紧密绑定的流处理框架. Samza可以更好地发挥Kafka独特的架构优势和保障, 提供容错、缓冲以及状态存储. Samza与Kafka之间紧密的关系使得处理步骤本身可以非常松散地耦合在一起. 无需事先协调, 即可在输出的任何步骤中增加任意数量的订阅者, 直接写入Kafka还可避免回压(Backpressure)问题, 还可以使用以本地键值存储方式实现的容错检查点系统存储数据. Samza本身很适合有多个团队需要使用(但相互之间并不一定紧密协调)不同处理阶段的多个数据流的组织. Samza可大幅简化很多流处理工作, 可实现低延迟的性能. 如果部署需求与当前系统不兼容, 也许并不适合使用, 但如果需要极低延迟的处理, 或对严格的一次处理语义有较高需求, 此时依然适合考虑
Spark: 批处理和流处理
Apache Spark是一种包含流处理能力的下一代批处理框架. 与Hadoop的MapReduce引擎基于各种相同原则开发而来的Spark主要侧重于通过完善的内存计算和处理优化机制加快批处理工作负载的运行速度. Spark可作为独立集群部署(需要相应存储层的配合), 或可与Hadoop集成并取代MapReduce引擎. 与MapReduce不同, Spark的数据处理工作全部在内存中进行, 只在一开始将数据读入内存, 以及将最终结果持久存储时需要与存储层交互, 所有中间态的处理结果均存储在内存中. 除了在内存中处理方式可大幅改善性能, Spark因为通过提前对整个任务集进行分析可以实现更完善的整体式优化, 在处理与磁盘有关的任务时速度也有很大提升. Spark本身在设计上主要面向批处理工作负载. 为了实现内存中批计算, Spark会使用一种名为Resilient Distributed Dataset(弹性分布式数据集), 即RDD的模型来处理数据. 而流处理能力是由Spark Streaming实现的, 该技术引入微批(Micro-batch)的概念, 将数据流视作一系列非常小的"批&rdquo;, 借此即可通过批处理引擎的原生语义进行处理, Spark Streaming会以亚秒级增量对流进行缓冲, 随后这些缓冲会作为小规模的固定数据集进行批处理. 这种方式的实际效果非常好, 但相比真正的流处理框架在性能方面依然存在不足. Spark相比MapReduce拥有更快的速度, 且架构多样化, 可同时支持批处理和流处理, 拥有丰富的生态系统, 任务编写也比MapReduce简单, 其缺点是流处理的缓冲机制不适合对延迟要求较高的工作负载, 且由于大量使用内存成本更高. Spark是多样化工作负载处理任务的最佳选择. Spark批处理能力以更高内存占用为代价提供了无与伦比的速度优势. 对于重视吞吐率而非延迟的工作负载, 则比较适合使用Spark Streaming作为流处理解决方案
Flink: 批处理和流处理
Apache Flink是一种新兴的可以处理批处理任务的流处理框架. Flink可将批处理数据视作具备有限边界的数据流, 借此将批处理任务作为流处理的子集加以处理. 为所有处理任务采取流处理为先的方法会产生一系列有趣的副作用. 这种流处理为先的方法也叫做Kappa架构, 与之相对的是更加被广为人知的Lambda架构(该架构中使用批处理作为主要处理方法, 使用流作为补充并提供早期未经提炼的结果). Kappa架构中会对一切进行流处理, 借此对模型进行简化, 而这一切是在最近流处理引擎逐渐成熟后才可行的. Flink的流处理模型在处理传入数据时会将每一项视作真正的数据流. Flink提供的DataStream API可用于处理无尽的数据流. 为了在计算过程中遇到问题后能够恢复, 流处理任务会在预定时间点创建快照. 为了实现状态存储, Flink可配合多种状态后端系统使用, 具体取决于所需实现的复杂度和持久性级别. Flink的批处理模型在很大程度上仅仅是对流处理模型的扩展. 此时模型不再从持续流中读取数据, 而是从持久存储中以流的形式读取有边界的数据集, Flink会对这些处理模型使用完全相同的运行时, 但可以对批处理工作负载实现一定的优化. Flink目前是处理框架领域一个独特的技术, 虽然Spark也可以执行批处理和流处理, 但Spark的流处理采取的微批架构使其无法适用于很多用例. Flink流处理为先的方法可提供低延迟, 高吞吐率, 近乎逐项处理的能力. Flink的很多组件是自行管理的, 可自行管理内存, 自行处理数据分区和自动缓存, 待处理数据的特征发生变化后无需手工优化和调整. Flink提供了基于Web的调度视图, 借此可轻松管理任务并查看系统状态, 能很好地与其他组件配合使用. Flink最大的局限之一在于这依然是一个非常"年幼"的项目. 现实环境中该项目的大规模部署尚不如其他处理框架那么常见, 对于Flink在缩放能力方面的局限目前也没有较为深入的研究. 随着快速开发周期的推进和兼容包等功能的完善, 当越来越多的组织开始尝试时, 可能会出现越来越多的Flink部署. Flink提供了低延迟流处理, 同时可支持传统的批处理任务. Flink也许最适合有极高流处理需求, 并有少量批处理任务的组织. 该技术可兼容原生Storm和Hadoop程序, 可在YARN管理的集群上运行, 因此可以很方便地进行评估. 快速进展的开发工作使其值得被大家关注
插件化支持
调度器
Yarn默认的调度器存在当大量的job提交、用尽所有计算资源后, 新的job要等待很久才能被处理, 即便新的job是非常重要的任务, 也只能等待的问题. 可以通过scheduler plugin(例如: FIFO Scheduler、Fair Scheduler、Capacity Scheduler)的方式, 配置不同的资源调度规则, 来尽量缓解该问题, 让重要的job可以优先获得资源调配
计算框架
Yarn是一种支持多种计算框架的资源统一管理和调度的全局资源管理器. 支持MapReduce, Tez, Storm, Samza, Spark, Flink等全部流行的计算框架
容器执行器
在 Yarn 的架构中, 将集群中的计算资源(主要是内存和 CPU)封装抽象出了 Container 的概念, 类似于 container_001 &lt;memory:2048, vCores:1>. Container 由 ResourceManager 负责调度与分配, 由资源所在的 NodeManager 负责启动与管理
Container 所封装的计算资源是由集群中的 NodeManager 提供的, 所以 Container 的启动、运行、监控和管理也需要对应的 NodeManager 来执行. ContainerExecutor 正是 NodeManager 用来启动与管理 Container 的工具
Yarn 3.0 版本中, 在 Linux 系统环境下, ContainerExecutor 有两种实现:
DefaultContainerExecutor: 简称 DCE ,, 如其名, 是默认的 ContainerExecutor 实现. 如果用户未指定 ContainerExecutor 的具体实现, NM 就会使用它. DCE 直接使用 bash 来启动 container 进程, 所有 container 都使用 NM 进程用户 (yarn) 启动
LinuxContainerExecutor: 简称 LCE, 相比于 DCE , 它能提供更多有用的功能, 如用户权限隔离, 支持使用提交任务用户来启动 container, 支持使用 cgroup 进行资源限制, 支持运行 docker container (合并了 2.x 版本中的 DockerContainerExecutor). LCE 使用可执行的二进制文件 container-executor 来启动 container 进程, container 的用户根据配置可以统一使用默认用户, 也可以使用提交任务的用户(需要提前在 NM 上添加所有支持的用户)
LCE 是安全的 ContainerExecutor. 在默认的情况下, 如果我们的集群是 non-secure , 而且没有什么特殊需求时, 使用 DCE 就足够了, 因为 DCE 配置和使用都很简单. 但是当我们的集群要求安全性, 比如开启了 kerberos 验证, 我们就必须使用 LCE, 使用 DCE 的话 MapReduce 任务会在 reduce shuffle 阶段失败退出
配置文件 $HADOOP_HOME/etc/hadoop/yarn-site.xml: hadoop中core配置文件. default
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 &lt;configuration> &lt;property> &lt;name>yarn.timeline-service.enabled&lt;/name> &lt;value>true&lt;/value> &lt;description>启用timeline server&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.scheduler.capacity.root.default.maximum-allocation-vcores&lt;/name> &lt;value>4&lt;/value> &lt;description>每一个容器最大可申请的CPU核数&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.system-metrics-publisher.enabled&lt;/name> &lt;value>true&lt;/value> &lt;description>是否发布系统级指标&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.store.class&lt;/name>&lt;value>org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore&lt;/value> &lt;/property> &lt;description>Application状态信息数据持久化方式(RM HA模式必须为ZKRMStateStore), 用于Application恢复&lt;/description> &lt;property> &lt;name>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage&lt;/name> &lt;value>98.5&lt;/value> &lt;description>磁盘健康检查阈值&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.log.server.url&lt;/name> &lt;value>http://historyserver:8188/applicationhistory/logs/&lt;/value> &lt;description>日志服务器地址&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.fs.state-store.uri&lt;/name> &lt;value>/rmstate&lt;/value> &lt;description>状态存储路径&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.timeline-service.generic-application-history.enabled&lt;/name> &lt;value>true&lt;/value> &lt;description>client是否通过timeline history-service查询通用的application数据&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.log-aggregation-enable&lt;/name> &lt;value>true&lt;/value> &lt;description>是否开启日志聚合&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.hostname&lt;/name> &lt;value>resourcemanager&lt;/value> &lt;description>resourcemanager主机名&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.scheduler.capacity.root.default.maximum-allocation-mb&lt;/name> &lt;value>8192&lt;/value> &lt;description>每一个容器最大可申请的内存大小&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.aux-services&lt;/name> &lt;value>mapreduce_shuffle&lt;/value> &lt;description>使用的shuffle服务&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.resource_tracker.address&lt;/name> &lt;value>resourcemanager:8031&lt;/value> &lt;description>资源跟踪地址&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.timeline-service.hostname&lt;/name> &lt;value>historyserver&lt;/value> &lt;description>timeline服务主机名&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.scheduler.address&lt;/name> &lt;value>resourcemanager:8030&lt;/value> &lt;description>调度器地址&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.address&lt;/name> &lt;value>resourcemanager:8032&lt;/value> &lt;description>资源管理器地址&lt;/description> &lt;/property> &lt;property> &lt;name>mapred.map.output.compress.codec&lt;/name> &lt;value>org.apache.hadoop.io.compress.SnappyCodec&lt;/value> &lt;description>map输出压缩编码&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.remote-app-log-dir&lt;/name> &lt;value>/app-logs&lt;/value> &lt;description>日志汇总路径&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.scheduler.class&lt;/name> &lt;value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value> &lt;description>使用的调度器&lt;/description> &lt;/property> &lt;property> &lt;name>mapreduce.map.output.compress&lt;/name> &lt;value>true&lt;/value> &lt;description>map输出是否压缩&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.resource.memory-mb&lt;/name> &lt;value>16384&lt;/value> &lt;description>可为容器分配的内存大小&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.recovery.enabled&lt;/name> &lt;value>true&lt;/value> &lt;description>是否启用Application自动恢复&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.resource.cpu-vcores&lt;/name> &lt;value>8&lt;/value> &lt;description>可为容器分配的CPU核数&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.bind-host&lt;/name> &lt;value>0.0.0.0&lt;/value> &lt;description>resourcemanager绑定地址&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.bind-host&lt;/name> &lt;value>0.0.0.0&lt;/value> &lt;description>nodemanager绑定地址&lt;/description> &lt;/property> &lt;property> &lt;name>yarn.timeline-service.bind-host&lt;/name> &lt;value>0.0.0.0&lt;/value> &lt;description>timeline server绑定地址&lt;/description> &lt;/property> &lt;/configuration> 运维命令 应用管理
1 2 3 4 5 6 7 8 9 10 11 12 13 # 查看application列表 yarn application -list yarn application -list -appStates ALL yarn application -list -appStates RUNNING yarn application -list -appTypes MAPREDUCE # 杀死application yarn application -kill &lt;applicationid> # 查看application状态 yarn application -status &lt;applicationid> # 查看application日志 yarn logs -applicationId &lt;applicationid> # 移动application到其他队列 yarn application -movetoqueue &lt;applicationid> -queue other 节点管理
1 2 # 查看各node上的application yarn node --list 常用API 相关工具 文章推荐 官方文档 The YARN Timeline Server DockerContainerExecutor 批处理和流处理 排障经验 Hadoop 分布式数据存储与分析框架
基本概念 BigData: 大数据是指高速 (Velocity) 涌现的大量 (Volume) 的多样化 (Variety) 数据, 表示越来越庞大、越来越复杂的数据集. 大数据技术就是围绕大数据的采集, 集成, 管理, 分析, 可视化等一系列挖掘数据价值的相关技术 HDFS: 全称Hadoop Distributed File System, 是一个可扩展、容错、高性能的分布式文件系统, 异步复制, 一次写入多次读取. HDFS是Hadoop四大组件之一(核心, Storage layer), 主要负责数据存储 MapReduce: Hadoop内置的大规模数据集分布式并行计算框架, MapReduce框架基于MapReduce编程模型实现, 是一种成本低廉的批处理离线计算框架. MapReduce是hadoop四大组件之一(核心, Processing layer), 主要负责数据计算 YARN: Hadoop集成的新一代全局资源管理与调度框架, 负责为计算任务分配计算资源, 支持多种计算框架. Yarn是hadoop四大组件之一(核心, Resource Management layer), 主要负责资源管理与调度 Common: Hadoop内支持其他模块的工具模块, Common是hadoop四大组件之一, 负责为其他hadoop模块提供基础设施, 是其他组件的底层指出, 主要提供基础工具包和 RPC 框架等 架构特性 集群架构
生态系统
大数据领域的核心是Hadoop, 虽然Hadoop本身只包括四大组件, 但围绕着Hadoop诞生了众多的大数据相关项目, 形成了庞大的Hadoop大数据生态圈:
Zookeeper: Zookeeper是流行的分布式协调服务, 它并不是为大数据设计, 大量的分布式系统依赖Zookeeper实现分布式一致性
Kafka: Kafka是高吞吐量的分布式发布订阅消息队列系统, 它并不是为大数据设计, 在大数据生态系统中, 可以将Kafka作为数据交换枢纽, 不同类型的分布式系统(关系数据库、NoSQL数据库、流处理系统、批处理系统等), 可以统一接入到Kafka, 实现和Hadoop各个组件之间的不同类型数据的实时高效交换, 较好地满足各种企业应用需求
HBase: HBase是分布式可扩展的大数据列式数据库, 基于bigtable模型, 使用HDFS作为其底层存储系统, 支持大规模数据的随机和实时读写访问
Spark: spark是当前最流行的大数据内存计算框架, 可独立部署或与Hadoop集成, 相比MapReduce性能提升明显, 特别适合迭代计算场景. spark能够同时支持批处理和微批流处理. spark生态系统已经发展成为一个包含多个子项目的集合, 其中包含SparkSQL、Spark Streaming、GraphX、MLib、SparkR等子项目, 能够处理大数据计算中的大多数场景
Storm: Storm是一个开源的分布式流处理计算框架, 具有低延迟、容错、高可用等特性. 它可以轻松可靠地处理无限数据流, 是实时分析、在线机器学习、持续计算、分布式 RPC 、ETL 的优良选择
Flink: Flink是一个面向数据流处理和批量数据处理的开源框架和分布式处理引擎, 完全兼容Hadoop, 具有高吞吐、低延迟、高扩展、支持容错等特性, Flink和Spark都是下一代大数据计算引擎的有力竞争者
Tez: Tez是开源的支持DAG(有向无环图)作业的计算框架, 通过DAG作业的方式运行MapReduce 作业, 提供了程序运行的整体处理逻辑, 就可以去除工作流当中多余的Map阶段, 减少不必要的操作, 提升数据处理的性能. 可以让Tez 框架运行在YARN 框架之上, 然后让MapReduce、Pig 和Hive等计算框架运行在Tez框架之上, 从而借助于Tez 框架实现对MapReduce、Pig 和Hive等的性能优化, 更好地解决现有MapReduce框架在迭代计算(如PageRank计算)和交互式计算方面存在的问题
Hive: Hive是建立在Hadoop基础上的数据仓库软件包, 支持将结构化数据文件映射为数据库表并提供类SQL查询语言HiveQL实现简单的SQL查询功能, 通过HiveQL能够将SQL语句转换为MapReduce作业, Hive依赖HDFS和MapReduce进行数据存储和任务计算, 利用Hive能够降低Hadoop使用门槛, 特别适合数据仓库统计分析
Pig: Pig与Hive类似, 也是对大数据集进行分析和评估的工具, 不同于Hive的是Pig提供了一种高层的, 面向领域的抽象语言Pig Latin. 同样Pig也可以将Pig Latin转化为MapReduce作业. 相比与SQL, Pig Latin更加灵活, 但学习成本更高
Impala: Impala可以对存储HDFS、HBase的海量数据提供交互查询的SQL接口. 除了和Hive使用相同的统一存储平台, Impala也使用相同的元数据, SQL语法, ODBC驱动程序和用户界面. Impala还提供了一个熟悉的面向批量或者实时查询的统一平台. Impala的特点是查询非常迅速, 其性能大幅度领先于Hive. Impala并不是基于MapReduce的, 它的定位是OLAP, 是Google的新三驾马车之一Dremel的开源实现
Solr: Solr是基于Lucene的高性能全文检索引擎, 通过与HBase配合, 建立HBase表中条件过滤字段和rowkey索引可以实现快速的大数据条件查询
Mahout: Mahout是一个机器学习和数据挖掘库, 它利用MapReduce编程模型实现k-means, Native, Bayes, Collaborative Filtering等经典的机器学习算法, 并使其具有良好的可扩展性
Kylin: Kylin是一个开源的分布式分析型数据仓库, 提供Hadoop/Spark 之上的 SQL查询接口及多维分析(OLAP)能力以支持超大规模数据, 能够在亚秒内查询巨大的表
Sqoop: Sqoop是开源的数据转换工具, 主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql等)间进行数据的传递, 可以将一个关系型数据库中的数据导入到Hadoop的HDFS中, 也可以将HDFS的数据导出到关系型数据库中
Flume: Flume是一个高可用, 高可靠, 分布式的海量日志采集、聚合和传输系统. 它是hadoop生态系统的日志采集系统, 用途广泛, 可以将日志、网络数据、kafka消息收集并存储在大数据HDFS系统之上. 现在Flume特指第二代Flume, 即flume-ng
Oozie: Oozie是一个管理Hadoop作业(job)的工作流程调度管理系统, 是一个可伸缩、可靠和可扩展的系统. Oozie协调作业就是通过时间(频率)和有效数据触发当前的Oozie工作流程, Oozie与Hadoop生态圈的其他部分集成在一起, 支持多种类型的Hadoop作业(如Java map-reduce、流式map-reduce、Pig、Hive、Sqoop和Distcp)以及特定于系统的工作(如Java程序和shell脚本)
Ranger: Ranger是大数据领域一个集中式安全管理框架, 管理授权和审计, 是Hadoop生态的综合安全管理组件. 通过制定策略(policies)实现对诸如HDFS、Yarn、Hive、Kafka、HBase、Storm等组件进行细粒度的权限控制. 通过Ranger控制台, 管理员通过配置策略来控制用户访问权限. 比如可以控制用户读取HDFS文件权限, 甚至可以控制用户对Hive某列的访问权限
Atlas: Atlas是Hadoop社区为解决Hadoop生态系统的元数据治理问题而产生的开源项目, 它为Hadoop集群提供了包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理在内的元数据治理核心功能. Atlas支持各种Hadoop和非Hadoop元数据类型, 提供了丰富的REST API进行集成, 对数据血缘的追溯达到了字段级别, 对权限也有很好的控制
Ambari: Ambari是开源的大数据生态部署管理工具, 它可以创建、管理、监视Hadoop整个生态圈(例如Hive，Hbase，Sqoop，Zookeeper等)的集群, 使得Hadoop以及相关的大数据软件更容易使用. Ambari本身是一个分布式架构的软件, 由Ambari Server和Ambari Agent两部分组成, 用户可通过Ambari Server通知Ambari Agent安装对应的软件, Ambari Agent会定时地发送各个机器每个软件模块的状态给Ambari Server, 最终这些状态信息会呈现在Ambari的GUI, 方便用户了解到集群的各种状态, 并进行相应的维护
配置文件 $HADOOP_HOME/etc/hadoop/core-site.xml: hadoop中core配置文件. default
1 2 3 4 5 6 7 8 9 10 11 12 &lt;configuration> &lt;property>&lt;name>hadoop.proxyuser.hue.hosts&lt;/name>&lt;value>*&lt;/value>&lt;/property> &lt;property>&lt;name>fs.defaultFS&lt;/name>&lt;value>hdfs://namenode:9000&lt;/value>&lt;/property> &lt;property>&lt;name>hadoop.http.staticuser.user&lt;/name>&lt;value>root&lt;/value>&lt;/property> &lt;property>&lt;name>io.compression.codecs&lt;/name>&lt;value>org.apache.hadoop.io.compress.SnappyCodec&lt;/value>&lt;/property> &lt;property>&lt;name>hadoop.proxyuser.hue.groups&lt;/name>&lt;value>*&lt;/value>&lt;/property> &lt;property>&lt;name>hadoop.proxyuser.hue.hosts&lt;/name>&lt;value>*&lt;/value>&lt;/property> &lt;property>&lt;name>fs.defaultFS&lt;/name>&lt;value>hdfs://namenode:9000&lt;/value>&lt;/property> &lt;property>&lt;name>hadoop.http.staticuser.user&lt;/name>&lt;value>root&lt;/value>&lt;/property> &lt;property>&lt;name>io.compression.codecs&lt;/name>&lt;value>org.apache.hadoop.io.compress.SnappyCodec&lt;/value>&lt;/property> &lt;property>&lt;name>hadoop.proxyuser.hue.groups&lt;/name>&lt;value>*&lt;/value>&lt;/property> &lt;/configuration> 运维命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 整个集群启停 sbin/start-all.sh sbin/stop-all.sh # yarn启停 sbin/start-yarn.sh sbin/stop-yarn.sh # dfs启停 sbin/start-dfs.sh sbin/stop-dfs.sh # 格式化zk bin/hdfs zkfc -formatZK # 格式化namenode bin/hadoop namenode -format # 启动journalnode集群 bin/hadoop-daemons.sh start journalnode # 启动namenode bin/hadoop-daemon.sh start namenode # 启动datanode bin/hadoop-daemon.sh start datanode # 启动zkfc bin/hadoop-daemon.sh start zkfc # namenode变为stanbynode bin/hdfs namenode -bootstrapStandby # 启动resourcemanager bin/start-yarn.sh bin/yarn-daemon.sh start resourcemanager # 启动dfs(namenode,journalnode,datanode,zkfc都会启动) sbin/start-dfs.sh # 启动yarn(nodemanager, resourcemanager都会启动) sbin/start-yarn.sh # 启动journalnode(也可单独启动namenode, datanode) sbin/hadoop-daemon.sh start journalnode # 启动resourcemanager(也可单独启动nodemanager) sbin/yarn-daemon.sh start resourcemanager # 单独启动datanode sbin/start-secure-dns.sh # 下线节点 # 修改/hadoop所在目录/etc/hadoop/slaves # 去掉要下线的数据节点 # 修改/hadoop所在目录/etc/hadoop/excludes # 增加要下线的数据节点 # 把这两个文件同步到所有的hadoop节点的相应目录下 # 刷新节点列表 bin/hdfs dfsadmin -refreshNodes 文章推荐 官方文档 Hadoop系列 大数据系列 大数据学习系列 Hadoop配置文件详解 Hadoop HDFS和MapReduce Apache Hadoop Architecture 大数据处理框架发展史 HBase架构剖析 HBase架构模型与读写流程 Spark2.x系列 Spark2.x模块解析 Storm架构 Storm架构与运行原理 Flink系列 Flink关键技术解析与优化实战 Tez是什么 Tez Overview Hive介绍 Hive架构原理 Pig系列 Impala系列 Solr系列 Solr搜索服务器 Solr架构图 Mahout快速指南 Kylin系列 Sqoop使用手册 Sqoop详解 Flume系列 Oozie系列 Ranger学习总结 Atlas详解 Atlas实践 Ambari系列 Ambari架构详解</content></entry><entry><title>Loki云原生日志系统</title><url>https://xshrim.github.io/post/Loki%E4%BA%91%E5%8E%9F%E7%94%9F%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag><tag>loki</tag><tag>log</tag><tag>日志采集</tag></tags><content type="html"> 概览 组件 存储 查询 部署</content></entry><entry><title>Markdown语法手册</title><url>https://xshrim.github.io/post/markdown-syntax/</url><categories><category>themes</category><category>syntax</category></categories><tags><tag>markdown</tag><tag>css</tag><tag>html</tag></tags><content type="html"> 本文提供了一个可以在 Hugo 内容文件中使用的基本Markdown语法示例，还展示了基本 HTML 元素在 Hugo 主题中是否使用 CSS 装饰。
标题 下面的 HTML 代码&lt;h1>—&lt;h6> 元素表示六个级别的节标题。 &lt;h1>是最高的节级别，&lt;h6>是最低的节级别。
H1 H2 H3 H4 H5 H6 段落 Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.
伊塔图？厨房里有很多东西，我不知道他们喜欢吃什么，或者他们喜欢吃什么。
引用 blockquote元素表示从另一个来源引用的内容，可选的引用必须在footer或cite元素内，也可选的内嵌更改，如注释和缩写。
引用没有归属 Tiam, ad mint andaepu dandae nostion secatur sequo quae. 注意 可以在块引用中使用 Markdown 语法。
带归属的引用 不要通过分享记忆来交流，通过交流来分享记忆。
— 罗布·派克1
表格 表不是Markdown核心规范的一部分，但是Hugo支持开箱即用。
Name Age Bob 27 Alice 23 表格内使用Markdown语法 Italics Bold Code italics bold code 图像 1 ![图像描述](图像地址) 示例 Google Chrome Firefox Browser
点击图像可以打开图像浏览器，快试试吧。
代码块 带有引号的代码块 1 2 3 4 5 6 7 8 9 10 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 用四个空格缩进的代码块 &lt;!doctype html>
&lt;html lang="en">
&lt;head>
&lt;meta charset="utf-8">
&lt;title>Example HTML5 Document&lt;/title>
&lt;/head>
&lt;body>
&lt;p>Test&lt;/p>
&lt;/body>
&lt;/html>
代码块引用Hugo的内部高亮短代码 1 2 3 4 5 6 7 8 9 10 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 列表类型 有序列表 First item Second item Third item 无序列表 List item Another item And another item 嵌套列表 Fruit Apple Orange Banana Dairy Milk Cheese 其他元素 — abbr, sub, sup, kbd, mark GIF 是位图图像格式。
H2O
Xn + Yn = Zn
按 CTRL+ALT+Delete 组合键结束会话。
大多数蝾螈在夜间活动，捕食昆虫、蠕虫和其他小动物。
以上引文摘自Rob Pike在2015年11月18日Gopherfest上的演讲。&#160;&#8617;&#xfe0e;</content></entry><entry><title>富文本内容测试</title><url>https://xshrim.github.io/post/rich-content/</url><categories/><tags><tag>shortcodes</tag><tag>privacy</tag></tags><content type="html"> Hugo上有几个内置短代码，用于丰富内容，以及隐私配置还有一组简单的短代码，支持各种社交媒体嵌入的静态和非JS版本。
YouTube Privacy Enhanced Shortcode Twitter Simple Shortcode Vimeo Simple Shortcode</content></entry><entry><title>占位符文本显示</title><url>https://xshrim.github.io/post/placeholder-text/</url><categories/><tags><tag>markdown</tag><tag>text</tag></tags><content type="html"> 你对我的心有偏见。我向您保证，我们的生活将不会受到影响，我们的生活将会受到影响。你说你现在住在医院里，因为你的眼睛是透明的，你的眼睛是光明的，你的眼睛是光明的!
Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.
Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon
Mane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.
Iubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.
Eurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.</content></entry><entry><title>数据公式设置显示</title><url>https://xshrim.github.io/post/math-typesetting/</url><categories/><tags/><content type="html"> Hugo项目中的数学表示法可以通过使用第三方JavaScript库来实现。
在这个例子中，我们将使用 MathJax
Create a post under /content/en[zh-CN]/math.md
可以全局启用MathJax，请在项目配置中将参数math设置为true
或是在每页基础上启用MathJax，在内容文件中包括参数math: true
注意： 使用支持的TeX功能的联机参考资料
例子 重复的分数 $$ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} \equiv 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } } $$
总和记号 $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$
几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \displaystyle。
$$ \displaystyle\sum_{i=1}^{k+1}i $$
$$ \displaystyle= \left(\sum_{i=1}^{k}i\right) +(k+1) $$
$$ \displaystyle= \frac{k(k+1)}{2}+k+1 $$
$$ \displaystyle= \frac{k(k+1)+2(k+1)}{2} $$
$$ \displaystyle= \frac{(k+1)(k+2)}{2} $$
$$ \displaystyle= \frac{(k+1)((k+1)+1)}{2} $$
乘记号 $$ \displaystyle 1 + \frac{q^2}{(1-q)}+\frac{q^6}{(1-q)(1-q^2)}+\cdots = \displaystyle \prod_{j=0}^{\infty}\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \displaystyle\text{ for }\lvert q\rvert &lt; 1. $$
随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。
希腊字母 $$ \Gamma\ \Delta\ \Theta\ \Lambda\ \Xi\ \Pi\ \Sigma\ \Upsilon\ \Phi\ \Psi\ \Omega \alpha\ \beta\ \gamma\ \delta\ \epsilon\ \zeta\ \eta\ \theta\ \iota\ \kappa\ \lambda\ \mu\ \nu\ \xi \ \omicron\ \pi\ \rho\ \sigma\ \tau\ \upsilon\ \phi\ \chi\ \psi\ \omega\ \varepsilon\ \vartheta\ \varpi\ \varrho\ \varsigma\ \varphi $$
箭头 $$ \gets\ \to\ \leftarrow\ \rightarrow\ \uparrow\ \Uparrow\ \downarrow\ \Downarrow\ \updownarrow\ \Updownarrow $$
$$ \Leftarrow\ \Rightarrow\ \leftrightarrow\ \Leftrightarrow\ \mapsto\ \hookleftarrow \leftharpoonup\ \leftharpoondown\ \rightleftharpoons\ \longleftarrow\ \Longleftarrow\ \longrightarrow $$
$$ \Longrightarrow\ \longleftrightarrow\ \Longleftrightarrow\ \longmapsto\ \hookrightarrow\ \rightharpoonup $$
$$ \rightharpoondown\ \leadsto\ \nearrow\ \searrow\ \swarrow\ \nwarrow $$
符号 $$ \surd\ \barwedge\ \veebar\ \odot\ \oplus\ \otimes\ \oslash\ \circledcirc\ \boxdot\ \bigtriangleup $$
$$ \bigtriangledown\ \dagger\ \diamond\ \star\ \triangleleft\ \triangleright\ \angle\ \infty\ \prime\ \triangle $$
微积分学 $$ \int u \frac{dv}{dx},dx=uv-\int \frac{du}{dx}v,dx $$
$$ f(x) = \int_{-\infty}^\infty \hat f(\xi),e^{2 \pi i \xi x} $$
$$ \oint \vec{F} \cdot d\vec{s}=0 $$
洛伦茨方程 $$ \begin{aligned} \dot{x} &amp; = \sigma(y-x) \ \dot{y} &amp; = \rho x - y - xz \ \dot{z} &amp; = -\beta z + xy \end{aligned} $$
交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
这里有一个解决方案:使用“mfrac”类(在MathJax情况下没有区别)的额外类使分数更小:
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
强调 $$ \hat{x}\ \vec{x}\ \ddot{x} $$
有弹性的括号 $$ \left(\frac{x^2}{y^3}\right) $$
评估范围 $$ \left.\frac{x^3}{3}\right|_0^1 $$
诊断标准 $$ f(n) = \begin{cases} \frac{n}{2}, &amp; \text{if } n\text{ is even} \ 3n+1, &amp; \text{if } n\text{ is odd} \end{cases} $$
麦克斯韦方程组 $$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \ \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \ \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \ \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
这些方程式很狭窄。我们可以使用(例如)添加垂直间距 [1em] 在每个换行符(\)之后。正如你在这里看到的：
$$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \[1em] \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \[0.5em] \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \[1em] \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
统计学 固定词组：
$$ \frac{n!}{k!(n-k)!} = {^n}C_k {n \choose k} $$
分数在分数 $$ \frac{\frac{1}{x}+\frac{1}{y}}{y-z} $$
ｎ次方根 $$ \sqrt[n]{1+x+x^2+x^3+\ldots} $$
矩阵 $$ \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\ a_{21} &amp; a_{22} &amp; a_{23}\ a_{31} &amp; a_{32} &amp; a_{33} \end{pmatrix} \begin{bmatrix} 0 &amp; \cdots &amp; 0 \ \vdots &amp; \ddots &amp; \vdots \ 0 &amp; \cdots &amp; 0 \end{bmatrix} $$
标点符号 $$ f(x) = \sqrt{1+x} \quad (x \ge -1) f(x) \sim x^2 \quad (x\to\infty) $$
现在用标点符号:
$$ f(x) = \sqrt{1+x}, \quad x \ge -1 f(x) \sim x^2, \quad x\to\infty $$</content></entry><entry><title>支持Emoji表情符号</title><url>https://xshrim.github.io/post/emoji-support/</url><categories/><tags><tag>emoji</tag></tags><content type="html"> 在Hugo项目中可以通过多种方式启用Emoji。
The emojify function can be called directly in templates or Inline Shortcodes.
To enable emoji globally, set enableEmoji to true in your site&rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.
馃檲 🙈 馃檳 🙉 馃檴 🙊
The Emoji cheat sheet is a useful reference for emoji shorthand codes.
N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.
1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; }</content></entry><entry><title>关于我</title><url>https://xshrim.github.io/about.html</url><categories/><tags/><content type="html"> Hugo是用Go编写的一个开放源代码静态站点生成器，可在Apache许可证2.0下使用。 Hugo支持TOML, YAML和JSON数据文件类型，Markdown和HTML内容文件，并使用短代码添加丰富的内容。其他值得注意的功能包括分类法、多语言模式、图像处理、自定义输出格式、HTML/CSS/JS缩小和对Sass SCSS工作流的支持。
Hugo使用了多种开源项目，包括:
https://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo是博客、企业网站、创意作品集、在线杂志、单页应用程序甚至是数千页的网站的理想选择。
Hugo适合那些想要手工编写自己的网站代码，而不用担心设置复杂的运行时、依赖关系和数据库的人。
使用Hugo建立的网站非常快速、安全，可以部署在任何地方，包括AWS、GitHub Pages、Heroku、Netlify和任何其他托管提供商。
更多信息请访问GitHub.</content></entry><entry><title/><url>https://xshrim.github.io/post/golang%E5%AD%A6%E4%B9%A0/</url><categories/><tags/><content type="html"> 图谱 文章 Go语言设计与实现 鸟窝的Go语言 Go夜读 猿码记 煎鱼Go Go路线图 Go如何进阶 项目 GoByExample GoGinExample Go-gRPC</content></entry><entry><title/><url>https://xshrim.github.io/post/Jvm%E8%AF%A6%E8%A7%A3/</url><categories/><tags/><content type="html"> JVM 概述 无可避免地，我们都需要用到多线程的一天。单纯地使用多线程的参数设置，比如-Xms、-Xmx、-Xss等，还不足够，我们还要学会如何分析JVM里面的线程状况。
在进行java程序问题定位时，内存问题定位是很关键的，jvm自带的命令可以方便的在生产监控和打印堆栈的日志信息帮忙我们来定位问题！虽然jvm调优成熟的工具已经有很多：jconsole、大名鼎鼎的VisualVM，IBM的Memory Analyzer等等，但是在生产环境出现问题的时候，工具的使用会有所限制。所有的工具几乎都是依赖于jdk的接口和底层的这些命令，研究和掌握这些命令的使用也让我们更能了解jvm构成和特性。
Sun JDK监控JVM命令有：
jps JVM Process Status Tool，显示指定系统内所有的HotSpot虚拟机进程； jstat 提供Java垃圾回收以及类加载信息； 故障排除命令有
jcmd 打印一个Java进程的类、线程以及虚拟机信息 jinfo 访问JVM系统属性，同事可以动态修改这些属性 jhat 帮助分析内存堆存储 jmap 提供JVM内存使用信息 jstack Java堆栈跟踪工具 监控JVM命令 jps JVM Process Status Tool，显示指定系统内所有的HotSpot虚拟机进程。
命令格式 1 jps [options] [hostid] options参数 1 2 3 4 -l：输出主类全名或jar路径 -q：抑制类名的输出，JAR文件名和传递给main方法的参数，仅生成本地JVM标识符列表 -m：输出JVM启动时传递给main()的参数 -v：输出JVM启动时显示指定的JVM参数 示例 1 2 3 4 $ jps -l -m 28920 org.apache.catalina.startup.Bootstrap start 11589 org.apache.catalina.startup.Bootstrap start 25816 sun.tools.jps.Jps -l -m jstat jstat(JVM statistics Monitoring)是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。
命令格式 1 jstat [option] LVMID [interval] [count] options参数 1 2 3 4 [option]：操作参数 LVMID：本地虚拟机进程ID [interval]：连续输出的时间间隔 [count]：连续输出的次数 option参数总览：
option 描述 class class loader的行为统计 compiler HotSpot JIT编译器行为统计 gc 垃圾回收堆的行为统计 gccapacity 各个垃圾回收代容量(young，old，perm)和他们相应的空间统计 gcnew 新生代行为统计 gcnewcapacity 新生代与其相应的内存空间的统计 gcold 年老代和永生代行为统计 gcoldcapacity 年老代行为统计 gcpermcapacity 永生代行为统计 printcompilation HotSpot编译方法统计 示例 -class 监视类装载、卸载数量、总空间以及耗费的时间
1 2 3 4 5 6 7 8 9 [root@cdh1 ~]# jstat -class 348534 Loaded Bytes Unloaded Bytes Time 9099 18284.4 32 46.4 13.85 Loaded：加载class的数量 Bytes：class字节大小 Unloaded：未加载class的数量 Bytes：未加载class的字节大小 Time：加载时间 -compiler 输出JIT编译过的方法数量耗时等
1 2 3 4 5 6 7 8 9 10 [root@cdh2 ~]# jstat -compiler 348534 Compiled Failed Invalid Time FailedType FailedMethod 23470 1 0 234.19 1 sun/misc/URLClassPath$JarLoader getResource Compiled：编译数量 Failed：编译失败数量 Invalid：无效数量 Time：编译耗时 FailedType：失败类型 FailedMethod：失败方法的全限定名 -gc 垃圾回收堆的行为统计
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [root@cdh2 ~]# jstat -gc 348534 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 4096.0 4096.0 3616.1 0.0 3486720.0 2576053.9 6990848.0 6040397.9 62848.0 61320.9 6784.0 6381.8 16264 962.293 3 6.332 968.625 C即Capacity总容量，U即Used已使用的容量 S0C：survivor0区的总容量 S1C：survivor1区的总容量 S0U：survivor0区已使用的容量 S1U：survivor1区已使用的容量 EC：Eden区的总容量 EU：Eden区已使用的容量 OC：Old区的总容量 OU：Old区已使用的容量 MC：方法区的总容量 MU: 方法区已使用的容量 CCSC：压缩类的总容量 CCSU：压缩类已使用的容量 YGC：新生代垃圾回收次数 YGCT：新生代垃圾回收时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收时间 GCT：垃圾回收总消耗时间 注：之前的PC和PU被MC、MU取代了（永久代）
1 [root@cdh2 ~]# jstat -gc 348534 2000 10 这个命令意思就是每隔2000ms输出348534的gc情况，一共输出10次
-gccapacity 同-gc，不过还会输出Java堆各区域使用到的最大、最小空间
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [root@hscluster2 yangjianqiu]# jstat -gccapacity 348534 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 3494912.0 3494912.0 3494912.0 4608.0 4608.0 3485696.0 6990848.0 6990848.0 6990848.0 6990848.0 0.0 1105920.0 62848.0 0.0 1048576.0 6784.0 16277 3 NGCMN：新生代占用的最小容量 NGCMX：新生代占用的最大容量 NGC：当前新生代容量 S0C：surivivor0区的容量 S1C：surivivor1区的容量 EC：伊甸园区的大小 OGCMN：老年代占用的最小容量 OGCMX：老年代占用的最大容量 OGC：当前老年代的容量（KB） OC：当前老年代的空间（KB） MCMN：最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代gc次数 FGC：老年代GC次数 -gcutil 同-gc，不过输出的是已使用空间占总空间的百分比
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@cdh2 ~]# jstat -gcutil 348534 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 83.13 39.56 87.70 97.59 94.07 16737 996.073 3 6.332 1002.406 S0：surivivor0区 S1：surivivor1区 E：伊甸园区 O：老年代 M：元数据 CCS：压缩类 YGC：年轻代gc次数 YGCT：新生代垃圾回收时间 FGC：老年代GC次数 FGCT：老年代垃圾回收时间 GCT：垃圾回收总消耗时间 -gccause 垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因。
1 2 3 4 5 6 [root@cdh2 ~]# jstat -gccause 348534 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT LGCC GCC 0.00 60.07 67.49 87.74 97.59 94.07 16753 997.315 3 6.332 1003.647 Allocation Failure No GC LGCC：最近垃圾回收的原因 GCC：当前垃圾回收的原因 -gcnew 统计新生代的行为
1 2 3 4 5 6 7 8 [root@cdh2 ~] # jstat -gcnew 348534 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT 5120.0 5120.0 3872.1 0.0 15 15 5120.0 3484672.0 2025220.0 16828 1003.157 TT：Tenuring threshold（提升阀值） MTT：最大的tenuring threshold DSS：survivor区域大小（KB） -gcnewcapacity 新生代与其相应的内存空间的统计
1 2 3 4 5 6 7 8 [root@cdh2 ~]# jstat -gcnewcapacity 348534 NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 3494912.0 3494912.0 3494912.0 1164800.0 5120.0 1164800.0 5120.0 3493888.0 3484672.0 16837 3 NGC：当前年轻代的容量（KB） S0CMX：最大的S0空间（KB） S0C：当前S0空间（KB） ECMX：最大eden空间（KB） -gcold 统计老年代的行为
1 2 3 4 [root@cdh2 ~] # jstat -gcold 348534 MC MU CCSC CCSU OC OU YGC FGC FGCT GCT 62848.0 61330.8 6784.0 6381.8 6990848.0 6169097.4 16842 3 6.332 1010.295　-gcoldcapacity 统计老年代的大小和空间
1 2 3 [root@cdh2 ~]# jstat -gcoldcapacity 348534 OGCMN OGCMX OGC OC YGC FGC FGCT GCT 6990848.0 6990848.0 6990848.0 6990848.0 16844 3 6.332 1010.395 -gcmetacapacity 元数据的大小和空间
1 2 3 [root@cdh2 ~]# jstat -gcmetacapacity 348534 MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC FGCT GCT 0.0 1105920.0 62848.0 0.0 1048576.0 6784.0 16846 3 6.332 1010.522　-printcompilation hotspot编译方法统计
1 2 3 4 5 6 7 8 [root@cdh2 ~]# jstat -printcompilation 348534 Compiled Size Type Method 23495 366 1 org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf$Saver commitSection Compiled：被执行的编译任务的数量 Size：方法字节码的字节数 Type：编译类型 Method：编译方法的类名和方法名。类名使用“/”代替“，”作为空间分隔符.方法名是给出类的方法名.格式是一致于HotSpot -XX:+PrintComplation选项 故障处理命令 jcmd 由于调优参数非常繁多，需要借助JVM命令行和JVM调优参数来使用。使用command_line命令可以获得命令行中指定的调优参数，flags命令可以获得通过命令设置的调优参数和JVM设置的调优参数。
通过jcmd命令可以获得一个运行中JVM内生效的调优参数。jcmd是JDK1.7之后出现的，jcmd的常见用法：
堆直方图查看：查看系统中类统计信息GC.class_histogram 堆转储：导出堆信息GC.heap_dump 获取系统Properties内容VM.system_properties 获取启动参数VM.flags 获取所有性能相关数据PerfCounter.print 查看原生内存信息：jcmd process_id VM.native_memory summary 查看CompressedClassSpace大小：jcmd pid GC.head_info 命令格式 1 jcmd process_id [option] options参数 option 描述 -l 列出所有JVM虚拟机 help 帮助 VM.uptime 查看虚拟机启动时间VM.uptime Thread.print 打印线程栈信息 GC.class_histogram 查看系统中类统计信息 GC.heap_dump 导出堆栈信息 VM.system_properties 获取系统Properties内容 VM.flags 获取启动参数 PerfCounter.print 获取所有性能相关数据 VM.native_memory 查看原生内存信息 summary/detail/baseline/summary.diff/detail.diff/shutdown jinfo jinfo（JVM Configuration info）这个命令作用是实时查看和调整虚拟机运行参数。jps -v命令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo命令。
命令格式 1 jinfo [option] [args] LVMID option参数 1 2 3 -flag：输出指定args参数的值 -flags：不需要args参数，输出所有JVM参数的值 -sysprops：输出系统属性，等同于System.getProperties() 示例 1 2 3 4 5 6 7 [root@cdh2 ~]# jinfo -flags 21341 Attaching to process ID 21341, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.112-b15 Non-default VM flags: -XX:CICompilerCount=15 -XX:InitialHeapSize=10737418240 -XX:MaxHeapSize=10737418240 -XX:MaxNewSize=4294967296 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=4294967296 -XX:OldSize=6442450944 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGC Command line: -Dproc_rangeradmin -XX:MaxPermSize=256m -Xmx10240m -Xms10240m -Xmn4096m -Duser.timezone=UTC -Duser=root -Dhostname=cdh2 -Dservername=rangeradmin -Dlogdir=/home/hypergalaxy/rangeradmin/ews/logs -Dcatalina.base=/home/hypergalaxy/rangeradmin/ews jmap jmap（JVM Memory Map）命令用于生成heap dump文件，如果不使用这个命令，还可以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候，自动生成dump文件。jmap不仅能生成dump文件，还可以查询finalize执行队列、Java堆和永久代的详细信息，如当前使用率、当前使用的是哪种收集器等。
命令格式 1 jmap [option] LVMID option参数 1 2 3 4 5 6 dump：生成堆转储快照 finalizerinfo：显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象 heap：显示Java堆详细信息 histo：显示堆中对象的统计信息 permstat：to print permanent generation statistic F：当-dump没有响应时，强制生成dump快照 示例 -dump 常用格式
1 -dump::live, format=b, file=&lt;filename> pid dump dump堆到文件，format指定输出格式，live指明是活着的对象，file指定文件名
1 2 3 $ jmap -dump:live, format=b, file=dump.hprof 28920 Dumping heap to /home/xxx/dump.hprof ... Heap dump file created dump.hprof这个后缀是为了后续可以直接用MAT（Memory Anlysis Tool）打开。
-finalizerinfo 打印等待回收对象的信息
1 2 3 4 5 6 $ jmap -finalizerinfo 24314 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 Number of objects pending for finalization: 0 可以看到当前F-QUEUE队列中并没有等待Finalizer线程执行finalizer方法的对象。
-heap 打印heap的概要信息，GC使用的算法，heap的配置以及wist heap的使用情况，可以用此来判断内存目前的使用情况以及垃圾回收情况
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 $ jmap -heap 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 using thread-local object allocation. Parallel GC with 4 thread(s)//GC 方式 Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value>:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value>:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value>:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB) Heap Usage://堆内存使用情况 PS Young Generation Eden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率 From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used To Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used PS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% used PS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used 670 interned Strings occupying 43720 bytes. 可以很清楚的看到Java堆中各个区域目前的情况
-histo 打印堆的对象统计，包括对象数、内存大小等等（因为在dump:live前会进行full gc，如果带上live则只统计活对象，因此不加live的堆大小要大于加live堆的大小）
1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ jmap -histo:live 28920 | more num #instances #bytes class name ---------------------------------------------- 1: 83613 12012248 &lt;constMethodKlass> 2: 23868 11450280 [B 3: 83613 10716064 &lt;methodKlass> 4: 76287 10412128 [C 5: 8227 9021176 &lt;constantPoolKlass> 6: 8227 5830256 &lt;instanceKlassKlass> 7: 7031 5156480 &lt;constantPoolCacheKlass> 8: 73627 1767048 java.lang.String 9: 2260 1348848 &lt;methodDataKlass> 10: 8856 849296 java.lang.Class .... 仅仅打印了前10行
xml class name是对象类型，说明如下：
1 2 3 4 5 6 7 8 9 B byte C char D double F float I int J long Z boolean [ 数组，如[I表示int[] [L+类名 其他对象 -permstat 打印java堆内存的永久保存区域的类加载器的智能统计信息。对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ jmap -permstat 28920 Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 finding class loader instances ..done. computing per loader stat ..done. please wait.. computing liveness.liveness analysis may be inaccurate ... class_loader classes bytes parent_loader alive? type &lt;bootstrap> 3111 18154296 null live &lt;internal> 0x0000000600905cf8 1 1888 0x0000000600087f08 dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 0x00000006008fcb48 1 1888 0x0000000600087f08 dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 0x00000006016db798 0 0 0x00000006008d3fc0 dead java/util/ResourceBundle$RBClassLoader@0x0000000780626ec0 0x00000006008d6810 1 3056 null dead sun/reflect/DelegatingClassLoader@0x00000007800500a0 -F 强制模式。如果指定的pid没有响应，请使用jmap -dump或jmap -histo选项。此模式下，不支持live子选项。
3.4 jhat jhat（JVM Heap Analysis Tool）命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看。在此要注意，一般不会直接在服务器上进行分析，因为jhat是一个耗时并且耗费硬件资源的过程，一般把服务器生成的dump文件复制到本地或其他机器上进行分析。
命令格式 1 jhat [dumpfile] option参数 1 2 3 4 5 6 7 8 -stack false | true：关闭对象分配调用栈跟踪(tracking object allocation call stack)。如果分配位置信息在堆栈转储中不可用。则必须将此标志设置为false，默认值为true； -refs false | true：关闭对象引用跟踪（tracking of references to objects）。默认值为true。默认情况下，返回的指针是指向其他特定对象的对象，如反向链接或输入引用（referrers or incoming references），会统计/计算堆中的所有对象。 -port port-number：设置jhat HTTP server的端口号，默认值 7000； -exclude exclude-file 指定对象查询时需要排除的数据成员列表文件。例如，如果文件列列出了java.lang.String.value，那么当从某个特定对象Object o 计算可达的对象列表时，引用路径涉及java.lang.String.value的都会被排除。 -baseline exclude-file：指定一个基准堆转储（baseline heap dump）。在两个heap dumps中有相同object ID的对象会被标记为不是新的.其他对象被标记为新的，在比较两个不同的堆转储时很有用。 -debug int：设置debug级别。0表示不输出调试信息。值越大则表示输出更详细的debug信息。 -version：启动后只显示版本信息就退出 -J &lt;flag>：因为jhat命令实际上会启动一个JVM来执行，通过-J可以在启动JVM时传入一些启动参数。例如，-J-Xmx512m则指定运行jhat的Java虚拟机使用的最大堆内存为512MB。如果需要使用多个JVM启动参数，则传入多个-Jxxxxxx. 示例 1 2 3 4 5 6 7 8 9 10 $ jhat -J-Xmx512m dump.hprof eading from dump.hprof... Dump file created Fri Mar 11 17:13:42 CST 2016 Snapshot read, resolving... Resolving 271678 objects... Chasing references, expect 54 dots...................................................... Eliminating duplicate references...................................................... Snapshot resolved. Started HTTP server on port 7000 Server is ready. 中间的-J-Xmx512m是在dump快照很大的情况下分配512M内存去启动HTTP服务器，运行完之后就可在浏览器打开http://localhost:7000进行快照分析。堆快照分析主要在最后面的Heap Histogram里，里面根据class列出了dump的时候所有存活对象。
分析同样一个dump快照，MAT需要的额外内存比jhat要小的多的多，所以建议使用MAT来进行分析，当然也看个人偏好。
分析 打开浏览器http://localhost:7000，该页面提供了几个查询功能可供使用：
1 2 3 4 5 6 7 All classes including platform Show all members of the rootset Show instance counts for all classes (including platform) Show instance counts for all classes (excluding platform) Show heap histogram Show finalizer summary Execute Object Query Language (OQL) query 一般查看堆异常情况主要看你这两个部分：Show instance counts for all classes （excluding platform），平台外的所有对象信息。
Show heap histogram 以树状图形式展示堆情况。
具体排查时需要结合代码，观察是否大量应该被回收的对象在一直被引用或者是否有占有内存特别大的对象无法被回收。一般情况，会down到客户端用工具来分析。
jstack jstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息，如果现在运行的java程序呈现hung的状态，jstack是非常有用的。
命令格式 1 jstack [option] LVMID option参数 1 -F：当正常输出请求不被响应时，强制输出线程堆栈``-l：除堆栈外，显示关于锁的附加信息``-m：如果调用到本地方法的话，可以显示C``/C``++的堆栈 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 $ jstack -l 11494|more 2016-07-28 13:40:04 Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.71-b01 mixed mode): "Attach Listener" daemon prio=10 tid=0x00007febb0002000 nid=0x6b6f waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE Locked ownable synchronizers: - None "http-bio-8005-exec-2" daemon prio=10 tid=0x00007feb94028000 nid=0x7b8c waiting on condition [0x00007fea8f56e000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000cae09b80> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:104) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:32) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None ..... JVM详解 前言 如果在文中用词或者理解方面出现问题，欢迎指出。此文旨在提及而不深究，但会尽量效率地把知识点都抛出来
JVM的基本介绍 JVM 是 Java Virtual Machine 的缩写，它是一个虚构出来的计算机，一种规范。通过在实际的计算机上仿真模拟各类计算机功能实现···
好，其实抛开这么专业的句子不说，就知道JVM其实就类似于一台小电脑运行在windows或者linux这些操作系统环境下即可。它直接和操作系统进行交互，与硬件不直接交互，可操作系统可以帮我们完成和硬件进行交互的工作。 Java文件是如何被运行的 比如我们现在写了一个 HelloWorld.java 好了，那这个 HelloWorld.java 抛开所有东西不谈，那是不是就类似于一个文本文件，只是这个文本文件它写的都是英文，而且有一定的缩进而已。
那我们的 JVM 是不认识文本文件的，所以它需要一个 编译 ，让其成为一个它会读二进制文件的 HelloWorld.class
① 类加载器 如果 JVM 想要执行这个 .class 文件，我们需要将其装进一个 类加载器 中，它就像一个搬运工一样，会把所有的 .class 文件全部搬进JVM里面来。 ② 方法区 方法区 是用于存放类似于元数据信息方面的数据的，比如类信息，常量，静态变量，编译后代码···等
类加载器将 .class 文件搬过来就是先丢到这一块上
③ 堆 堆 主要放了一些存储的数据，比如对象实例，数组···等，它和方法区都同属于 线程共享区域 。也就是说它们都是 线程不安全 的
④ 栈 栈 这是我们的代码运行空间。我们编写的每一个方法都会放到 栈 里面运行。
我们会听说过 本地方法栈 或者 本地方法接口 这两个名词，不过我们基本不会涉及这两块的内容，它俩底层是使用C来进行工作的，和Java没有太大的关系。
⑤ 程序计数器 主要就是完成一个加载工作，类似于一个指针一样的，指向下一行我们需要执行的代码。和栈一样，都是 线程独享 的，就是说每一个线程都会有自己对应的一块区域而不会存在并发和多线程的问题。 小总结 Java文件经过编译后变成 .class 字节码文件 字节码文件通过类加载器被搬运到 JVM 虚拟机中 虚拟机主要的5大块：方法区，堆都为线程共享区域，有线程安全问题，栈和本地方法栈和计数器都是独享区域，不存在线程安全问题，而 JVM 的调优主要就是围绕堆，栈两大块进行 简单的代码例子 一个简单的学生类 一个main方法 执行main方法的步骤如下:
编译好 App.java 后得到 App.class 后，执行 App.class，系统会启动一个 JVM 进程，从 classpath 路径中找到一个名为 App.class 的二进制文件，将 App 的类信息加载到运行时数据区的方法区内，这个过程叫做 App 类的加载 JVM 找到 App 的主程序入口，执行main方法 这个main中的第一条语句为 Student student = new Student(&ldquo;tellUrDream&rdquo;) ，就是让 JVM 创建一个Student对象，但是这个时候方法区中是没有 Student 类的信息的，所以 JVM 马上加载 Student 类，把 Student 类的信息放到方法区中 加载完 Student 类后，JVM 在堆中为一个新的 Student 实例分配内存，然后调用构造函数初始化 Student 实例，这个 Student 实例持有 指向方法区中的 Student 类的类型信息 的引用 执行student.sayName();时，JVM 根据 student 的引用找到 student 对象，然后根据 student 对象持有的引用定位到方法区中 student 类的类型信息的方法表，获得 sayName() 的字节码地址。 执行sayName() 其实也不用管太多，只需要知道对象实例初始化时会去方法区中找类信息，完成后再到栈那里去运行方法。找方法就在方法表中找。
类加载器的介绍 之前也提到了它是负责加载.class文件的，它们在文件开头会有特定的文件标示，将class文件字节码内容加载到内存中，并将这些内容转换成方法区中的运行时数据结构，并且ClassLoader只负责class文件的加载，而是否能够运行则由 Execution Engine 来决定
类加载器的流程 从类被加载到虚拟机内存中开始，到释放内存总共有7个步骤：加载，验证，准备，解析，初始化，使用，卸载。其中验证，准备，解析三个部分统称为连接
加载 将class文件加载到内存 将静态数据结构转化成方法区中运行时的数据结构 在堆中生成一个代表这个类的 java.lang.Class对象作为数据访问的入口 连接 验证：确保加载的类符合 JVM 规范和安全，保证被校验类的方法在运行时不会做出危害虚拟机的事件，其实就是一个安全检查 准备：为static变量在方法区中分配内存空间，设置变量的初始值，例如 static int a = 3 （注意：准备阶段只设置类中的静态变量（方法区中），不包括实例变量（堆内存中），实例变量是对象初始化时赋值的） 解析：虚拟机将常量池内的符号引用替换为直接引用的过程（符号引用比如我现在import java.util.ArrayList这就算符号引用，直接引用就是指针或者对象地址，注意引用对象一定是在内存进行） 初始化 初始化其实就是一个赋值的操作，它会执行一个类构造器的()方法。由编译器自动收集类中所有变量的赋值动作，此时准备阶段时的那个 static int a = 3 的例子，在这个时候就正式赋值为3
卸载 GC将无用对象从内存中卸载
类加载器的加载顺序 加载一个Class类的顺序也是有优先级的，类加载器从最底层开始往上的顺序是这样的
BootStrap ClassLoader：rt.jar Extention ClassLoader: 加载扩展的jar包 App ClassLoader：指定的classpath下面的jar包 Custom ClassLoader：自定义的类加载器 双亲委派机制 当一个类收到了加载请求时，它是不会先自己去尝试加载的，而是委派给父类去完成，比如我现在要new一个Person，这个Person是我们自定义的类，如果我们要加载它，就会先委派App ClassLoader，只有当父类加载器都反馈自己无法完成这个请求（也就是父类加载器都没有找到加载所需的Class）时，子类加载器才会自行尝试加载
这样做的好处是，加载位于rt.jar包中的类时不管是哪个加载器加载，最终都会委托到BootStrap ClassLoader进行加载，这样保证了使用不同的类加载器得到的都是同一个结果。
其实这个也是一个隔离的作用，避免了我们的代码影响了JDK的代码，比如我现在要来一个
1 2 3 public class String(){ public static void main(){sout;} } 这种时候，我们的代码肯定会报错，因为在加载的时候其实是找到了rt.jar中的String.class，然后发现这也没有main方法
运行时数据区 本地方法栈和程序计数器 比如说我们现在点开Thread类的源码，会看到它的start0方法带有一个native关键字修饰，而且不存在方法体，这种用native修饰的方法就是本地方法，这是使用C来实现的，然后一般这些方法都会放到一个叫做本地方法栈的区域。
程序计数器其实就是一个指针，它指向了我们程序中下一句需要执行的指令，它也是内存区域中唯一一个不会出现OutOfMemoryError的区域，而且占用内存空间小到基本可以忽略不计。这个内存仅代表当前线程所执行的字节码的行号指示器，字节码解析器通过改变这个计数器的值选取下一条需要执行的字节码指令。
如果执行的是native方法，那这个指针就不工作了。
方法区 方法区主要的作用技术存放类的元数据信息，常量和静态变量···等。当它存储的信息过大时，会在无法满足内存分配时报错。
虚拟机栈和虚拟机堆 一句话便是：栈管运行，堆管存储。则虚拟机栈负责运行代码，而虚拟机堆负责存储数据。
虚拟机栈的概念 它是Java方法执行的内存模型。里面会对局部变量，动态链表，方法出口，栈的操作（入栈和出栈）进行存储，且线程独享。同时如果我们听到局部变量表，那也是在说虚拟机栈
1 2 3 4 5 6 7 public class Person{ int a = 1; public void doSomething(){ int b = 2; } } 虚拟机栈存在的异常 如果线程请求的栈的深度大于虚拟机栈的最大深度，就会报 StackOverflowError （这种错误经常出现在递归中）。Java虚拟机也可以动态扩展，但随着扩展会不断地申请内存，当无法申请足够内存时就会报错 OutOfMemoryError。
虚拟机栈的生命周期 对于栈来说，不存在垃圾回收。只要程序运行结束，栈的空间自然就会释放了。栈的生命周期和所处的线程是一致的。
这里补充一句：8种基本类型的变量+对象的引用变量+实例方法都是在栈里面分配内存。
虚拟机栈的执行 我们经常说的栈帧数据，说白了在JVM中叫栈帧，放到Java中其实就是方法，它也是存放在栈中的。
栈中的数据都是以栈帧的格式存在，它是一个关于方法和运行期数据的数据集。比如我们执行一个方法a，就会对应产生一个栈帧A1，然后A1会被压入栈中。同理方法b会有一个B1，方法c会有一个C1，等到这个线程执行完毕后，栈会先弹出C1，后B1,A1。它是一个先进后出，后进先出原则。
局部变量的复用 局部变量表用于存放方法参数和方法内部所定义的局部变量。它的容量是以Slot为最小单位，一个slot可以存放32位以内的数据类型。
虚拟机通过索引定位的方式使用局部变量表，范围为[0,局部变量表的slot的数量]。方法中的参数就会按一定顺序排列在这个局部变量表中，至于怎么排的我们可以先不关心。而为了节省栈帧空间，这些slot是可以复用的，当方法执行位置超过了某个变量，那么这个变量的slot可以被其它变量复用。当然如果需要复用，那我们的垃圾回收自然就不会去动这些内存。
虚拟机堆的概念 JVM内存会划分为堆内存和非堆内存，堆内存中也会划分为年轻代和老年代，而非堆内存则为永久代。年轻代又会分为Eden和Survivor区。Survivor也会分为FromPlace和ToPlace，toPlace的survivor区域是空的。Eden，FromPlace和ToPlace的默认占比为 8:1:1。当然这个东西其实也可以通过一个 -XX:+UsePSAdaptiveSurvivorSizePolicy 参数来根据生成对象的速率动态调整
堆内存中存放的是对象，垃圾收集就是收集这些对象然后交给GC算法进行回收。非堆内存其实我们已经说过了，就是方法区。在1.8中已经移除永久代，替代品是一个元空间(MetaSpace)，最大区别是metaSpace是不存在于JVM中的，它使用的是本地内存。并有两个参数
1 2 MetaspaceSize：初始化元空间大小，控制发生GC MaxMetaspaceSize：限制元空间大小上限，防止占用过多物理内存。 移除的原因可以大致了解一下：融合HotSpot JVM和JRockit VM而做出的改变，因为JRockit是没有永久代的，不过这也间接性地解决了永久代的OOM问题。
Eden年轻代的介绍 当我们new一个对象后，会先放到Eden划分出来的一块作为存储空间的内存，但是我们知道对堆内存是线程共享的，所以有可能会出现两个对象共用一个内存的情况。这里JVM的处理是每个线程都会预先申请好一块连续的内存空间并规定了对象存放的位置，而如果空间不足会再申请多块内存空间。这个操作我们会称作TLAB，有兴趣可以了解一下。
当Eden空间满了之后，会触发一个叫做Minor GC（就是一个发生在年轻代的GC）的操作，存活下来的对象移动到Survivor0区。Survivor0区满后触发 Minor GC，就会将存活对象移动到Survivor1区，此时还会把from和to两个指针交换，这样保证了一段时间内总有一个survivor区为空且to所指向的survivor区为空。经过多次的 Minor GC后仍然存活的对象（这里的存活判断是15次，对应到虚拟机参数为 -XX:MaxTenuringThreshold 。为什么是15，因为HotSpot会在对象投中的标记字段里记录年龄，分配到的空间仅有4位，所以最多只能记录到15）会移动到老年代。老年代是存储长期存活的对象的，占满时就会触发我们最常听说的Full GC，期间会停止所有线程等待GC的完成。所以对于响应要求高的应用应该尽量去减少发生Full GC从而避免响应超时的问题。
而且当老年区执行了full gc之后仍然无法进行对象保存的操作，就会产生OOM，这时候就是虚拟机中的堆内存不足，原因可能会是堆内存设置的大小过小，这个可以通过参数-Xms、-Xmx来调整。也可能是代码中创建的对象大且多，而且它们一直在被引用从而长时间垃圾收集无法收集它们。 如何判断一个对象需要被干掉 图中程序计数器、虚拟机栈、本地方法栈，3个区域随着线程的生存而生存的。内存分配和回收都是确定的。随着线程的结束内存自然就被回收了，因此不需要考虑垃圾回收的问题。而Java堆和方法区则不一样，各线程共享，内存的分配和回收都是动态的。因此垃圾收集器所关注的都是堆和方法这部分内存。
在进行回收前就要判断哪些对象还存活，哪些已经死去。下面介绍两个基础的计算方法
1.引用计数器计算：给对象添加一个引用计数器，每次引用这个对象时计数器加一，引用失效时减一，计数器等于0时就是不会再次使用的。不过这个方法有一种情况就是出现对象的循环引用时GC没法回收。
2.可达性分析计算：这是一种类似于二叉树的实现，将一系列的GC ROOTS作为起始的存活对象集，从这个节点往下搜索，搜索所走过的路径成为引用链，把能被该集合引用到的对象加入到集合中。搜索当一个对象到GC Roots没有使用任何引用链时，则说明该对象是不可用的。主流的商用程序语言，例如Java，C#等都是靠这招去判定对象是否存活的。
（了解一下即可）在Java语言汇总能作为GC Roots的对象分为以下几种：
虚拟机栈（栈帧中的本地方法表）中引用的对象（局部变量） 方法区中静态变量所引用的对象（静态变量） 方法区中常量引用的对象 本地方法栈（即native修饰的方法）中JNI引用的对象（JNI是Java虚拟机调用对应的C函数的方式，通过JNI函数也可以创建新的Java对象。且JNI对于对象的局部引用或者全局引用都会把它们指向的对象都标记为不可回收） 已启动的且未终止的Java线程 这种方法的优点是能够解决循环引用的问题，可它的实现需要耗费大量资源和时间，也需要GC（它的分析过程引用关系不能发生变化，所以需要停止所有进程）
如何宣告一个对象的真正死亡 首先必须要提到的是一个名叫 finalize() 的方法
finalize()是Object类的一个方法、一个对象的finalize()方法只会被系统自动调用一次，经过finalize()方法逃脱死亡的对象，第二次不会再调用。
补充一句：并不提倡在程序中调用finalize()来进行自救。建议忘掉Java程序中该方法的存在。因为它执行的时间不确定，甚至是否被执行也不确定（Java程序的不正常退出），而且运行代价高昂，无法保证各个对象的调用顺序（甚至有不同线程中调用）。在Java9中已经被标记为 deprecated ，且java.lang.ref.Cleaner（也就是强、软、弱、幻象引用的那一套）中已经逐步替换掉它，会比finalize来的更加的轻量及可靠。
判断一个对象的死亡至少需要两次标记
如果对象进行可达性分析之后没发现与GC Roots相连的引用链，那它将会第一次标记并且进行一次筛选。判断的条件是决定这个对象是否有必要执行finalize()方法。如果对象有必要执行finalize()方法，则被放入F-Queue队列中。 GC对F-Queue队列中的对象进行二次标记。如果对象在finalize()方法中重新与引用链上的任何一个对象建立了关联，那么二次标记时则会将它移出“即将回收”集合。如果此时对象还没成功逃脱，那么只能被回收了。 如果确定对象已经死亡，我们又该如何回收这些垃圾呢
垃圾回收算法 不会非常详细的展开，常用的有标记清除，复制，标记整理和分代收集算法
标记清除算法 标记清除算法就是分为“标记”和“清除”两个阶段。标记出所有需要回收的对象，标记结束后统一回收。这个套路很简单，也存在不足，后续的算法都是根据这个基础来加以改进的。
其实它就是把已死亡的对象标记为空闲内存，然后记录在一个空闲列表中，当我们需要new一个对象时，内存管理模块会从空闲列表中寻找空闲的内存来分给新的对象。
不足的方面就是标记和清除的效率比较低下。且这种做法会让内存中的碎片非常多。这个导致了如果我们需要使用到较大的内存块时，无法分配到足够的连续内存。比如下图 此时可使用的内存块都是零零散散的，导致了刚刚提到的大内存对象问题
复制算法 为了解决效率问题，复制算法就出现了。它将可用内存按容量划分成两等分，每次只使用其中的一块。和survivor一样也是用from和to两个指针这样的玩法。fromPlace存满了，就把存活的对象copy到另一块toPlace上，然后交换指针的内容。这样就解决了碎片的问题。
这个算法的代价就是把内存缩水了，这样堆内存的使用效率就会变得十分低下了 不过它们分配的时候也不是按照1:1这样进行分配的，就类似于Eden和Survivor也不是等价分配是一个道理。
标记整理算法 复制算法在对象存活率高的时候会有一定的效率问题，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存 分代收集算法 这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或者“标记-整理”算法来进行回收。
说白了就是八仙过海各显神通，具体问题具体分析了而已。
各种各样的垃圾回收器 HotSpot VM中的垃圾回收器，以及适用场景 到jdk8为止，默认的垃圾收集器是Parallel Scavenge 和 Parallel Old
从jdk9开始，G1收集器成为默认的垃圾收集器 目前来看，G1回收器停顿时间最短而且没有明显缺点，非常适合Web应用。在jdk8中测试Web应用，堆内存6G，新生代4.5G的情况下，Parallel Scavenge 回收新生代停顿长达1.5秒。G1回收器回收同样大小的新生代只停顿0.2秒。
JVM的常用参数 JVM的参数非常之多，这里只列举比较重要的几个，通过各种各样的搜索引擎也可以得知这些信息。
参数名称 含义 默认值 说明 -Xms 初始堆大小 物理内存的1/64(&lt;1GB) 默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制. -Xmx 最大堆大小 物理内存的1/4(&lt;1GB) 默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 -Xmn 年轻代大小(1.4or lator) 注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。整个堆大小=年轻代大小 + 老年代大小 + 持久代（永久代）大小.增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8 -XX:NewSize 设置年轻代大小(for 1.3/1.4) -XX:MaxNewSize 年轻代最大值(for 1.3/1.4) -XX:PermSize 设置持久代(perm gen)初始值 物理内存的1/64 -XX:MaxPermSize 设置持久代最大值 物理内存的1/4 -Xss 每个线程的堆栈大小 JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.更具应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:-Xss is translated in a VM flag named ThreadStackSize”一般设置这个值就可以了 -XX:NewRatio 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) -XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。 -XX:SurvivorRatio Eden区与Survivor区的大小比值 设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10 -XX:+DisableExplicitGC 关闭System.gc() 这个参数需要严格的测试 -XX:PretenureSizeThreshold 对象超过多大是直接在旧生代分配 0 单位字节 新生代采用Parallel ScavengeGC时无效另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象. -XX:ParallelGCThreads 并行收集器的线程数 此值最好配置与处理器数目相等 同样适用于CMS -XX:MaxGCPauseMillis 每次年轻代垃圾回收的最长时间(最大暂停时间) 如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值. 其实还有一些打印及CMS方面的参数，这里就不以一一列举了
关于JVM调优的一些方面 根据刚刚涉及的jvm的知识点，我们可以尝试对JVM进行调优，主要就是堆内存那块
所有线程共享数据区大小=新生代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m。所以java堆中增大年轻代后，将会减小年老代大小（因为老年代的清理是使用fullgc，所以老年代过小的话反而是会增多fullgc的）。此值对系统性能影响较大，Sun官方推荐配置为java堆的3/8。
调整最大堆内存和最小堆内存 -Xmx –Xms：指定java堆最大值（默认值是物理内存的1/4(&lt;1GB)）和初始java堆最小值（默认值是物理内存的1/64(&lt;1GB))
默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制.，默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制。简单点来说，你不停地往堆内存里面丢数据，等它剩余大小小于40%了，JVM就会动态申请内存空间不过会小于-Xmx，如果剩余大小大于70%，又会动态缩小不过不会小于–Xms。就这么简单
开发过程中，通常会将 -Xms 与 -Xmx两个参数的配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。
我们执行下面的代码
1 2 3 System.out.println("Xmx=" + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + "M"); //系统的最大空间 System.out.println("free mem=" + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + "M"); //系统的空闲空间 System.out.println("total mem=" + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + "M"); //当前可用的总空间 注意：此处设置的是Java堆大小，也就是新生代大小 + 老年代大小 设置一个VM options的参数
1 -Xmx20m -Xms5m -XX:+PrintGCDetails 再次启动main方法 这里GC弹出了一个Allocation Failure分配失败，这个事情发生在PSYoungGen，也就是年轻代中
这时候申请到的内存为18M，空闲内存为4.214195251464844M
我们此时创建一个字节数组看看，执行下面的代码
1 2 3 4 byte[] b = new byte[1 * 1024 * 1024];System.out.println("分配了1M空间给数组"); System.out.println("Xmx=" + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + "M"); //系统的最大空间 System.out.println("free mem=" + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + "M"); //系统的空闲空间 System.out.println("total mem=" + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + "M"); 此时free memory就又缩水了，不过total memory是没有变化的。Java会尽可能将total mem的值维持在最小堆内存大小
1 2 3 4 byte[] b = new byte[10 * 1024 * 1024];System.out.println("分配了10M空间给数组"); System.out.println("Xmx=" + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + "M"); //系统的最大空间 System.out.println("free mem=" + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + "M"); //系统的空闲空间 System.out.println("total mem=" + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + "M"); //当前可用的总空间 这时候我们创建了一个10M的字节数据，这时候最小堆内存是顶不住的。我们会发现现在的total memory已经变成了15M，这就是已经申请了一次内存的结果。
此时我们再跑一下这个代码
1 2 3 4 System.gc(); System.out.println("Xmx=" + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + "M"); //系统的最大空间 System.out.println("free mem=" + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + "M"); //系统的空闲空间 System.out.println("total mem=" + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + "M"); //当前可用的总空间 此时我们手动执行了一次fullgc，此时total memory的内存空间又变回5.5M了，此时又是把申请的内存释放掉的结果。
调整新生代和老年代的比值 -XX:NewRatio &mdash; 新生代（eden+2*Survivor）和老年代（不包含永久区）的比值
例如：-XX:NewRatio=4，表示新生代:老年代=1:4，即新生代占整个堆的1/5。在Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。
调整Survivor区和Eden区的比值 -XX:SurvivorRatio（幸存代）&mdash; 设置两个Survivor区和eden的比值
例如：8，表示两个Survivor:eden=2:8，即一个Survivor占年轻代的1/10
设置年轻代和老年代的大小 -XX:NewSize &mdash; 设置年轻代大小
-XX:MaxNewSize &mdash; 设置年轻代最大值
可以通过设置不同参数来测试不同的情况，反正最优解当然就是官方的Eden和Survivor的占比为8:1:1，然后在刚刚介绍这些参数的时候都已经附带了一些说明，感兴趣的也可以看看。反正最大堆内存和最小堆内存如果数值不同会导致多次的gc，需要注意。
小总结 根据实际事情调整新生代和幸存代的大小，官方推荐新生代占java堆的3/8，幸存代占新生代的1/10
在OOM时，记得Dump出堆，确保可以排查现场问题，通过下面命令你可以输出一个.dump文件，这个文件可以使用VisualVM或者Java自带的Java VisualVM工具。
1 -Xmx20m -Xms5m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=你要输出的日志路径 一般我们也可以通过编写脚本的方式来让OOM出现时给我们报个信，可以通过发送邮件或者重启程序等来解决。
永久区的设置 1 -XX:PermSize -XX:MaxPermSize 初始空间（默认为物理内存的1/64）和最大空间（默认为物理内存的1/4）。也就是说，jvm启动时，永久区一开始就占用了PermSize大小的空间，如果空间还不够，可以继续扩展，但是不能超过MaxPermSize，否则会OOM。
tips：如果堆空间没有用完也抛出了OOM，有可能是永久区导致的。堆空间实际占用非常少，但是永久区溢出 一样抛出OOM。
JVM的栈参数调优 调整每个线程栈空间的大小 可以通过-Xss：调整每个线程栈空间的大小
JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。在相同物理内存下,减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右
设置线程栈的大小 1 -XXThreadStackSize： 设置线程栈的大小(0 means use default stack size) 这些参数都是可以通过自己编写程序去简单测试的，这里碍于篇幅问题就不再提供demo了
JVM其他参数介绍 形形色色的参数很多，就不会说把所有都扯个遍了，因为大家其实也不会说一定要去深究到底。
设置内存页的大小 1 -XXThreadStackSize： 设置内存页的大小，不可设置过大，会影响Perm的大小复制代码 设置原始类型的快速优化 1 -XX:+UseFastAccessorMethods： 设置原始类型的快速优化 设置关闭手动GC 1 -XX:+DisableExplicitGC： 设置关闭System.gc()(这个参数需要严格的测试) 设置垃圾最大年龄 1 2 3 4 5 -XX:MaxTenuringThreshold 设置垃圾最大年龄。如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率。如果将此值设置为一个较大值, 则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活时间, 增加在年轻代即被回收的概率。该参数只有在串行GC时才有效. 加快编译速度 1 -XX:+AggressiveOpts 加快编译速度
改善锁机制性能 1 -XX:+UseBiasedLocking 禁用垃圾回收 1 -Xnoclassgc 设置堆空间存活时间 1 -XX:SoftRefLRUPolicyMSPerMB 设置每兆堆空闲空间中SoftReference的存活时间，默认值是1s。 设置对象直接分配在老年代 1 -XX:PretenureSizeThreshold 设置对象超过多大时直接在老年代分配，默认值是0。 设置TLAB占eden区的比例 1 -XX:TLABWasteTargetPercent 设置TLAB占eden区的百分比，默认值是1% 。 设置是否优先YGC 1 -XX:+CollectGen0First 设置FullGC时是否先YGC，默认值是false。</content></entry><entry><title/><url>https://xshrim.github.io/post/Kubernetes%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E8%AF%A6%E8%A7%A3/</url><categories/><tags/><content type="html"> Kubernetes网络插件详解 VxLan 解读VXLAN 起源-Origin 传统的交换网络解决了二层的互通及隔离问题，这个架构发展了几十年已经相当成熟。而随着云时代的到来，却渐渐暴露出了一些主要的缺点。
多租户环境和虚拟机迁移
为了满足在云网络中海量虚拟机迁移前后业务不中断的需要，要求虚拟机迁移前后的IP不能变化，继而要求网络必须是大二层结构。传统的二层网络技术，在链路使用率、收敛时间等方面都不能满足需要。
VLAN的局限
随着云业务的运营，租户数量剧增。传统交换网络用VLAN来隔离用户和虚拟机，但理论上只支持最多4K个标签的VLAN，已无法满足需求。
竞争-Competition 为了解决上述局限性，不论是网络设备厂商，还是虚拟化软件厂商，都提出了一些新的Overlay解决方案。
网络设备厂商，基于硬件设备开发出了EVI（Ethernet Virtualization Interconnect）、TRILL（Transparent Interconnection of Lots of Links)、SPB（Shortest Path Bridging）等大二层技术。这些技术通过网络边缘设备对流量进行封装/解封装，构造一个逻辑的二层拓扑，同时对链路充分利用、表项资源分担、多租户等问题采取各自的解决方法。此类技术一般要求网络边缘设备必须支持相应的协议，优点是硬件设备表项容量大、转发速度快。
虚拟化软件厂商，从自身出发，提出了VXLAN（Virtual eXtensible LAN）、NVGRE（Network Virtualization Using Generic Routing Encapsulation）、STT（A Stateless Transport Tunneling Protocol for Network Virtualization）等一系列技术。这部分技术利用主机上的虚拟交换机（vSwitch）作为网络边缘设备，对流量进行封装/解封装。优点是对网络硬件设备没有过多要求。
通过下表我们可以看到这几种Overlay技术对比。 其中，虚拟化软件厂商提出的Overlay技术由于天然支持vSwitch，在云计算网络中更有优势。
通过下表可以看到VXLAN、NVGRE、STT这三种技术的区别。 与NVGRE相比，VXLAN不需要改变报文结构即可支持L2~L4的链路负载均衡；与STT相比，VXLAN不需要修改传输层结构，与传统网络设备完美兼容。由此，VXLAN脱颖而出，成为了SDN环境下的主流Overlay技术。
VXLAN是由IETF定义的NVO3（Network Virtualization over Layer 3）标准技术之一，采用MAC-in-UDP的报文封装模式，可实现二层网络在三层范围内进行扩展，满足数据中心大二层虚拟机迁移的需求。在VXLAN网络中，属于相同VXLAN的虚拟机处于同一个逻辑二层网络，彼此之间二层互通；属于不同VXLAN的虚拟机之间二层隔离。
VXLAN最初只在虚拟交换机实现，但虚拟交换机天然具有转发性能低下的缺点，并不适合大流量的网络环境。于是，各硬件厂商也纷纷推出支持VXLAN的硬件产品，与虚拟交换机一起，共同成为网络边缘设备，最终使VXLAN技术能够适应各种网络。
数据平面-Data Plane VXLAN基本概念 VNI（VXLAN Network Identifier，VXLAN网络标识符）
VXLAN通过VXLAN ID来标识，其长度为24比特。VXLAN 16M个标签数解决了VLAN标签不足的缺点。
VTEP（VXLAN Tunnel End Point，VXLAN隧道端点）
VXLAN的边缘设备。VXLAN的相关处理都在VTEP上进行，例如识别以太网数据帧所属的VXLAN、基于VXLAN对数据帧进行二层转发、封装/解封装报文等。VTEP可以是一台独立的物理设备，也可以是虚拟机所在服务器的虚拟交换机。
VXLAN Tunnel
两个VTEP之间点到点的逻辑隧道。VTEP为数据帧封装VXLAN头、UDP头、IP头后，通过VXLAN隧道将封装后的报文转发给远端VTEP，远端VTEP对其进行解封装。
VSI（irtual Switching Instance，虚拟交换实例）
VTEP上为一个VXLAN提供二层交换服务的虚拟交换实例。VSI可以看作是VTEP上的一台基于VXLAN进行二层转发的虚拟交换机，它具有传统以太网交换机的所有功能，包括源MAC地址学习、MAC地址老化、泛洪等。VSI与VXLAN一一对应。
VSI-Interface（VSI的虚拟三层接口）
类似于Vlan-Interface，用来处理跨VNI即跨VXLAN的流量。VSI-Interface与VSI一一对应，在没有跨VNI流量时可以没有VSI-Interface。
现有VTEP设备中，一般用“接口+VLAN”的方式来区分流量与VSI的对应关系，而VSI与VXLAN Tunnel之间既可以建立全连接，也可以根据需求进行关联。
VXLAN帧格式 RFC7348封装 RFC7348规定了VXLAN报文的格式：
Outer MAC Header
封装外层以太头，14字节，如果有VLAN TAG则为18字节。其中，源MAC地址（Outer Source MAC Address）为源VM所属VTEP的MAC地址，目的MAC地址（Outer Destination MAC Address）为到达目的VTEP的路径上下一跳设备的MAC地址。类型字段为0x0800，指示内层封装的是IP报文。
Outer IP Header
封装外层IP头，20字节。其中，源IP地址（Outer Source IP Address）为源VM所属VTEP的IP地址，目的IP地址（Outer Destination IP Address）为目的VM所属VTEP的IP地址。协议字段为0x11，指示内层封装的是UDP报文。
UDP Header
UDP报文头，8字节。其中，UDP目的端口号（UDP Destination Port）固定为4789，指示内层封装报文为VXLAN报文。UDP源端口号（UDP Source Port）为随机任意值，可以用于VTEP之间多路径负载分担的计算。
VXLAN Header
VXLAN协议新定义的VXLAN头，8字节。
Flags
8 bit，RRRRIRRR。“I”位为1时，表示VXLAN头中的VXLAN ID有效；为0，表示VXLAN ID无效。“R”位保留未用，设置为0。
VXLAN ID(VNI)
24 bit，用于标识一个单独的VXLAN网络。
Reserved
分别为24 bit和8 bit。保留位。
Original L2 Frame
原始以太网报文。
从报文的封装可以看出，VXLAN头和原始二层报文是作为UDP报文的载荷存在的。在VTEP之间的网络设备，只需要根据Outer MAC Header和Outer IP Header进行转发，利用UDP Source Port进行负载分担，这一过程，与转发普通的IP报文完全相同。这样，除了VTEP设备，现网的大量设备无需更换或升级即可支持VXLAN网络。
不过，新增加的VXLAN报文封装也引入了一个问题，即MTU值的设置。
一般来说，虚拟机的默认MTU为1500 Bytes，也就是说原始以太网报文最大为1500字节。这个报文在经过VTEP时，会封装上50字节的新报文头（VXLAN头8字节+UDP头8字节+外部IP头20字节+外部MAC头14字节），这样一来，整个报文长度达到了1550字节。而现有的VTEP设备，一般在解封装VXLAN报文时，要求VXLAN报文不能被分片，否则无法正确解封装。这就要求VTEP之间的所有网络设备的MTU最小为 1550字节。
如果中间设备的MTU值不方便进行更改，那么设置虚拟机的MTU值为1450，也可以暂时解决这个问题。
VXLAN GPE封装 RFC7348中规定的VXLAN内部的载荷报文必须是以太网报文，这就限制了VXLAN协议的使用范围。为了让VXLAN能够更广泛的支持其他协议报文的Overlay传输，RFC草案正在探索VXLAN Generic Protocol Encapsulation （GPE）即VXLAN通用协议封装。
GPE封装使用了原FRC7348中规定的一些保留位。
Version(Ver)：指示VXLAN GPE协议版本。初始值为0。
Next Protocol Bit (P bit)：如果P位为1，则Next Protocol域有效。
BUM Traffic Bit (B bit)： 如果B位为1，则表示VXLAN内部的封装报文为BUM报文。
OAM Flag Bit (O bit)：如果O位为1，则表示VXLAN内部的封装报文为OAM报文。
Next Protocol：8位。表示VXLAN内部的封装报文的协议格式。
VXLAN的GPE封装还处于草案阶段，读者只需要了解VXLAN协议还在不断的发展中，暂时不必深究GPE封装的格式和应用。
BUM报文转发 BUM（Broadcast, Unknown-unicast, Multicast）即广播、未知单播、组播流量。根据对泛洪流量的复制方式不同可分为单播路由方式（头端复制）和组播路由方式（核心复制）两种。
单播路由方式泛洪（头端复制） 在头端复制方式下，VTEP负责复制报文，采用单播方式将复制后的报文通过本地接口发送给本地站点，并通过VXLAN隧道发送给VXLAN内的所有远端VTEP。
如图5所示，当VTEP 1上的VM 1发出BUM报文后，VTEP 1判断数据所属的VXLAN，通过该VXLAN内所有本地接口和VXLAN Tunnel转发报文。通过VXLAN Tunnel转发报文时，封装VXLAN头、UDP头和IP头，将泛洪报文封装于单播报文中，发送到VXLAN内的所有远端VTEP。
远端VTEP收到VXLAN报文后，解封装报文，将原始数据在本地站点的VXLAN内泛洪。为避免环路，远端VTEP从VXLAN隧道上接收到报文后，不会再将其泛洪到其他的VXLAN隧道。
组播路由方式泛洪（核心复制） 组播路由方式的组网中同一个VXLAN内的所有VTEP都加入同一个组播组，利用组播路由协议（如PIM）在IP网络上为该组播建立组播转发表项，VTEP上相应生成一个组播隧道。
如图所示，当VTEP 1上的VM 1发出BUM报文后，VTEP 1不仅在本地站点内泛洪，还会为其封装组播目的IP地址，封装后的报文根据已建立的组播转发表项转发到IP网络。
在组播报文到达IP网络中的中间设备时，该设备根据已建立的组播表项对报文进行复制并转发。
远端VTEP（VTEP 2和VTEP 3）接收到报文后，解封装报文，将原始的数据帧在本地站点的指定VXLAN泛洪。为了避免环路，远端VTEP从VXLAN隧道上接收到报文后，不会再将其泛洪到其他的VXLAN隧道。
由于泛洪流量使用了组播技术，所以整个组网中的网络设备需要支持组播路由协议（如PIM等）来建立组播路径以便组播报文转发。
单播报文转发流程 下面，我们用实际的例子帮助大家理解VXLAN是如何完成报文转发的，其中，BUM报文采用头端复制的方法进行泛洪。
同VNI单播报文转发流程 ARP请求报文转发流程
VM 1与VM3的IP地址在同一网段。VM 1想要与VM 3进行通信，但发现没有VM 3的MAC地址，于是发起VM 3的ARP请求报文。ARP请求报文的源IP是VM 1的IP，目的IP是VM 3的IP，源MAC是VM 1的MAC，目的MAC则是全0字段，表示希望获得VM 3的MAC信息。外层封装以太网头，其中目的MAC为全F，表示这是一个广播报文。
Leaf A收到了VM 1发来的ARP请求报文，根据其入端口和VLAN信息，判断出这个报文应该匹配VXLAN 10。将VXLAN、MAC、入端口和VLAN信息写入相应的VSI MAC表中。
Leaf A发现ARP请求报文是一个广播报文，于是将这个报文在本地和远端所有VXLAN 10的端口进行广播。由于本流程广播采用头端复制的方法，Leaf A将给Leaf B和Spine C各发送一份VXLAN报文。Leaf A发送给Leaf B的报文，最外层是以太网头，接着是IP头，其中源IP是Leaf A的IP，目的IP是Leaf B的IP。再往内是UDP头和VXLAN头，其中VNI为10。最内层是VM 1的ARP请求报文。Leaf A发给Spine C的报文封装相同，不同之处在于外层目的IP是Spine C的IP，外层目的MAC根据下一跳不同而不同。
Spine C收到Leaf A发来的报文，发现外层目的IP是自己，于是将其解封装。发现UDP的目的端口是4789，于是将UDP的上层报文进行VXLAN解封装处理。根据VXLAN报文的信息，将VXLAN、内部MAC、入端口等信息写入相应的VSI MAC表中。再发现内部原始二层报文是一个广播报文，根据水平分割的要求，不再往其他VTEP设备转发，只在本地的VXLAN 10端口内进行广播。由于Spine C上没有连接服务器，所以Spine C对这个报文不再进行后续处理，予以丢弃。
同样的，Leaf B也收到Leaf A发来的报文，解封装后，将VXLAN、内部MAC、入端口等信息写入相应的VSI MAC表中。由于报文是从Tunnel 1中收到的，所以端口信息为Tunnel 1。根据VXLAN 10的映射关系表，将原始二层报文在本地所有VXLAN 10端口进行广播.
最终VM 3收到了VM 1的ARP请求报文，将VM 1的IP和MAC对应关系写入自己的ARP表项，准备进行ARP应答。
ARP应答报文转发流程
VM 3给VM 1发送ARP应答报文。ARP应答报文的源IP是VM 3的IP，目的IP是VM 1的IP，源MAC是VM 3的MAC，目的MAC是VM 1的MAC。外层封装以太网头，源MAC是VM 3的MAC，目的MAC是VM 1的MAC，表示这是一个单播报文。
Leaf B收到VM3发来的ARP应答报文，根据其入端口和VLAN信息，判断出这个报文应该匹配VXLAN 10。将VXLAN、MAC、入端口和VLAN信息写入相应的VSI MAC表中。
Leaf B发现ARP应答报文是一个单播报文，其目的MAC是MAC 1，于是在VXLAN 10中查找。发现MAC 1的条目存在，其对应的端口为VXLAN Tunnel 1，于是把原始报文进行VXLAN封装。最外层是以太网头，接着是IP头，其中源IP是Leaf B的IP，目的IP是Leaf A的IP。再往内是UDP头和VXLAN头，其中VNI为10。最内层是VM 3的ARP应答报文。
Leaf A收到Leaf B发来的报文，发现外层目的IP是自己，于是将其解封装。发现UDP的目的IP是4789，于是将UDP的上层报文进行VXLAN解封装处理。根据VXLAN报文的信息，将VXLAN、内部MAC、入端口等信息写入相应的VSI MAC表中。发现原始二层报文的目的MAC为MAC 1，于是在VXLAN 10中查找，找到MAC 1的对应表项，将报文从对应端口发送出去。
VM 1收到了VM 3的ARP应答报文，将VM 3的IP和MAC写入ARP表项中，完成了此次ARP的学习。
同VNI单播报文转发流程
在进行ARP报文的交互后，VM 1上已经存在VM 3的ARP表项，VM 3上也有VM 1的ARP表项。之后，VM 1和VM 3的通信就走单播报文转发流程了。
VM 1将发给VM 3的单播报文发送出去。Leaf A收到VM 1发来的报文，发现其目的MAC为MAC 3，在VXLAN 10中查找到MAC 3后，进行VXLAN封装后通过Tunnel 1发送出去。
Leaf B收到Leaf A发来的报文，解封装后在VXLAN 10中找到MAC 3表项，将其在对应的本地端口和VLAN中发出去。
VM 3收到报文后，往VM 1发送单播报文的流程相同，在此不再赘述。
跨VNI单播报文转发 跨VNI的流量需要经过VXLAN L3 Gateway（VXLAN L3 Gateway用于转发跨VXLAN的流量，后文有详细介绍）来转发，这里采用集中式网关的模式进行说明。有关集中式网关和分布式网关的内容，在后文中会说明。
由于是首次进行通信，且VM 1和VM 4处于不同网段。VM 1的网关VSI-Interface 10的IP为IP G10，MAC为MAC G10；VM4的网关VSI-Interface 20的IP为IP G20，MAC为MAC　G20；VSI-interface 10 和VSI-interface 20均在Spine C上。VM 1需要先发送ARP广播报文请求网关（VSI-Interface 10）的MAC，获得网关的MAC后，VM 1先将数据报文发送给网关；之后网关也将发送ARP广播报文请求VM 4的MAC，获得VM 4的MAC后，网关再将数据报文发送给VM 4。以上MAC地址学习的过程与同子网互通中MAC地址学习的流程一致，不再赘述。现在假设VM 1和VM 4均已学到网关的MAC、网关也已经学到VM 1和VM 4的MAC，下面就让我们来看下数据报文是如何从VM 1发送到VM 4的。
VM 1先将报文发送给网关。报文的源MAC是VM 1的MAC，目的MAC是网关VSI-Interface 10的MAC，源IP是VM 1的IP，目的IP是VM 4的IP。
Leaf A收到VM 1发来的报文，识别此报文属于VXLAN 10，查找目的MAC G10的表项，就报文进行VXLAN封装后从Tunnel 2发送出去。其中，VXLAN头中的VNI为10；外层源IP地址为Leaf A的IP，外层目的IP地址为Spine C的IP；外层源MAC地址为Leaf A的MAC，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。
Spine C收到Leaf A发来的报文，发现外层目的IP是自己，于是对报文进行解封装。解完封装后，Spine C发现原始二层报文的目的MAC为本机VSI-interface 10的MAC，目的IP是IP4，于是根据路由表查找IP 4的下一跳。发现一下跳为Leaf B，出接口为VSI-Interface 20。再查询ARP表项，并将原始二层报文的源MAC修改为VSI-interface 20的MAC，将目的MAC修改为VM 4的MAC。报文到达VSI-interface 20接口时，识别到需要进入VXLAN 20隧道，所以根据MAC表对报文进行封装。这里封装的VXLAN头中的VNI为20，外层源IP地址为Spine C的IP地址，外层目的IP地址为Leaf B的IP地址；外层源MAC地址为Spine C的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。
Leaf B收到Spine C发来的报文后，解封装，得到原始二层报文。在VXLAN 20内找到目的MAC为MAC 4的表项，并将报文从对应的接口和VLAN中发送出去。最终VM 4收到了来自VM 1的报文。
VM 4发送给VM 1的过程与此类似，在此不再赘述。
VXLAN三层网关-L3 Gateway VXLAN三层网关提供了VXLAN的三层转发功能，通过将VXLAN关联VSI虚接口（VXLAN虚接口）的方式实现，在VSI虚接口指定IP地址作为VXLAN内所有虚拟机的网关。
VXLAN三层网关的主要功能：
实现VXLAN内虚拟机与非VXLAN网络的互访
完成跨VXLAN的虚拟机互访
VXLAN三层网关根据其部署方式不同，有集中式和分布式两种。
集中式三层网关 集中式网关，即网关都集中在Spine设备。如图10所示，VSI-interface 10和VSI-interface 20都在Spine C设备上。所有跨VXLAN的流量，VXLAN与非VXLAN的互访流量都需要经过Spine。如图10中VM 1访问VM 4时，需要通过Spine设备，并经过两段VXLAN Tunnel，即VXLAN Tunnel 2和VXLAN Tunnel 3。而VM 1访问VM 2，也需要绕行Spine设备，同样需要历经从A到C和从C到A两次VXLAN封装。
集中式网关的优点是流量均会经过Spine设备，能比较容易实现流量控制、自动引流等功能。缺点是Spine设备压力过大，不利于大规模部署。
分布式三层网关 在分布式VXLAN 三层网关方案中，每台VTEP设备都可以作为VXLAN IP网关，对本地站点的流量进行三层转发。分布式三层网关可以很好地解决流量集中而导致Spine设备压力过大的问题，在组网上也可以做到灵活扩展。
在分布式网关组网中，Spine设备一般不是VTEP，仅为Underlay网络的一部分，承担普通IP报文的转发功能。
VXLAN的三层网关分布在所有的Leaf设备上。如图12，Leaf A和Leaf B上均有相同的VSI-Interface。VM 1访问VM 4为跨网段通信，VXLAN流量只需要在Leaf A和Leaf B之间直接交互，而不用Spine设备参与。VM 1访问VM 2也是跨网段通信，由于VM 1和VM 2都直连在Leaf A下，VXLAN流量甚至不用出Leaf A就能完成互访。由此，我们能看出，分布式网关的部署方式大大减少了Spine设备的压力。
4.3 ARP抑制 ARP流量是数据网络中最常见的BUM报文。为了尽量减少ARP广播对带宽的影响，一般会在VXLAN网络中开启ARP抑制功能。
ARP抑制方法有两种，我们称之为ARP代理和ARP代答。
ARP代理 在ARP代理模式中，VTEP设备会用网关自身的MAC地址进行回应ARP请求。
VM 1想要和同网段的VM 3进行通信，于是VM 1发起了ARP请求寻找VM 3的MAC。
Leaf A开启了ARP代理模式，于是将VSI-Interface 10的MAC回应给VM 1，VM 1上生成了IP 3和MAC G10对应的ARP表项。
Leaf A若是没有VM 3的ARP表项，则会在VXLAN中的所有本地和远端端口广播。Leaf A将ARP请求报文的源MAC地址修改成本地地址MAC A，再封装成VXLAN报文发送出去。
Leaf B收到Leaf A发来的报文，解封装后，将IP 1与MAC A的对应关系写进表项。发现请求的是本地直连网段的ARP，于是将ARP请求报文中的源MAC地址修改成本地VSI-Interface 10的MAC，发送出去。
VM 3收到Leaf B发来的ARP请求报文，将IP 1和MAC G10的对应关系写进自己的ARP表。然后开始回送ARP应答报文，一路回送，最终Leaf A学到了IP 3与MAC B的对应表项。
VM 1发送数据报文给VM 3，目的MAC地址为Leaf A上的网关MAC。Leaf A收到报文后，发现目的MAC地址是VSI-interface 10的MAC，于是进行三层查表转发。找到IP 3对应的表项，将目的MAC改为Leaf B的MAC后，再把报文进行VXLAN封装发送给Leaf B。
Leaf B解封装VXLAN报文后，发现目的MAC是自己，于是进行三层查表转发。找到IP 3对应的表项，将目的MAC改为VM 3的MAC后，发送给VM 3。VM 3收到VM 1发来的数据报文，回送过程不再赘述。
在ARP代理模式下，网关设备在回应ARP时，只会以自己的网关MAC进行回应，这就将所有下挂的服务器MAC进行了屏蔽，实现了ARP抑制的作用。而在数据转发时，由于报文的目的MAC是自己，所以每一跳都会进行三层查表转发。
ARP代答 在ARP代答模式中，VTEP设备会将用请求虚拟机的实际MAC回应ARP请求。
ARP代答模式下的首次ARP请求和前文“同VNI单播报文转发流程”章节中的过程相同。在VM 1和VM 3已经在经过flood-learn的过程后，VM 1和VM 3已经可以正常通信，且沿途的设备均已建立正确的表项。
此时，处于同一网段的VM2，同样想要和VM 3通信时，就需要发送ARP请求报文来寻找VM 3的MAC信息。Leaf A已经开启了ARP代答功能，且此时Leaf A上已经有了VM 3的IP和MAC对应表项，那么Leaf A会直接将表项中的MAC 3回应给VM 2，而不需要再经过一次泛洪。这样，ARP代答就可以大大减少ARP泛洪流量。而ARP代答若是配合可以在全网VTEP同步IP和MAC信息的VXLAN控制平面，那么ARP泛洪流量对带宽的影响可以降至最低。
控制平面-Control Plane RFC7348只规定了VXLAN协议的数据平面，对控制平面未做任何要求。这样做的好处是，可以使各类设备无须做较大改动就能互相兼容。如前文所述，和传统VLAN网络数据平面一样，数据经过未知单播泛洪->MAC表项及ARP表项建立->单播转发的过程，我们称之为自学习模式。但自学习方式过于简单，其大量的泛洪报文以及无法智能调整的缺点，使得这样的控制平面构建方式不适合SDN网络。
于是，各厂商纷纷探索更为先进的控制平面实现方法。
控制平面的功能 VXLAN控制平面必须实现的功能：
VTEP邻居发现
VXLAN网络中的VTEP数量众多，类型不同，纯手工配置VTEP非常困难也不利于大规模部署。VXLAN的控制平面应该具有自动发现VTEP邻居、自动建立VXLAN Tunnel、自动进行关联等功能。
虚拟机信息同步
虚拟机信息同步主要是指MAC及ARP的同步。上线的虚拟机信息需要在各VTEP上同步，下线的虚拟机信息要能够在各VTEP上删除或老化，迁移的虚拟机信息要能够从旧VTEP转移到新VTEP。
除了以上两点之外，不同的控制平面协议还能实现自动部署、灵活调整、策略下发等功能。
基于Controller的控制平面 SDN最大的特点就是转控分离，集中控制。按照这个指导思想，将控制功能单独剥离出来成为一个单独的设备便是很自然的事了。这个设备就是 Controller。
Controller可以是一个或者一组硬件设备，也可以是一套软件。Controller与网络中所有设备建立连接，整个VXLAN网络的数据转发都由Controller来管理。Controller与设备连接的接口称为南向接口，可以使用OpenFlow、Netconf等协议；对用户提供服务的接口称为北向接口，也可以提供API以便与其他管理平台对接或进行深度开发。
基于Controller的控制平面，其SDN网络的功能几乎都依赖于Controller本身的特性，根据Controller的不同，会有不同的实现方式和功能。
基于VXLAN-ISIS的控制平面 基于VXLAN-ISIS的控制平面利用ENDP（Enhanced Neighbor Discovery Protocol，增强邻居发现协议）和VXLAN-ISIS两个协议共同完成VXLAN所需的自动建立隧道和信息同步功能。这种控制平面利用ISIS协议的可扩展特性来同步VXLAN建立和流量转发所需要的信息，是早期VXLAN控制平面探索时期的成果之一。
基于EVPN的控制平面 RFC7432（BGP MPLS-Based Ethernet VPN）定义了EVPN。EVPN架构是在现有的BGP VPLS（RFC4761）方案上，参考了BGP/MPLS L3 VPN（RFC4364）的架构提出的。
EVPN构建在MP-BGP之上，依靠MP-BGP来传递EVPN信息。EVPN规定了控制平面需要完成的功能，数据平面可以选择MPLS、PBB和VXLAN中的任意一种。
用VXLAN构建数据平面，用EVPN配合来构建控制平面，是当下较为流行的一种方式。
EVPN利用MP-BGP实现邻居发现，自动发现VXLAN网络中的VTEP，并在有相同VXLAN ID的VTEP之间自动创建VXLAN隧道，自动关联VXLAN隧道和VXLAN。
EVPN利用MP-BGP扩展路由类型报文完成MAC地址同步、主机路由同步。
有关EVPN技术的更详细的内容，后续文章会有相应介绍。
各控制平面特点 最后，我们来比较一下各控制平面的特点。
未来-Future VXLAN由于其简单的数据平面，良好的兼容性，已经成为了当下SDN Overlay技术的最好选择，但VXLAN未来还有很长的路要走。比如探索VXLAN GPE封装是一个方向，解决VXLAN隧道的QoS也是一个方向。而控制平面要做的更多，如何更好的实现按需定制，如何实现智能流量调整，如何更好的兼容异构设备等等。相信未来会给我们一个更好的答案。
VXLAN 协议原理 VXLAN（Virtual eXtensible Local Area Network，虚拟可扩展局域网），是一种虚拟化隧道通信技术。它是一种 Overlay（覆盖网络）技术，通过三层的网络来搭建虚拟的二层网络。
简单来讲，VXLAN 是在底层物理网络（underlay）之上使用隧道技术，借助 UDP 层构建的 Overlay 的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。它对原有的网络架构几乎没有影响，不需要对原网络做任何改动，即可架设一层新的网络。也正是因为这个特性，很多 CNI 插件（Kubernetes 集群中的容器网络接口，这个大家应该都知道了吧，如果你不知道，现在你知道了）才会选择 VXLAN 作为通信网络。
VXLAN 不仅支持一对一，也支持一对多，一个 VXLAN 设备能通过像网桥一样的学习方式学习到其他对端的 IP 地址，还可以直接配置静态转发表。
一个典型的数据中心 VXLAN 网络拓扑图如图所示：
其中 VM 指的是虚拟机，Hypervisor 指的是虚拟化管理器。
为什么需要 VXLAN？ 与 VLAN 相比，VXLAN 很明显要复杂很多，再加上 VLAN 的先发优势，已经得到了广泛的支持，那还要 VXLAN 干啥？
VLAN ID 数量限制 VLAN tag 总共有 4 个字节，其中有 12 bit 用来标识不同的二层网络（即 LAN ID），故而最多只能支持 $2^{12}$，即 4096 个子网的划分。而虚拟化（虚拟机和容器）的兴起使得一个数据中心会有成千上万的机器需要通信，这时候 VLAN 就无法满足需求了。而 VXLAN 的报文 Header 预留了 24 bit 来标识不同的二层网络（即 VNI，VXLAN Network Identifier），即 3 个字节，可以支持 $2^{24}$ 个子网。
交换机 MAC 地址表限制 对于同网段主机的通信而言，报文到底交换机后都会查询 MAC 地址表进行二层转发。数据中心虚拟化之后，VM 的数量与原有的物理机相比呈数量级增长，而应用容器化之后，容器与 VM 相比也是呈数量级增长。。。而交换机的内存是有限的，因而 MAC 地址表也是有限的，随着虚拟机（或容器）网卡 MAC 地址数量的空前增加，交换机表示压力山大啊！
而 VXLAN 就厉害了，它用 VTEP（后面会解释）将二层以太网帧封装在 UDP 中，一个 VTEP 可以被一个物理机上的所有 VM（或容器）共用，一个物理机对应一个 VTEP。从交换机的角度来看，只是不同的 VTEP 之间在传递 UDP 数据，只需要记录与物理机数量相当的 MAC 地址表条目就可以了，一切又回到了和从前一样。
虚机或容器迁移范围受限 VLAN 与物理网络融合在一起，不存在 Overlay 网络，带来的问题就是虚拟网络不能打破物理网络的限制。举个例子，如果要在 VLAN 100 部署虚拟机（或容器），那只能在支持 VLAN 100 的物理设备上部署。
VLAN 其实也有解决办法，就是将所有的交换机 Trunk 连接起来，产生一个大的二层，这样带来的问题就是广播域过分扩大，也包括更多未知的单播和多播，即 BUM（Broadcast，Unknown Unicast，Multicast），同时交换机 MAC 地址表也会有承受不住的问题。
而 VXLAN 将二层以太网帧封装在 UDP 中（上面说过了），相当于在三层网络上构建了二层网络。这样不管你物理网络是二层还是三层，都不影响虚拟机（或容器）的网络通信，也就无所谓部署在哪台物理设备上了，可以随意迁移。
总的来说，传统二层和三层的网络在应对这些需求时变得力不从心，虽然很多改进型的技术比如堆叠、SVF、TRILL 等能够增加二层的范围，努力改进经典网络，但是要做到对网络改动尽可能小的同时保证灵活性却非常困难。为了解决这些问题，有很多方案被提出来，Overlay 就是其中之一，而 VXLAN 是 Overlay 的一种典型的技术方案。下面就对 Overlay 做一个简要的介绍。
Overlay 是个啥？ Overlay 在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于 IP 的基础网络技术为主。
IETF 在 Overlay 技术领域提出 VXLAN、NVGRE、STT 三大技术方案。大体思路均是将以太网报文承载到某种隧道层面，差异性在于选择和构造隧道的不同，而底层均是 IP 转发。VXLAN 和 STT 对于现网设备而言对流量均衡要求较低，即负载链路负载分担适应性好，一般的网络设备都能对 L2-L4 的数据内容参数进行链路聚合或等价路由的流量均衡，而 NVGRE 则需要网络设备对 GRE 扩展头感知并对 flow ID 进行 HASH，需要硬件升级；STT 对于 TCP 有较大修改，隧道模式接近 UDP 性质，隧道构造技术属于革新性，且复杂度较高，而 VXLAN 利用了现有通用的 UDP 传输，成熟性极高。
总体比较，VLXAN 技术具有更大优势，而且当前 VLXAN 也得到了更多厂家和客户的支持，已经成为 Overlay 技术的主流标准。
VXLAN 协议原理 VXLAN 有几个常见的术语：
VTEP（VXLAN Tunnel Endpoints，VXLAN 隧道端点）
VXLAN 网络的边缘设备，用来进行 VXLAN 报文的处理（封包和解包）。VTEP 可以是网络设备（比如交换机），也可以是一台机器（比如虚拟化集群中的宿主机）。
VNI（VXLAN Network Identifier，VXLAN 网络标识符）
VNI 是每个 VXLAN 段的标识，是个 24 位整数，一共有 $2^{24} = 16777216$（一千多万），一般每个 VNI 对应一个租户，也就是说使用 VXLAN 搭建的公有云可以理论上可以支撑千万级别的租户。
Tunnel（VXLAN 隧道）
隧道是一个逻辑上的概念，在 VXLAN 模型中并没有具体的物理实体向对应。隧道可以看做是一种虚拟通道，VXLAN 通信双方认为自己是在直接通信，并不知道底层网络的存在。从整体来说，每个 VXLAN 网络像是为通信的虚拟机搭建了一个单独的通信通道，也就是隧道。
上图所示为 VXLAN 的工作模型，它创建在原来的 IP 网络（三层）上，只要是三层可达（能够通过 IP 相互通信）的网络就能部署 VXLAN。在 VXLAN 网络的每个端点都有一个 VTEP 设备，负责 VXLAN 协议报文的解包和封包，也就是在虚拟报文上封装 VTEP 通信的报文头部。
物理网络上可以创建多个 VXLAN 网络，可以将这些 VXLAN 网络看成一个隧道，不同节点上的虚拟机/容器能够通过隧道直连。通过 VNI 标识不同的 VXLAN 网络，使得不同的 VXLAN 可以相互隔离。
VXLAN 的报文结构如下图所示：
VXLAN Header : 在原始二层帧的前面增加 8 字节的 VXLAN 的头部，其中最主要的是 VNID，占用 3 个字节（即 24 bit），类似 VLAN ID，可以具有 $2^{24}$ 个网段。
UDP Header : 在 VXLAN 和原始二层帧的前面使用 8 字节 UDP 头部进行封装（MAC IN UDP），目的端口号缺省使用 4789，源端口按流随机分配（通过 MAC，IP，四层端口号进行 hash 操作）， 这样可以更好的做 ECMP。
IANA（Internet As-signed Numbers Autority）分配了 4789 作为 VXLAN 的默认目的端口号。
在上面添加的二层封装之后，再添加底层网络的 IP 头部（20 字节）和 MAC 头部（14 字节），这里的 IP 和 MAC 是宿主机的 IP 地址和 MAC 地址。
同时，这里需要注意 MTU 的问题，传统网络 MTU 一般为 1500，这里加上 VXLAN 的封装多出的（36+14/18，对于 14 的情况为 access 口，省去了 4 字节的 VLAN Tag）50 或 54 字节，需要调整 MTU 为 1550 或 1554，防止频繁分包。
VXLAN 的 Flood 与 Learn 总的来说，VXLAN 报文的转发过程就是：原始报文经过 VTEP，被 Linux 内核添加上 VXLAN 头部以及外层的 UDP 头部，再发送出去，对端 VTEP 接收到 VXLAN 报文后拆除外层 UDP 头部，并根据 VXLAN 头部的 VNI 把原始报文发送到目的服务器。但这里有一个问题，第一次通信前双方如何知道所有的通信信息？这些信息包括：
哪些 VTEP 需要加到一个相同的 VNI 组？ 发送方如何知道对方的 MAC 地址？ 如何知道目的服务器在哪个节点上（即目的 VTEP 的地址）？ 第一个问题简单，VTEP 通常由网络管理员来配置。要回答后面两个问题，还得回到 VXLAN 协议的报文上，看看一个完整的 VXLAN 报文需要哪些信息：
内层报文 : 通信双方的 IP 地址已经明确，只需要 VXLAN 填充对方的 MAC 地址，因此需要一个机制来实现 ARP 功能。
VXLAN 头部 : 只需要知道 VNI。一般直接配置在 VTEP 上，要么提前规划，要么根据内层报文自动生成。
UDP 头部 : 需要知道源端口和目的端口，源端口由系统自动生成，目的端口默认是 4789。
IP 头部 : 需要知道对端 VTEP 的 IP 地址，这个是最关键的部分。
实际上，VTEP 也会有自己的转发表，转发表通过泛洪和学习机制来维护，对于目标 MAC 地址在转发表中不存在的未知单播，广播流量，都会被泛洪给除源 VTEP 外所有的 VTEP，目标 VTEP 响应数据包后，源 VTEP 会从数据包中学习到 MAC，VNI 和 VTEP 的映射关系，并添加到转发表中，后续当再有数据包转发到这个 MAC 地址时，VTEP 会从转发表中直接获取到目标 VTEP 地址，从而发送单播数据到目标 VTEP。
VTEP 转发表的学习可以通过以下两种方式：
多播 外部控制中心（如 Flannel、Cilium 等 CNI 插件） MAC 头部 : 确定了 VTEP 的 IP 地址，后面就好办了，MAC 地址可以通过经典的 ARP 方式获取。
Linux 的 VXLAN Linux 对 VXLAN 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，可能会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 VXLAN。
到了 kernel 3.12 版本，Linux 对 VXLAN 的支持已经完备，支持单播和组播，IPv4 和 IPv6。利用 man 查看 ip 的 link 子命令，可以查看是否有 VXLAN type：
1 $ man ip-link 搜索 VXLAN，可以看到如下描述：
管理 VXLAN 接口 Linux VXLAN 接口的基本管理如下：
创建点对点的 VXLAN 接口：
1 $ ip link add vxlan0 type vxlan id 4100 remote 192.168.1.101 local 192.168.1.100 dstport 4789 dev eth0 其中 id 为 VNI，remote 为远端主机的 IP，local 为你本地主机的 IP，dev 代表 VXLAN 数据从哪个接口传输。
在 VXLAN 中，一般将 VXLAN 接口（本例中即 vxlan0）叫做 VTEP。
创建多播模式的 VXLAN 接口：
1 $ ip link add vxlan0 type vxlan id 4100 group 224.1.1.1 dstport 4789 dev eth0 多播组主要通过 ARP 泛洪来学习 MAC 地址，即在 VXLAN 子网内广播 ARP 请求，然后对应节点进行响应。group 指定多播组的地址。
查看 VXLAN 接口详细信息：
1 $ ip -d link show vxlan0 FDB 表 FDB（Forwarding Database entry，即转发表）是 Linux 网桥维护的一个二层转发表，用于保存远端虚拟机/容器的 MAC地址，远端 VTEP IP，以及 VNI 的映射关系，可以通过 bridge fdb 命令来对 FDB 表进行操作：
条目添加：
1 $ bridge fdb add &lt;remote_host_mac> dev &lt;vxlan_interface> dst &lt;remote_host_ip> 条目删除：
1 $ bridge fdb del &lt;remote_host_mac> dev &lt;vxlan_interface> 条目更新：
1 $ bridge fdb replace &lt;remote_host_mac> dev &lt;vxlan_interface> dst &lt;remote_host_ip> 条目查询：
1 $ bridge fdb show 总结 本文通过介绍 VXLAN 出现的时代背景、VXLAN 的概念和网络模型、VXLAN 报文结构，让你对 VXLAN 有了初步的认识；通过介绍 VXLAN 转发表的泛洪和学习，让你知道了通信双方如何感知对方；最后介绍了 Linux 中 VXLAN 的基本配置，让你进一步了解如何在 Linux 中玩转 VXLAN。下一篇文章将会通过实战来说明如何搭建基于 VXLAN 的 Overlay 网络，顺便展开解读上文提到的多播和外部控制中心的工作原理。
参考资料 vxlan 协议原理简介 VXLAN vs VLAN Flannel Kubernetes Flannel网络分析 flannel是coreos开源的Kubernetes CNI实现。它使用etcd或者Kubernetes API存储整个集群的网络配置。每个kubernetes节点上运行flanneld组件，它从etcd或者Kubernetes API获取集群的网络地址空间，并在空间内获取一个subnet,该节点上的容器IP都从这个subnet中分配，从而保证不同节点上的IP不会冲突。flannel通过不同的backend来实现跨主机的容器网络通信，目前支持udp,vxlan,host-gw等一系列backend实现。本文介绍vxlan backend下的容器通信过程。
flannel在v0.9.0版本上对vxlan的实现作了改动。源码中有一段非常详细的注释介绍了不同版本的设计与实现:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // Some design notes and history: // VXLAN encapsulates L2 packets (though flannel is L3 only so don't expect to be able to send L2 packets across hosts) // The first versions of vxlan for flannel registered the flannel daemon as a handler for both "L2" and "L3" misses // - When a container sends a packet to a new IP address on the flannel network (but on a different host) this generates // an L2 miss (i.e. an ARP lookup) // - The flannel daemon knows which flannel host the packet is destined for so it can supply the VTEP MAC to use. // This is stored in the ARP table (with a timeout) to avoid constantly looking it up. // - The packet can then be encapsulated but the host needs to know where to send it. This creates another callout from // the kernal vxlan code to the flannel daemon to get the public IP that should be used for that VTEP (this gets called // an L3 miss). The L2/L3 miss hooks are registered when the vxlan device is created. At the same time a device route // is created to the whole flannel network so that non-local traffic is sent over the vxlan device. // // In this scheme the scaling of table entries (per host) is: // - 1 route (for the configured network out the vxlan device) // - One arp entry for each remote container that this host has recently contacted // - One FDB entry for each remote host // // The second version of flannel vxlan removed the need for the L3MISS callout. When a new remote host is found (either // during startup or when it's created), flannel simply adds the required entries so that no further lookup/callout is required. // // // The latest version of the vxlan backend removes the need for the L2MISS too, which means that the flannel deamon is not // listening for any netlink messages anymore. This improves reliability (no problems with timeouts if // flannel crashes or restarts) and simplifies upgrades. // // How it works: // Create the vxlan device but don't register for any L2MISS or L3MISS messages // Then, as each remote host is discovered (either on startup or when they are added), do the following // 1) create routing table entry for the remote subnet. It goes via the vxlan device but also specifies a next hop (of the remote flannel host). // 2) Create a static ARP entry for the remote flannel host IP address (and the VTEP MAC) // 3) Create an FDB entry with the VTEP MAC and the public IP of the remote flannel daemon. // // In this scheme the scaling of table entries is linear to the number of remote hosts - 1 route, 1 arp entry and 1 FDB entry per host // // In this newest scheme, there is also the option of skipping the use of vxlan for hosts that are on the same subnet, // this is called "directRouting" v0.9.0之前版本的实现主要依赖vxlan内核模块的L2MISS和L3MISS消息机制。L2MISS是指vxlan设备在ARP表中找不到内层IP对应的MAC地址时会给用户态程序发送netlink消息。L3MISS是指vxlan设备在FDB表中找不到VXLAN协议内层MAC地址所属的VTEP的IP地址时会给用户态程序发送netlink消息。之前的文章&laquo;动态维护FDB表项实现VXLAN通信&raquo;介绍过相关概念和操作。本文主要分析v0.9.0版本上的实现方式。
之前的方式实现是，flanneld作为L2MISS和L3MISS消息的处理器,当收到相应消息时从etcd或者kubernetes API获取到相应的ARP或者FDB信息来填充相应条目。如果flanneld异常退出，那么整个容器网络集群的网络就中断了。这是一个很大的隐患。v0.9.0实现不再需要处理L2MISS和L3MISS消息，而是由flanneld通过watch etcd或者kubernetes API的相关节点信息来动态地维护各节点通信所需的ARP、FDB以及路由条目。即使flanneld崩溃，整个集群网络数据转发依然可以运行。这个实现很优雅，每个节点只需要一条路由，一个ARP缓存条目和一个FDB条目。
下面在实验环境中分析flannel vxlan的网络通信过程。整个网络架构如图:
CNI配置文件/etc/cni/net.d/09-flannel.conf内容如下:
1 2 3 4 5 6 7 8 9 { "name": "cbr0", "cniVersion": "0.3.1", "type": "flannel", "delegate": { "isDefaultGateway": true } } 节点上每个pod会有一对veth pair设备，其中一端放在pod的network namespace中，另一端在宿主机上接在cni0网桥上。flanneld启动时创建了vxlan设备:flannel.1。
node1上的flannel网络信息如下,分配的subnet为10.230.41.1/24:
1 2 3 4 5 [root@node1 ~]# cat /run/flannel/subnet.env FLANNEL_NETWORK=10.230.0.0/16 FLANNEL_SUBNET=10.230.41.1/24 FLANNEL_MTU=1450 FLANNEL_IPMASQ=false node2上的flannel网络信息如下, 分配的subnet为10.230.93.1/24:
1 2 3 4 5 [root@node2 ~]# cat /run/flannel/subnet.env FLANNEL_NETWORK=10.230.0.0/16 FLANNEL_SUBNET=10.230.93.1/24 FLANNEL_MTU=1450 FLANNEL_IPMASQ=false 我们来看10.230.41.17向10.230.93.2发送数据包的过程。
10.230.93.2与10.230.41.17不在同一二层网络，因而需要查找路由来决定由哪个设备发送到哪里。10.230.41.17的路由如下:
1 2 3 4 [root@master1 ~]# kubectl exec -it busybox2-6f8fdb784d-r6ln2 -- ip route default via 10.230.41.1 dev eth0 10.230.0.0/16 via 10.230.41.1 dev eth0 10.230.41.0/24 dev eth0 scope link src 10.230.41.17 匹配到默认路由，因而需要发送到网关10.230.41.1。10.230.41.1配置在网桥cni0上。内核通过ARP请求获得10.230.41.1的MAC地址, 将数据包转发到cni0上。
1 2 3 4 5 6 7 [root@node1 ~]# ip addr show dev cni0 5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether 86:99:b6:37:95:b2 brd ff:ff:ff:ff:ff:ff inet 10.230.41.1/24 brd 10.230.41.255 scope global cni0 valid_lft forever preferred_lft forever inet6 fe80::8499:b6ff:fe37:95b2/64 scope link valid_lft forever preferred_lft forever flanneld在加入集群时会为每个其他节点生成一条on-link路由，on-link路由表示是直连路由，匹配该条路由的数据包将触发ARP请求获取目的IP的MAC地址。在node1上查看路由信息:
1 2 [root@node1 ~]# ip route show dev flannel.1 10.230.93.0/24 via 10.230.93.0 onlink cni0设备根据这条路由将数据包转给vxlan设备flannel.1，并且接收端的IP地址为10.230.93.0, 需要通过ARP获取MAC地址。
flannel.1的信息如下, 可以看到没有开启l2miss和l3miss:
1 2 3 4 [root@node1 ~]# ip -d link show flannel.1 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default link/ether a6:f7:8b:a4:60:b0 brd ff:ff:ff:ff:ff:ff promiscuity 0 vxlan id 1 local 10.240.0.101 dev eth1 srcport 0 0 dstport 8472 nolearning ageing 300 noudpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 vxlan设备需要对接收到的数据包进行VXLAN协议封装。它需要知道对端10.230.93.0的MAC地址。而flanneld在启动时已经根据从etcd或kubernetes API获取到的信息写入到ARP表中:
1 2 [root@node1 ~]# ip neigh show dev flannel.1 10.230.93.0 lladdr 2a:02:24:58:e9:07 PERMANENT 这样获取到10.230.93.0的MAC地址后，就可以完成内层数据的封装。数据包封装完成后，它需要获得对应这个MAC地址的VTEP的IP地址。flanneld已经在启动时写入FDB条目:
1 2 [root@node1 ~]# bridge fdb show dev flannel.1 2a:02:24:58:e9:07 dst 10.240.0.102 self permanent 可以看到2a:02:24:58:e9:07对应的VTEP IP为10.240.0.102。这时flannel.1这个vxlan设备知道数据包要发送的目的IP，根据主机的路由策略从eth1设备发出。主机路由信息如下:
1 2 3 4 5 6 7 8 [root@node1 ~]# ip route default via 10.0.2.2 dev eth0 10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 10.230.41.0/24 dev cni0 proto kernel scope link src 10.230.41.1 10.230.93.0/24 via 10.230.93.0 dev flannel.1 onlink 10.240.0.0/24 dev eth1 proto kernel scope link src 10.240.0.101 169.254.0.0/16 dev eth0 scope link metric 1002 169.254.0.0/16 dev eth1 scope link metric 1003 数据包到达node2的eth1后，eth1将收到VXLAN数据包, 数据包中的MAC地址为:2a:02:24:58:e9:07, 正是node2节点上flannel.1的地址, 将它转给flannel.1设备:
1 2 3 4 5 6 7 [root@node2 ~]# ip addr show flannel.1 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 2a:02:24:58:e9:07 brd ff:ff:ff:ff:ff:ff inet 10.230.93.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::2802:24ff:fe58:e907/64 scope link valid_lft forever preferred_lft forever flannel.1解包之后，根据内层目的地址:10.240.93.2查找路由转发到cni0:
1 2 3 4 5 6 [root@node2 ~]# ip route default via 10.0.2.2 dev eth0 proto dhcp metric 100 10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100 10.230.41.0/24 via 10.230.41.0 dev flannel.1 onlink 10.230.93.0/24 dev cni0 proto kernel scope link src 10.230.93.1 10.240.0.0/24 dev eth1 proto kernel scope link src 10.240.0.102 metric 101 cni0再通过ARP请求获得10.230.93.2的MAC地址，从而将数据包转发到相应的POD中的veth pair设备，从而到达容器中。
回包的路径是一样的，不再详述。
下面简要分析一下flanneld的源码实现。
main函数中首先调用newSubnetManager创建SubnetManager。
1 2 3 4 5 6 sm, err := newSubnetManager() if err != nil { log.Error("Failed to create SubnetManager: ", err) os.Exit(1) } log.Infof("Created subnet manager: %s", sm.Name()) SubnetManager用于向网络配置存储租用或续组subnet。每个节点都会有自己的一个subnet,保证了节点之间的IP不会冲突。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func newSubnetManager() (subnet.Manager, error) { if opts.kubeSubnetMgr { return kube.NewSubnetManager(opts.kubeApiUrl, opts.kubeConfigFile) } cfg := &amp;etcdv2.EtcdConfig{ Endpoints: strings.Split(opts.etcdEndpoints, ","), Keyfile: opts.etcdKeyfile, Certfile: opts.etcdCertfile, CAFile: opts.etcdCAFile, Prefix: opts.etcdPrefix, Username: opts.etcdUsername, Password: opts.etcdPassword, } // Attempt to renew the lease for the subnet specified in the subnetFile prevSubnet := ReadSubnetFromSubnetFile(opts.subnetFile) return etcdv2.NewLocalManager(cfg, prevSubnet) } 如果命令行参数中指定了kube-subnet-mgr, 则使用kubernetes API作为全局网络配置存储，否则使用etcd。
接着调用getConfig从全局配置存储获取网络配置, 包括容器集群的网络信息，backend的配置等等:
1 2 3 4 5 6 // Fetch the network config (i.e. what backend to use etc..). config, err := getConfig(ctx, sm) if err == errCanceled { wg.Wait() os.Exit(0) } 比如，我的实验环境写到etcd的配置内容为:
1 {"Network":"10.230.0.0/16","SubnetLen":24, "Backend":{"Type": "vxlan"}} 接下来，main函数会调用backend.NewManager。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Create a backend manager then use it to create the backend and register the network with it. bm := backend.NewManager(ctx, sm, extIface) be, err := bm.GetBackend(config.BackendType) if err != nil { log.Errorf("Error fetching backend: %s", err) cancel() wg.Wait() os.Exit(1) } bn, err := be.RegisterNetwork(ctx, config) if err != nil { log.Errorf("Error registering network: %s", err) cancel() wg.Wait() os.Exit(1) } 开头时也介绍过，flannel通过backend机制来支持各种不同的跨主机通信方式。不同的实现方式会在init函数中向backend注册自己的构造函数。比如，package vxlan的init函数:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func init() { backend.Register("vxlan", New) } const ( defaultVNI = 1 ) type VXLANBackend struct { subnetMgr subnet.Manager extIface *backend.ExternalInterface } func New(sm subnet.Manager, extIface *backend.ExternalInterface) (backend.Backend, error) { backend := &amp;VXLANBackend{ subnetMgr: sm, extIface: extIface, } return backend, nil } be.RegisterNetwork会调用到package vxlan的RegisterNetwork:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 func (be *VXLANBackend) RegisterNetwork(ctx context.Context, config *subnet.Config) (backend.Network, error) { // Parse our configuration cfg := struct { VNI int Port int GBP bool DirectRouting bool }{ VNI: defaultVNI, } if len(config.Backend) > 0 { if err := json.Unmarshal(config.Backend, &amp;cfg); err != nil { return nil, fmt.Errorf("error decoding VXLAN backend config: %v", err) } } log.Infof("VXLAN config: VNI=%d Port=%d GBP=%v DirectRouting=%v", cfg.VNI, cfg.Port, cfg.GBP, cfg.DirectRouting) devAttrs := vxlanDeviceAttrs{ vni: uint32(cfg.VNI), name: fmt.Sprintf("flannel.%v", cfg.VNI), vtepIndex: be.extIface.Iface.Index, vtepAddr: be.extIface.IfaceAddr, vtepPort: cfg.Port, gbp: cfg.GBP, } dev, err := newVXLANDevice(&amp;devAttrs) if err != nil { return nil, err } dev.directRouting = cfg.DirectRouting subnetAttrs, err := newSubnetAttrs(be.extIface.ExtAddr, dev.MACAddr()) if err != nil { return nil, err } lease, err := be.subnetMgr.AcquireLease(ctx, subnetAttrs) switch err { case nil: case context.Canceled, context.DeadlineExceeded: return nil, err default: return nil, fmt.Errorf("failed to acquire lease: %v", err) } // Ensure that the device has a /32 address so that no broadcast routes are created. // This IP is just used as a source address for host to workload traffic (so // the return path for the traffic has an address on the flannel network to use as the destination) if err := dev.Configure(ip.IP4Net{IP: lease.Subnet.IP, PrefixLen: 32}); err != nil { return nil, fmt.Errorf("failed to configure interface %s: %s", dev.link.Attrs().Name, err) } return newNetwork(be.subnetMgr, be.extIface, dev, ip.IP4Net{}, lease) } RegisterNetwork函数会调用newVXLANDevice创建一个vxlan设备，就对应我们实验环境中的flannel.1。从代码也可以看到flannel.1设备名中的1指的是VNI, 我们可以通过在全局配置存储中设置为其他值。然后获取本地VTEP的IP地址以及vxlan设备的MAC地址填充到subnetAttrs结构调用be.subnetMgr.AcquireLease。这最终会调用到package etcdv2的tryAcquireLease。tryAcquireLease则会调用m.registry.createSubnet或者m.registry.updateSubnet去向etcd中写入相应的Subnet信息，完成相应Subnet的租用。这时，如果已经有其他节点的flanneld在watch etcd上的subnets的key，则会触发添加路由、ARP及FDB条目的逻辑。这个下面我们再详细描述具体实现。之后，调用dev.Configure给vxlan设备配置一个掩码为32的地址防止广播路由创建。
RegisterNetwork返回后，main函数会调用WriteSubnetFile将获取到的网络信息写入subnetFile中，默认是/run/flannel/subnet.env，后续flanneld再启动时就会优先尝试使用这个文件中记录的信息去续组subnet:
1 2 3 4 5 6 if err := WriteSubnetFile(opts.subnetFile, config.Network, opts.ipMasq, bn); err != nil { // Continue, even though it failed. log.Warningf("Failed to write subnet file: %s", err) } else { log.Infof("Wrote subnet file to %s", opts.subnetFile) } 接着，main函数中启动一个goroutine去运行bn.Run:
1 2 3 4 5 6 7 // Start "Running" the backend network. This will block until the context is done so run in another goroutine. log.Info("Running backend.") wg.Add(1) go func() { bn.Run(ctx) wg.Done() }() 这会调用到package vxlan的Run实现，它会调用subnet.WatchLeases去获取全局范围的subnet情况:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func (nw *network) Run(ctx context.Context) { wg := sync.WaitGroup{} log.V(0).Info("watching for new subnet leases") events := make(chan []subnet.Event) wg.Add(1) go func() { subnet.WatchLeases(ctx, nw.subnetMgr, nw.SubnetLease, events) log.V(1).Info("WatchLeases exited") wg.Done() }() defer wg.Wait() for { select { case evtBatch := &lt;-events: nw.handleSubnetEvents(evtBatch) case &lt;-ctx.Done(): return } } } package subnet的WatchLeases函数中会一直循环调用sm.WatchLeases。sm.WatchLeases首次运行时会获取到当前etcd中已有的subnet信息，之后则开始watch etcd中subnets key获得变更的subnet信息。这些subnet信息传送给channel:receiver:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 func WatchLeases(ctx context.Context, sm Manager, ownLease *Lease, receiver chan []Event) { lw := &amp;leaseWatcher{ ownLease: ownLease, } var cursor interface{} for { res, err := sm.WatchLeases(ctx, cursor) if err != nil { if err == context.Canceled || err == context.DeadlineExceeded { return } log.Errorf("Watch subnets: %v", err) time.Sleep(time.Second) continue } cursor = res.Cursor var batch []Event if len(res.Events) > 0 { batch = lw.update(res.Events) } else { batch = lw.reset(res.Snapshot) } if len(batch) > 0 { receiver &lt;- batch } } } receiver的接收端协程则调用nw.handleSubnetEvents(evtBatch)来处理这些消息:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 func (nw *network) handleSubnetEvents(batch []subnet.Event) { for _, event := range batch { sn := event.Lease.Subnet attrs := event.Lease.Attrs if attrs.BackendType != "vxlan" { log.Warningf("ignoring non-vxlan subnet(%s): type=%v", sn, attrs.BackendType) continue } var vxlanAttrs vxlanLeaseAttrs if err := json.Unmarshal(attrs.BackendData, &amp;vxlanAttrs); err != nil { log.Error("error decoding subnet lease JSON: ", err) continue } // This route is used when traffic should be vxlan encapsulated vxlanRoute := netlink.Route{ LinkIndex: nw.dev.link.Attrs().Index, Scope: netlink.SCOPE_UNIVERSE, Dst: sn.ToIPNet(), Gw: sn.IP.ToIP(), } vxlanRoute.SetFlag(syscall.RTNH_F_ONLINK) // directRouting is where the remote host is on the same subnet so vxlan isn't required. directRoute := netlink.Route{ Dst: sn.ToIPNet(), Gw: attrs.PublicIP.ToIP(), } var directRoutingOK = false if nw.dev.directRouting { routes, err := netlink.RouteGet(attrs.PublicIP.ToIP()) if err != nil { log.Errorf("Couldn't lookup route to %v: %v", attrs.PublicIP, err) continue } if len(routes) == 1 &amp;&amp; routes[0].Gw == nil { // There is only a single route and there's no gateway (i.e. it's directly connected) directRoutingOK = true } } switch event.Type { case subnet.EventAdded: if directRoutingOK { log.V(2).Infof("Adding direct route to subnet: %s PublicIP: %s", sn, attrs.PublicIP) if err := netlink.RouteReplace(&amp;directRoute); err != nil { log.Errorf("Error adding route to %v via %v: %v", sn, attrs.PublicIP, err) continue } } else { log.V(2).Infof("adding subnet: %s PublicIP: %s VtepMAC: %s", sn, attrs.PublicIP, net.HardwareAddr(vxlanAttrs.VtepMAC)) if err := nw.dev.AddARP(neighbor{IP: sn.IP, MAC: net.HardwareAddr(vxlanAttrs.VtepMAC)}); err != nil { log.Error("AddARP failed: ", err) continue } if err := nw.dev.AddFDB(neighbor{IP: attrs.PublicIP, MAC: net.HardwareAddr(vxlanAttrs.VtepMAC)}); err != nil { log.Error("AddFDB failed: ", err) // Try to clean up the ARP entry then continue if err := nw.dev.DelARP(neighbor{IP: event.Lease.Subnet.IP, MAC: net.HardwareAddr(vxlanAttrs.VtepMAC)}); err != nil { log.Error("DelARP failed: ", err) } continue } // Set the route - the kernel would ARP for the Gw IP address if it hadn't already been set above so make sure // this is done last. if err := netlink.RouteReplace(&amp;vxlanRoute); err != nil { log.Errorf("failed to add vxlanRoute (%s -> %s): %v", vxlanRoute.Dst, vxlanRoute.Gw, err) // Try to clean up both the ARP and FDB entries then continue if err := nw.dev.DelARP(neighbor{IP: event.Lease.Subnet.IP, MAC: net.HardwareAddr(vxlanAttrs.VtepMAC)}); err != nil { log.Error("DelARP failed: ", err) } if err := nw.dev.DelFDB(neighbor{IP: event.Lease.Attrs.PublicIP, MAC: net.HardwareAddr(vxlanAttrs.VtepMAC)}); err != nil { log.Error("DelFDB failed: ", err) } continue } } case subnet.EventRemoved: if directRoutingOK { log.V(2).Infof("Removing direct route to subnet: %s PublicIP: %s", sn, attrs.PublicIP) if err := netlink.RouteDel(&amp;directRoute); err != nil { log.Errorf("Error deleting route to %v via %v: %v", sn, attrs.PublicIP, err) } } else { log.V(2).Infof("removing subnet: %s PublicIP: %s VtepMAC: %s", sn, attrs.PublicIP, net.HardwareAddr(vxlanAttrs.VtepMAC)) // Try to remove all entries - don't bail out if one of them fails. if err := nw.dev.DelARP(neighbor{IP: sn.IP, MAC: net.HardwareAddr(vxlanAttrs.VtepMAC)}); err != nil { log.Error("DelARP failed: ", err) } if err := nw.dev.DelFDB(neighbor{IP: attrs.PublicIP, MAC: net.HardwareAddr(vxlanAttrs.VtepMAC)}); err != nil { log.Error("DelFDB failed: ", err) } if err := netlink.RouteDel(&amp;vxlanRoute); err != nil { log.Errorf("failed to delete vxlanRoute (%s -> %s): %v", vxlanRoute.Dst, vxlanRoute.Gw, err) } } default: log.Error("internal error: unknown event type: ", int(event.Type)) } } } 这里我们忽略directRouting相关内容。EventAdded表示有新的节点上线，首先调用nw.dev.AddARP给vxlan设备添加ARP条目，MAC和IP分别为新上线节点上vxlan设备的MAC地址以及上面所配置的32位掩码的IP地址。接着调用nw.dev.AddFDB在vxlan设备上添加FDB条目，MAC和IP分别为新上线节点上的vxlan设备的MAC地址以及新节点上的VTEP的IP地址。最后，再调用netlink.RouteReplace(&amp;vxlanRoute)去添加经由32位掩码地址到达新上线subnet的路由。代码注释里也说明了，最后再添加路由是为了防止在ARP缓存没有填加的情况下发起ARP请求。
EventRemoved表示有节点下线，这里分别调用nw.dev.DelARP,nw.dev.DelFDB,netlink.RouteDel删除相应的ARP,FDB和路由条目。
在main函数的逻辑里接下来还会调用MonitorLease去定期续租subnet，这里不再详述。
参考:
https://www.cnblogs.com/robinunix/articles/13275530.html https://programmer.ink/think/5da939768e5cb.html Calico Kubernetes Calico 简介 Calico是一个非常流行的Kubernetes网络插件和解决方案.Calico是一个开源虚拟化网络方案，用于为云原生应用实现互联及策略控制。与Flannel相比，Calico的一个显著优势是对网络策略（network policy）的支持，它允许用户动态定义ACL规则控制进出容器的数据报文，实现为Pod间的通信按需施加安全策略。事实上，Calico可以整合进大多数主流的编排系统，如Kubernetes、Apache Mesos、Docker和OpenStack等。
Calico本身是一个三层的虚拟网络方案，它将每个节点都当作路由器（router），将每个节点的容器都当作是“节点路由器”的一个终端并为其分配一个IP地址，各节点路由器通过BGP（Border Gateway Protocol）学习生成路由规则，从而将不同节点上的容器连接起来。因此，Calico方案其实是一个纯三层的解决方案，通过每个节点协议栈的三层（网络层）确保容器之间的连通性，这摆脱了flannel host-gw类型的所有节点必须位于同一二层网络的限制，从而极大地扩展了网络规模和网络边界。
Calico利用Linux内核在每一个计算节点上实现了一个高效的vRouter（虚拟路由器）进行报文转发，而每个vRouter都通过BGP负责把自身所属的节点上运行的Pod资源的IP地址信息基于节点的agent程序（Felix）直接由vRouter生成路由规则向整个Calico网络内进行传播.
Calico承载的各Pod资源直接通过vRouter经由基础网络进行互联，它非叠加、无隧道、不使用VRF表，也不依赖于NAT，因此每个工作负载都可以直接配置使用公网IP接入互联网，当然，也可以按需使用网络策略控制它的网络连通性。
Calico官网介绍: projectcaclico.org
重要特性 经IP路由直连 Calico中，Pod收发的IP报文由所在节点的Linux内核路由表负责转发，并通过iptables规则实现其安全功能。某Pod对象发送报文时，Calico应确保节点总是作为下一跳MAC地址返回，不管工作负载本身可能配置什么路由，而发往某Pod对象的报文，其最后一个IP跃点就是Pod所在的节点，也就是说，报文的最后一程即由节点送往目标Pod对象，如下图所示。
需为某Pod对象提供连接时，系统上的专用插件（如Kubernetes的CNI）负责将需求通知给Calico Agent。收到消息后，Calico Agent会为每个工作负载添加直接路径信息到工作负载的TAP设备（如veth）。而运行于当前节点的BGP客户端监控到此类消息后会调用路由reflector向工作于其他节点的BGP客户端进行通告。
简单、高效、易扩展 Calico未使用额外的报文封装和解封装，从而简化了网络拓扑，这也是Calico高性能、易扩展的关键因素。毕竟，小的报文减少了报文分片的可能性，而且较少的封装和解封装操作也降低了对CPU的占用。此外，较少的封装也易于实现报文分析，易于进行故障排查。
创建、移动或删除Pod对象时，相关路由信息的通告速度也是影响其扩展性的一个重要因素。Calico出色的扩展性缘于与互联网架构设计原则别无二致的方式，它们都使用了BGP作为控制平面。BGP以高效管理百万级的路由设备而闻名于世，Calico自然可以游刃有余地适配大型IDC网络规模。另外，由于Calico各工作负载使用基IP直接进行互联，因此它还支持多个跨地域的IDC之间进行协同。
Calico系统架构 各组件介绍如下:
Felix
Calico Agent，运行于每个节点。主要负责网络接口管理和监听、路由、ARP 管理、ACL 管理和同步、状态上报等。
ETCD
分布式键值存储，主要负责网络元数据一致性，确保Calico网络状态的准确性，可以与kubernetes共用；
BGP Client（BIRD）
Calico 为每一台 Host 部署一个 BGP Client，使用 BIRD 实现，BIRD 是一个单独的持续发展的项目，实现了众多动态路由协议比如 BGP、OSPF、RIP 等。在 Calico 的角色是监听 Host 上由 Felix 注入的路由信息，然后通过 BGP 协议广播告诉剩余 Host 节点，从而实现网络互通。
BGP Route Reflector
在大型网络规模中，如果仅仅使用 BGP client 形成 mesh 全网互联的方案就会导致规模限制，因为所有节点之间俩俩互联，需要 N^2 个连接，为了解决这个规模问题，可以采用 BGP 的 Router Reflector 的方法，使所有 BGP Client 仅与特定 RR 节点互联并做路由同步，从而大大减少连接数。
Felix Felix运行于各节点的用于支持端点（VM或Container）构建的守护进程，它负责生成路由和ACL，以及其他任何由节点用到的信息，从而为各端点构建连接机制。Felix在各编排系统中主要负责以下任务。
首先是接口管理（Interface Management）功能，负责为接口生成必要的信息并送往内核，以确保内核能够正确处理各端点的流量，尤其是要确保各节点能够响应目标MAC为当前节点上各工作负载的MAC地址的ARP请求，以及为其管理的接口打开转发功能。另外，它还要监控各接口的变动以确保规则能够得到正确的应用。
其次是路由规划（Route Programming）功能，其负责为当前节点运行的各端点在内核FIB（Forwarding Information Base）中生成路由信息，以保证到达当前节点的报文可正确转发给端点。
再次是ACL规划（ACL Programming）功能，负责在Linux内核中生成ACL，用于实现仅放行端点间的合法流量，并确保流量不能绕过Calico的安全措施。
最后是状态报告（State Reporting）功能，负责提供网络健康状态的相关数据，尤其是报告由其管理的节点上的错误和问题。这些报告数据会存储于etcd，供其他组件或网络管理员使用。
编排系统插件 编排系统插件（Orchestrator Plugin）依赖于编排系统自身的实现，故此并不存在一个固定的插件以代表此组件。编排系统插件的主要功能是将Calico整合进系统中，并让管理员和用户能够使用Calico的网络功能。它主要负责完成API的转换和反馈输出。
编排系统通常有其自身的网络管理API，网络插件需要负责将对这些API的调用转为Calico的数据模型并存储于Calico的存储系统中。如果有必要，网络插件还要将Calico系统的信息反馈给编排系统，如Felix的存活状态，网络发生错误时设定相应的端点为故障等。
ETCD储系统 Calico使用etcd完成组件间的通信，并以之作为一个持久数据存储系统。根据编排系统的不同，etcd所扮演角色的重要性也因之而异，但它贯穿了整个Calico部署全程，并被分为两类主机：核心集群和代理（proxy）。在每个运行着Felix或编排系统插件的主机上都应该运行一个etcd代理以降低etcd集群和集群边缘节点的压力。此模式中，每个运行着插件的节点都会运行着etcd集群的一个成员节点。
etcd是一个分布式、强一致、具有容错功能的存储系统，这一点有助于将Calico网络实现为一个状态确切的系统：要么正常，要么发生故障。另外，分布式存储易于通过扩展应对访问压力的提升，而避免成为系统瓶颈。另外，etcd也是Calico各组件的通信总线，可用于确保让非etcd组件在键空间（keyspace）中监控某些特定的键，以确保它们能够看到所做的任何更改，从而使它们能够及时地响应这些更改。
BGP客户端(BIRD) Calico要求在每个运行着Felix的节点上同时还要运行一个BGP客户端，负责将Felix生成的路由信息载入内核并通告到整个IDC。在Calico语境中，此组件是通用的BIRD，因此任何BGP客户端（如GoBGP等）都可以从内核中提取路由并对其分发对于它们来说都适合的角色。
BGP客户端的核心功能就是路由分发，在Felix插入路由信息至内核FIB中时，BGP客户端会捕获这些信息并将其分发至其他节点，从而确保了流量的高效路由。
BGP路由反射器(Route Reflector) 在大规模的部署场景中，简易版的BGP客户端易于成为性能瓶颈，因为它要求每个BGP客户端都必须连接至其同一网络中的其他所有BGP客户端以传递路由信息，一个有着N个节点的部署环境中，其存在网络连接的数量为N的二次方，随着N值的逐渐增大，其连接复杂度会急剧上升。因而在较大规模的部署场景中，Calico应该选择部署一个BGP路由反射器，它是由BGP客户端连接的中心点，BGP的点到点通信也就因此转化为与中心点的单路通信模型，如图11-18所示。出于冗余之需，生产实践中应该部署多个BGP路由反射器。对于Calico来说，BGP客户端程序除了作为客户端使用之外，还可以配置成路由反射器。
Calico网络工作模式 BGP模式 边界网关协议（Border Gateway Protocol, BGP）是互联网上一个核心的去中心化自治路由协议，它通过维护IP路由表或“前缀”表来实现自治系统（AS）之间的可达性，属于矢量路由协议。不过，考虑到并非所有的网络都能支持BGP，以及Calico控制平面的设计要求物理网络必须是二层网络，以确保vRouter间均直接可达，路由不能够将物理设备当作下一跳等原因，为了支持三层网络。
在默认配置下每台宿主机的BGPClient需要和集群所有的BGPClient建立连接，进行路由信息交换，随着集群规模的扩大，集群的网络将会面临巨大的压力并且宿主机的路由表也会变的过大。所以在大规模的集群中，通常使用BGP Route Reflector充当BGP客户端连接的中心点，从而避免与互联网中的每个BGP客户端进行通信。Calico使用BGP Route Reflector是为了减少给定一个BGP客户端与集群其他BGP客户端的连接。用户也可以同时部署多个BGP Route Reflector服务实现高可用。Route Reflector仅仅是协助管理BGP网络，并没有工作负载的数据包经过它们。
IPIP模式 BGP模式要求Kubernetes的所有物理节点网络必须是二层网络.为了支持三层网络，Calico还推出了IP-in-IP叠加的模型，它也使用Overlay的方式来传输数据。IPIP的包头非常小，而且也是内置在内核中，因此理论上它的速度要比VxLAN快一点，但安全性更差。Calico 3.x的默认配置使用的是IPIP类型的传输方案而非BGP。
工作于IPIP模式的Calico会在每个节点上创建一个tunl0接口（TUN类型虚拟设备）用于封装三层隧道报文。节点上创建的每一个Pod资源，都会由Calico自动创建一对虚拟以太网接口（TAP类型的虚拟设备），其中一个附加于Pod的网络名称空间，另一个（名称以cali为前缀后跟随机字串）留置在节点的根网络名称空间，并经由tunl0封装或解封三层隧道报文。Calico IPIP模式如下图所示。
Calico 网络通信方式 Calico网络环境介绍 当前k8s集群使用的是v1.17.3的版本.有2个node节点.IP地址分别如下
1 2 3 [root@k8s-master ~]$kubectl get nodes -o wide | awk '{print $1,$6}' | sed 1,2d k8s-node1 172.16.20.252 k8s-node2 172.16.20.253 每个node节点都启动一个tunl0 的虚拟路由器.和许多calixxx 开头的虚拟网卡设备
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@k8s-node1 ~]# ifconfig cali42b086c8543: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1440 inet6 fe80::ecee:eeff:feee:eeee prefixlen 64 scopeid 0x20&lt;link> ether ee:ee:ee:ee:ee:ee txqueuelen 0 (Ethernet) RX packets 13335563 bytes 928478769 (885.4 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 13335563 bytes 928478769 (885.4 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 tunl0: flags=193&lt;UP,RUNNING,NOARP> mtu 1440 inet 10.100.36.64 netmask 255.255.255.255 tunnel txqueuelen 1000 (IPIP Tunnel) #默认是IPIP模式 RX packets 3978810 bytes 345003038 (329.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3674392 bytes 613045453 (584.6 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions Calico的CNI插件会为每个容器设置一个veth pair设备，然后把另一端接入到宿主机网络空间，由于没有网桥，CNI插件还需要在宿主机上为每个容器的veth pair设备配置一条路由规则，用于接收传入的IP包.
了这样的veth pair设备以后，容器发出的IP包就会通过veth pair设备到达宿主机，这些路由规则都是Felix维护配置的，而路由信息则是calico bird组件基于BGP分发而来。Calico实际上是将集群里所有的节点都当做边界路由器来处理，他们一起组成了一个全互联的网络，彼此之间通过BGP交换路由，这些节点我们叫做BGP Peer。
为了下面试验Calico的网络工作.当前集群使用daemonSet控制器运行了2个busybox:1.28.4 镜像的容器
1 2 3 4 [root@k8s-master ~]$kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES busybox-g5rkr 1/1 Running 0 130m 10.100.36.103 k8s-node1 &lt;none> &lt;none> busybox-zdwsc 1/1 Running 0 130m 10.100.169.176 k8s-node2 &lt;none> &lt;none> 在k8s-node1节点上可以看到两条相关路由
1 2 10.100.36.103 0.0.0.0 255.255.255.255 UH 0 0 0 cali96df9f67b52 10.100.169.128 172.16.20.253 255.255.255.192 UG 0 0 0 tunl0 第一条路由是访问该节点下的Busybox容器.它的下一跳是calixxxx开头的虚拟网卡.这种通信方式和docker的Bridge网桥模式其实并没有任何区别.
第二条路由的目的网络是10.100.169.128,子网掩码是255.255.255.192.它代表了IP范围为10.100.169.128-190的地址.而运行于另外一个节点下的busybox-zdwscPod的IP地址就位于这个范围之内.所以这条路由可以使node1节点借助于tunl0可以直接和node2节点下的pod进行通信.
在k8s-node2 服务器可以看到类似的这2条路由
Calico网络模型解密 登录k8s-node1节点下的Pod容器内部.查看Pod容器的IP地址,以及路由条目.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@k8s-master ~]$kubectl exec -it busybox-g5rkr -- sh / # ifconfig eth0 Link encap:Ethernet HWaddr 4A:7C:E7:FA:4B:CC inet addr:10.100.36.103 Bcast:0.0.0.0 Mask:255.255.255.255 UP BROADCAST RUNNING MULTICAST MTU:1440 Metric:1 RX packets:14 errors:0 dropped:0 overruns:0 frame:0 TX packets:6 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:1322 (1.2 KiB) TX bytes:426 (426.0 B) / # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 169.254.1.1 0.0.0.0 UG 0 0 0 eth0 169.254.1.1 0.0.0.0 255.255.255.255 UH 0 0 0 eth0 通过k8s-node节点上的下面的路由条目,我们可以知道节点主机和Pod容器的IP地址10.100.36.103通信使用的是cali96df9f67b52这个虚拟网卡
1 10.100.36.103 0.0.0.0 255.255.255.255 UH 0 0 0 cali96df9f67b52 路由条目显示169.254.1.1 是Pod容器的默认网关.但是有网络常识的我们都知道这个IP是个保留的IP地址,不存在于互联网或者任何设备中.那Pod如何和网关通信呢?
回顾一下网络课程,我们知道任何网络设备和网关设备都是在一个二层局域网中,而二层数据链路层使用MAC地址进行通信,不需要双方的IP地址信息.通信方(这里是Pod容器)会通过ARP协议获取网关的MAC地址,然后通过MAC地址将数据包发送给网关..也就是说网络设备不关心对方的IP是否可达,只要能找到对应的MAC地址就可以.
通过ip neigh命令查看Pod容器的ARP缓存
1 2 / # ip neigh 169.254.1.1 dev eth0 lladdr ee:ee:ee:ee:ee:ee ref 1 used 0/0/0 probes 4 REACHABLE 如果是新的Pod容器可能无法获得ARP缓存,此时只需要随便发生一个网络交互(例如ping百度)即可
这个MAC地址(ee:ee:ee:ee:ee:ee)也是Calico的虚拟cali96df9f67b52网卡的虚拟MAC地址.下放是宿主机网卡信息:
1 2 3 4 5 6 7 cali96df9f67b52: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1440 inet6 fe80::ecee:eeff:feee:eeee prefixlen 64 scopeid 0x20&lt;link> ether ee:ee:ee:ee:ee:ee txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 所有虚拟网卡默认开启了ARP代理协议
1 2 [root@k8s-node1 ~]# cat /proc/sys/net/ipv4/conf/cali96df9f67b52/proxy_arp 1 所以Calico 通过一个巧妙的方法将 Pod 的所有流量引导到一个特殊的网关 169.254.1.1，从而引流到主机的 calixxx 网络设备上，最终将二三层流量全部转换成三层流量来转发。
Calico IPIP网络模式 登录busybox-g5rkrPod容器内部.ping位于另外一台k8s-node2 下的busybox-zdwscPod容器
1 2 3 4 [root@k8s-master ~]$kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES busybox-g5rkr 1/1 Running 0 130m 10.100.36.103 k8s-node1 &lt;none> &lt;none> busybox-zdwsc 1/1 Running 0 130m 10.100.169.176 k8s-node2 &lt;none> &lt;none> 两个Pod之前可以直接访问对方的IP地址.而不需要像Docker容器那样暴露端口,然后利用对方宿主机的IP进行通信
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@k8s-master ~]$kubectl exec -it busybox-g5rkr -- sh / # ifconfig eth0 Link encap:Ethernet HWaddr 4A:7C:E7:FA:4B:CC inet addr:10.100.36.103 Bcast:0.0.0.0 Mask:255.255.255.255 UP BROADCAST RUNNING MULTICAST MTU:1440 Metric:1 RX packets:14 errors:0 dropped:0 overruns:0 frame:0 TX packets:6 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:1322 (1.2 KiB) TX bytes:426 (426.0 B) / # ping 10.100.169.176 PING 10.100.169.176 (10.100.169.176): 56 data bytes 64 bytes from 10.100.169.176: seq=0 ttl=62 time=0.622 ms 64 bytes from 10.100.169.176: seq=1 ttl=62 time=0.552 ms 64 bytes from 10.100.169.176: seq=2 ttl=62 time=0.597 ms 在k8s-node2 节点抓包
1 [root@k8s-node2 ~]# tcpdump -i ens192 -nn -w imcp.cap 用wireshark软件打开抓包文件.发现如下ICMP的报文
可以看到每个数据报文共有两个IP网络层,内层是Pod容器之间的IP网络报文,外层是宿主机节点的网络报文(2个node节点).之所以要这样做是因为tunl0是一个隧道端点设备，在数据到达时要加上一层封装，便于发送到对端隧道设备中。
Pod间的通信经由IPIP的三层隧道转发,相比较VxLAN的二层隧道来说，IPIP隧道的开销较小，但其安全性也更差一些。
IPIP的通信方式如下:
Pod和Service网络通信 经过测试.在k8s集群内部物理节点和pod容器内部访问Service的http服务.仍然使用的是Ipip通信模式.
下面是在容器内部通过Service访问busybox pod容器的http服务的抓包报文
1 2 3 4 5 6 7 [root@k8s-master ~]$kubectl exec -it busybox-6hnvc -- sh / # curl http://10.96.166.242 sh: curl: not found / # wget -O - -q http://10.96.166.242 wget: server returned error: HTTP/1.0 404 Not Found / # wget -O - -q http://10.96.166.242 wget: server returned error: HTTP/1.0 404 Not Found BGP网络模式 Calico网络部署时,默认安装就是IPIP网络.通过修改calico.yaml部署文件中的CALICO_IPV4POOL_IPIP 值修改成off 就切换到BGP网络模式
1 2 3 # Enable IPIP - name: CALICO_IPV4POOL_IPIP value: "Always" #改成Off 重新部署calico
1 [root@k8s-master ~]$kubectl apply -f calico-3.10.2.yaml 然后关闭ipipMode.把ipipMode从Always修改成为Never
1 2 3 [root@k8s-master1 target]# kubectl edit ippool ipipMode: Never bgp和Ipip的区别 BGP网络相比较IPIP网络，最大的不同之处就是没有了隧道设备 tunl0。 前面介绍过IPIP网络pod之间的流量发送tunl0，然后tunl0发送对端设备。BGP网络中，pod之间的流量直接从网卡发送目的地，减少了tunl0这个环节。
通信方式 删除原来的pod.重新启动新的
1 2 3 4 5 6 7 [root@k8s-master ~]$kubectl create -f deployment-kubia-v1.yaml daemonset.apps/busybox created service/busybox created [root@k8s-master ~]$kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES busybox-bd566 1/1 Running 0 16s 10.100.36.97 k8s-node1 &lt;none> &lt;none> busybox-fntv9 1/1 Running 0 16s 10.100.169.129 k8s-node2 &lt;none> &lt;none> 再次查看路由表.发现节点和pod容器通信直接通过宿主机的物理网卡,而不是tunl0设备了
1 2 3 4 5 6 [root@k8s-master ~]$route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.16.20.254 0.0.0.0 UG 100 0 0 ens192 10.100.36.64 172.16.20.252 255.255.255.192 UG 0 0 0 ens192 10.100.169.128 172.16.20.253 255.255.255.192 UG 0 0 0 ens192 此时,再次2个Pod容器互ping抓包分析.发现两个Pod像物理机一样直接通信,而不需要进行任何数据包封装和解封装.并且数据报文的MAC地址也是node1和node2物理网卡的MAC地址
BGP的网络连接方式:
BGP和ipip网络模式对比 IPIP:
特点: tunl0封装数据.形成隧道.所有Pod和pod.pod和节点之间进行三层网络传输
优点: 适用所有网络类型.能够解决跨网段的路由问题.
BGP:
特点: 适用BGP路由导向流量
优点: Pod之间直接通信.省去了隧道,封装,解封装等任何中间环节,传输效率非常高.
缺点: 需要确保所有物理节点在同一个二层网络,否则Pod无法跨节点网段通信
Calico网络优化 MTU Calico 的IPIP网络模型下tunl0接口的MTU默认为1440，这种设置主要是为适配Google的GCE环境，在非GCE的物理环境中，其最佳值为1480。因此，对于非GCE环境的部署，建议将配置清单calico.yaml下载至本地修改后，再将其应用到集群中。要修改的内容是DaemonSet资源calico-node的Pod模板，将容器calico-node的环境变量“FELIX_INPUTMTU”的值修改为1480即可
因为IPIP多了一层IP报文封装,而IP报文头部一般是20个字节.所以MUT的值应该是最大1500-20.
Calico-typha 对于50个节点以上规模的集群来说，所有Calico节点均基于Kubernetes API存取数据会为API Server带来不小的通信压力，这就应该使用calico-typha进程将所有Calico的通信集中起来与API Server进行统一交互。calico-typha以Pod资源的形式托管运行于Kubernetes系统之上，启用的方法为下载前面步骤中用到的Calico的部署清单文件至本地，修改其calico-typha的Pod资源副本数量为所期望的值并重新应用配置清单即可：
1 2 3 4 5 6 7 8 apiVersion: apps/v1beta1 kind: Deployment metadata: name: calico-typha ... spec: ... replicas: &lt;number of replicas> 每个calico-typha Pod资源可承载100到200个Calico节点的连接请求，最多不要超过200个。另外，整个集群中的calico-typha的Pod资源总数尽量不要超过20个。
BGP路由模型 默认情况下，Calico的BGP网络工作于点对点的网格（node-to-node mesh）模型，它仅适用于较小规模的集群环境。中级集群环境应该使用全局对等BGP模型（Global BGP peers），以在同一二层网络中使用一个或一组BGP反射器构建BGP网络环境。而大型集群环境需要使用每节点对等BGP模型（Per-node BGP peers），即分布式BGP反射器模型，一个典型的用法是将每个节点都配置为自带BGP反射器接入机架顶部交换机上的路由反射器。
使用BGP而非IPIP 事实上，仅在那些不支持用户自定义BGP配置的网络中才需要使用IPIP的隧道通信类型。如果有一个自主可控的网络环境且部署规模较大时，可以考虑启用BGP的通信类型降低网络开销以提升传输性能，并且应该部署BGP反射器来提高路由学习效率。
参考资料 Calico官网: www.projectcalico.org
k8s网络之Calico网络: https://www.cnblogs.com/goldsunshine/p/10701242.html#mxAMjXzT
kubernetes容器网络: https://tech.ipalfish.com/blog/2020/03/06/kubernetes_container_network/ (伴鱼团队)
Calico IPIP网络模式 本文主要分析k8s中网络组件calico的 IPIP网络模式。旨在理解IPIP网络模式下产生的calixxxx，tunl0等设备以及跨节点网络通信方式。可能看着有点枯燥，但是请花几分钟时间坚持看完，如果看到后面忘了前面，请反复看两遍，这几分钟时间一定你会花的很值。
calico介绍 Calico是Kubernetes生态系统中另一种流行的网络选择。虽然Flannel被公认为是最简单的选择，但Calico以其性能、灵活性而闻名。Calico的功能更为全面，不仅提供主机和pod之间的网络连接，还涉及网络安全和管理。Calico CNI插件在CNI框架内封装了Calico的功能。
Calico是一个基于BGP的纯三层的网络方案，与OpenStack、Kubernetes、AWS、GCE等云平台都能够良好地集成。Calico在每个计算节点都利用Linux Kernel实现了一个高效的虚拟路由器vRouter来负责数据转发。每个vRouter都通过BGP1协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则。Calico保证所有容器之间的数据流量都是通过IP路由的方式完成互联互通的。Calico节点组网时可以直接利用数据中心的网络结构(L2或者L3)，不需要额外的NAT、隧道或者Overlay Network，没有额外的封包解包，能够节约CPU运算，提高网络效率。
此外，Calico基于iptables还提供了丰富的网络策略，实现了Kubernetes的Network Policy策略，提供容器间网络可达性限制的功能。
**calico官网：**https://www.projectcalico.org/
calico架构及核心组件 架构图如下：
calico核心组件：
Felix：运行在每个需要运行workload的节点上的agent进程。主要负责配置路由及 ACLs(访问控制列表) 等信息来确保 endpoint 的连通状态，保证跨主机容器的网络互通; ETCD：强一致性、高可用的键值存储，持久存储calico数据的存储管理系统。主要负责网络元数据一致性，确保Calico网络状态的准确性; BGP Client(BIRD)：读取Felix设置的内核路由状态，在数据中心分发状态。 BGP Route Reflector(BIRD)：BGP路由反射器，在较大规模部署时使用。如果仅使用BGP Client形成mesh全网互联就会导致规模限制，因为所有BGP client节点之间两两互联，需要建立N^2个连接，拓扑也会变得复杂。因此使用reflector来负责client之间的连接，防止节点两两相连。 calico工作原理 Calico把每个操作系统的协议栈认为是一个路由器，然后把所有的容器认为是连在这个路由器上的网络终端，在路由器之间跑标准的路由协议——BGP的协议，然后让它们自己去学习这个网络拓扑该如何转发。所以Calico方案其实是一个纯三层的方案，也就是说让每台机器的协议栈的三层去确保两个容器，跨主机容器之间的三层连通性。
calico的两种网络方式 IPIP
把 IP 层封装到 IP 层的一个 tunnel。它的作用其实基本上就相当于一个基于IP层的网桥!一般来说，普通的网桥是基于mac层的，根本不需 IP，而这个 ipip 则是通过两端的路由做一个 tunnel，把两个本来不通的网络通过点对点连接起来。ipip 的源代码在内核 net/ipv4/ipip.c 中可以找到。
BGP
边界网关协议(Border Gateway Protocol, BGP)是互联网上一个核心的去中心化自治路由协议。它通过维护IP路由表或‘前缀’表来实现自治系统(AS)之间的可达性，属于矢量路由协议。BGP不使用传统的内部网关协议(IGP)的指标，而使用基于路径、网络策略或规则集来决定路由。因此，它更适合被称为矢量性协议，而不是路由协议。
PIP网络模式分析 由于个人环境中使用的是IPIP模式，因此接下来这里分析一下这种模式。
1 2 3 # kubectl get po -o wide -n paas | grep hello demo-hello-perf-d84bffcb8-7fxqj 1/1 Running 0 9d 10.20.105.215 node2.perf &lt;none> &lt;none> demo-hello-sit-6d5c9f44bc-ncpql 1/1 Running 0 9d 10.20.42.31 node1.sit &lt;none> &lt;none> 进行ping测试
这里在demo-hello-perf这个pod中ping demo-hello-sit这个pod。
1 2 3 4 5 6 7 8 9 root@demo-hello-perf-d84bffcb8-7fxqj:/# ping 10.20.42.31 PING 10.20.42.31 (10.20.42.31) 56(84) bytes of data. 64 bytes from 10.20.42.31: icmp_seq=1 ttl=62 time=5.60 ms 64 bytes from 10.20.42.31: icmp_seq=2 ttl=62 time=1.66 ms 64 bytes from 10.20.42.31: icmp_seq=3 ttl=62 time=1.79 ms ^C --- 10.20.42.31 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 6ms rtt min/avg/max/mdev = 1.662/3.015/5.595/1.825 ms 进入pod demo-hello-perf中查看这个pod中的路由信息
1 2 3 4 5 root@demo-hello-perf-d84bffcb8-7fxqj:/# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 169.254.1.1 0.0.0.0 UG 0 0 0 eth0 169.254.1.1 0.0.0.0 255.255.255.255 UH 0 0 0 eth0 根据路由信息，ping 10.20.42.31，会匹配到第一条。
**第一条路由的意思是：**去往任何网段的数据包都发往网关169.254.1.1，然后从eth0网卡发送出去。
demo-hello-perf所在的node node2.perf 宿主机上路由信息如下：
1 2 3 4 5 6 7 8 9 # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.16.36.1 0.0.0.0 UG 100 0 0 eth0 10.20.42.0 172.16.35.4 255.255.255.192 UG 0 0 0 tunl0 10.20.105.196 0.0.0.0 255.255.255.255 UH 0 0 0 cali4bb1efe70a2 169.254.169.254 172.16.36.2 255.255.255.255 UGH 100 0 0 eth0 172.16.36.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 可以看到一条Destination为 10.20.42.0的路由。
意思是：当ping包来到master节点上，会匹配到路由tunl0。该路由的意思是：去往10.20.42.0/26的网段的数据包都发往网关172.16.35.4。因为demo-hello-perf的pod在172.16.36.5上，demo-hello-sit的pod在172.16.35.4上。所以数据包就通过设备tunl0发往到node节点上。
demo-hello-sit所在的node node1.sit 宿主机上路由信息如下：
1 2 3 4 5 6 7 # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.16.35.1 0.0.0.0 UG 100 0 0 eth0 10.20.15.64 172.16.36.4 255.255.255.192 UG 0 0 0 tunl0 10.20.42.31 0.0.0.0 255.255.255.255 UH 0 0 0 cali04736ec14ce 10.20.105.192 172.16.36.5 255.255.255.192 UG 0 0 0 tunl0 当node节点网卡收到数据包之后，发现发往的目的ip为10.20.42.31，于是匹配到Destination为10.20.42.31的路由。
该路由的意思是：10.20.42.31是本机直连设备，去往设备的数据包发往cali04736ec14ce
为什么这么奇怪会有一个名为cali04736ec14ce的设备呢?这是个啥玩意儿呢?
其实这个设备就是veth pair的一端。在创建demo-hello-sit 时calico会给demo-hello-sit创建一个veth pair设备。一端是demo-hello-sit 的网卡，另一端就是我们看到的cali04736ec14ce
接着验证一下。我们进入demo-hello-sit 的pod，查看到 4 号设备后面的编号是：122964
1 2 3 4 5 6 7 8 9 10 11 root@demo-hello-sit--6d5c9f44bc-ncpql:/# ip a 1: lo: &lt;LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: tunl0@NONE: &lt;NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000 link/ipip 0.0.0.0 brd 0.0.0.0 4: eth0@if122964: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1380 qdisc noqueue state UP group default link/ether 9a:7d:b2:26:9b:17 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.20.42.31/32 brd 10.20.42.31 scope global eth0 valid_lft forever preferred_lft forever 然后我们登录到demo-hello-sit这个pod所在的宿主机查看
1 2 3 4 5 6 7 # ip a | grep -A 5 "cali04736ec14ce" 122964: cali04736ec14ce@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1380 qdisc noqueue state UP group default link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 16 inet6 fe80::ecee:eeff:feee:eeee/64 scope link valid_lft forever preferred_lft forever 120918: calidd1cafcd275@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1380 qdisc noqueue state UP group default link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 2 发现pod demo-hello-sit中 的另一端设备编号和这里在node上看到的cali04736ec14ce编号122964是一样的
所以，node上的路由，发送cali04736ec14ce网卡设备的数据其实就是发送到了demo-hello-sit的这个pod中去了。到这里ping包就到了目的地。
注意看 demo-hello-sit这个pod所在的宿主机的路由，有一条 Destination为10.20.105.192的路由
1 2 3 4 5 6 7 # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface ... 0.0.0.0 172.16.35.1 0.0.0.0 UG 100 0 0 eth0 10.20.105.192 172.16.36.5 255.255.255.192 UG 0 0 0 tunl0 ... 再查看一下demo-hello-sit的pod中路由信息，和demo-hello-perf的pod中是一样的。
所以综合上述例子来看，IPIP的网络模式就是将IP网络封装了一层。特点就是所有pod的数据流量都从隧道tunl0发送，并且tunl0这里增加了一层传输层的封包操作。
抓包分析 在demo-hello-perf这个pod中ping demo-hello-sit这个pod，接着在demo-hello-sit这个pod所在的宿主机进行tcpdump
1 2 # tcpdump -i eth0 -nn -w icmp_ping.cap tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 在demo-hello-perf这个pod中进行ping demo-hello-sit的操作
1 2 3 4 5 6 7 8 9 root@demo-hello-perf-d84bffcb8-7fxqj:/# ping 10.20.42.31 PING 10.20.42.31 (10.20.42.31) 56(84) bytes of data. 64 bytes from 10.20.42.31: icmp_seq=1 ttl=62 time=5.66 ms 64 bytes from 10.20.42.31: icmp_seq=2 ttl=62 time=1.68 ms 64 bytes from 10.20.42.31: icmp_seq=3 ttl=62 time=1.61 ms ^C --- 10.20.42.31 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 6ms rtt min/avg/max/mdev = 1.608/2.983/5.659/1.892 ms 结束抓包后下载icmp_ping.cap到本地windows进行抓包分析
能看到该数据包一共5层，其中IP(Internet Protocol)所在的网络层有两个，分别是pod之间的网络和主机之间的网络封装。
红色框选的是两个pod所在的宿主机，蓝色框选的是两个pod的ip，src表示发起ping操作的pod所在的宿主机ip以及发起ping操作的pod的ip，dst表示被ping的pod所在的宿主机ip及被ping的pod的ip
根据数据包的封装顺序，应该是在demo-hello-perf ping demo-hello-sit的ICMP包外面多封装了一层主机之间的数据包。
可以看到每个数据报文共有两个IP网络层,内层是Pod容器之间的IP网络报文,外层是宿主机节点的网络报文(2个node节点)。之所以要这样做是因为tunl0是一个隧道端点设备，在数据到达时要加上一层封装，便于发送到对端隧道设备中。
两层封包的具体内容如下：
Pod间的通信经由IPIP的三层隧道转发,相比较VxLAN的二层隧道来说，IPIP隧道的开销较小，但其安全性也更差一些。
pod到svc的访问 查看service
1 2 3 # kubectl get svc -o wide -n paas | grep hello demo-hello-perf ClusterIP 10.10.255.18 &lt;none> 8080/TCP 10d appEnv=perf,appName=demo-hello demo-hello-sit ClusterIP 10.10.48.254 &lt;none> 8080/TCP 10d appEnv=sit,appName=demo-hello 在pod demo-hello-sit 的宿主机上抓包
1 2 # tcpdump -i eth0 -nn -w svc.cap tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 测试访问，在demo-hello-sit中curl demo-hello-perf的svc的地址和端口
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 root@demo-hello-perf-d84bffcb8-7fxqj:/# curl -I http://10.10.48.254:8080/actuator/health HTTP/1.1 200 Content-Type: application/vnd.spring-boot.actuator.v3+json Transfer-Encoding: chunked Date: Fri, 30 Apr 2021 01:42:56 GMT root@demo-hello-perf-d84bffcb8-7fxqj:/# curl -I http://10.10.48.254:8080/actuator/health HTTP/1.1 200 Content-Type: application/vnd.spring-boot.actuator.v3+json Transfer-Encoding: chunked Date: Fri, 30 Apr 2021 01:42:58 GMT root@demo-hello-perf-d84bffcb8-7fxqj:/# curl -I http://10.10.48.254:8080/actuator/health HTTP/1.1 200 Content-Type: application/vnd.spring-boot.actuator.v3+json Transfer-Encoding: chunked Date: Fri, 30 Apr 2021 01:42:58 GMT 结束抓包，下载svc.cap文件放到wireshark中打开查看
可以看到wireshark中Src和Dst的结果。任然是和上面pod中访问pod的ip地址一样。这里Src和Dst任然是两个pod的宿主机的内网ip和两个pod自己的ip地址。是用ipip的方式进行通信的。</content></entry><entry><title/><url>https://xshrim.github.io/post/other/Harbor-v1.7.5%E5%AE%89%E8%A3%85/</url><categories/><tags/><content type="html"> 私有镜像仓库Harbor部署使用 Harbor介绍 Harbor是VMware公司开源的企业级Docker Registry项目，其目标是帮助用户迅速搭建一个企业级的Docker私有镜像仓库。Harbor基于官方Registry V2实现，提供了管理UI，基于角色的访问控制，LDAP集成、镜像复制、以及审计日志等企业用户需求的功能。
图形化用户界面 用户可以通过浏览器来浏览、检索Docker镜像仓库，管理项目。 基于角色的访问控制 按项目对Docker镜像进行组织，可以按项目对用户授权。 镜像复制 镜像可以在多个Harbor实例之间复制。镜像复制可以很好的应对多云、多数据中心的场景。 LDAP支持 Harbor可以集成企业内部AD/LDAP，方便统一进行用户管理。 审计管理 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 另外，Harbor也可以对上传的镜像进行漏洞扫描和签名，新版的Harbor也加入Helm仓库的功能。
先决条件 Harbor 有多个Docker容器组成，可以部署在任何支持Docker的Linux发行版上。目标主机需要安装Python、Docker、Docker Compose。
硬件 资源 最小配置 建议配置 CPU 最小 2 CPU 建议 4 CPU Mem 最小 4GB 建议 8GB Disk 最小 40GB 建议 160GB或更多，根据上传的镜像多少决定 软件 软件 版本 描述 Python 2.7版或更高 Docker engine 1.10版或更高 Docker Compose 1.6.0版或更高 Openssl 首选最新版 为Harbor生成证书 网络端口 端口 协议 描述 443 HTTPS Harbor Portal 和 core API 使用此端口对外提供服务 80 HTTP Harbor Portal 和 core API 使用此端口对外提供服务 升级操作系统到最新版本 操作系统我们选择 CentOS 7 最新版（7.6.1810），如果不是最新版，可参考如下升级到最新版。
按如下内容，编辑 /etc/yum.repos.d/CentOS-Base.repo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # CentOS-Base.repo # # The mirror system uses the connecting IP address of the client and the # update status of each mirror to pick mirrors that are updated to and # geographically close to the client. You should use this for CentOS updates # unless you are manually picking other mirrors. # # If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead. # # [base] name=CentOS-$releasever - Base #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra baseurl=http://mirrors.163.com/centos/7.6.1810/os/$basearch/ #baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-$releasever - Updates #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra baseurl=http://mirrors.163.com/centos/7.6.1810/updates/$basearch/ #baseurl=http://mirror.centos.org/centos/$releasever/updates/$basearch/ gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-$releasever - Extras #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra baseurl=http://mirrors.163.com/centos/7.6.1810/extras/$basearch/ #baseurl=http://mirror.centos.org/centos/$releasever/extras/$basearch/ gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever - Plus #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplus&amp;infra=$infra baseurl=http://mirrors.163.com/centos/7.6.1810/centosplus/$basearch/ #baseurl=http://mirror.centos.org/centos/$releasever/centosplus/$basearch/ gpgcheck=1 enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 升级系统并重启
1 2 $ yum update -y $ reboot 关闭SELinux，编辑 /etc/sysconfig/selinux，设置 SELINUX=disabled
1 $ setenforce 0 安装 Docker 安装依赖包
1 2 3 $ sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 添加docker官方仓库
1 2 3 $ sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 查看Docker可用版本
1 2 3 4 5 6 7 8 9 10 11 $ yum list docker-ce --showduplicates | sort -r docker-ce.x86_64 3:18.09.5-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.4-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.3-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.2-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.1-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable docker-ce.x86_64 18.06.3.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.2.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable 安装Docker CE
1 $ sudo yum install -y docker-ce-18.06.3.ce-3.el7 镜像加速配置
镜像加速服务可以使用阿里云的镜像加速服务。注册阿里云的用户后，登录 https://cr.console.aliyun.com ，在管理控制台选择镜像加速服务，可以获取加速地址，然后配置Docker。
1 2 3 4 5 $ vi /etc/docker/daemon.json { "graph":"/data/docker", "registry-mirrors": ["https://xxxxxx.mirror.aliyuncs.com"] } 启动Docker，并设置开机启动
1 2 $ sudo systemctl start docker $ sudo systemctl enable docker 安装 Docker Compose 确保目标主机上安装了Python 2.7 或更高版本
1 2 $ curl -L "https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose $ chmod +x /usr/local/bin/docker-compose 安装 Harbor 下载安装程序 Harbor的安装包分为在线版和离线版，离线版包含安装所需的所有镜像，如果你安装的环境不能上网，建议选择这个版本，否则选择在线版安装。
可以到Harbor的发布下载Harbor的安装程序，在此选择在线版本。
1 2 3 4 $ sudo mkdir /data $ cd /data $ wget https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.5.tgz $ tar xvf harbor-online-installer-v1.7.5.tgz 配置Harbor 在harbor.cfg配置文件中包含必填参数和可选参数。
设置访问harbor使用的域名和协议:
1 2 hostname = hub.hipstershop.cn ui_url_protocol = https 设置harbor使用的ssl证书：
1 2 ssl_cert = /data/harbor/cert/server.crt ssl_cert_key = /data/harbor/cert/server.key 邮箱相关的配置：
1 2 3 4 5 6 7 email_server = mail.hipstershop.cn email_server_port = 25 email_username = op@mail.hipstershop.cn email_password = abc email_from = Harbor &lt;op@mail.hipstershop.cn> email_ssl = false email_insecure = false Harbor admin账号密码：
1 harbor_admin_password = abc123456 认证相关配置，默认是db_auth：
1 2 3 4 auth_mode = ldap_auth ldap_url = ldaps://192.168.100.100:389 ldap_searchdn = hipstershop\op ldap_basedn = OU=op,DC=hipstershop,DC=cn 使用阿里云的OSS做镜像存储，默认是本地硬盘：
1 2 registry_storage_provider_name = oss registry_storage_provider_config = accesskeyid:xxxxxxxxxx,accesskeysecret: xxxxxxxxxxxxxx,region: oss-cn-beijing,bucket: xin-docker-hub, internal: true 上传SSL证书 创建cert目录并上传SSL证书
1 $ mkdir /data/harbor/cert 为域名申请证书，并上传到/data/harbor/cert，证书文件名：server.crt，私钥文件名：server.key
执行安装脚本 Notray：是一套docker镜像的签名工具，用来保证镜像在pull、push和传输过程中的一致性和完整性。避免中间人攻击，避免非法的镜像更新和运行。 Clair：是coreos开源的容器漏洞扫描工具。harbor很好的整合了Clair，通过简单的UI就可以对上传的镜像扫描，还可以通过每天的定时扫描对所有镜像进行统一扫描。 Chartmuseum：是Helm Charts仓库，用来存储Charts包。 1 $ ./install.sh --with-notary --with-clair --with-chartmuseum 如果一切正常，你可以打开浏览器访问：https://hub.hipstershop.cn ，默认的管理员用户名为：admin，密码：Harbor12345
修改Harbor配置 如下修改Harbor配置配置，比如Job Worker数量，我们需要如下操作：
停掉Harbor服务 1 2 $ /data/harbor $ docker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml -f ./docker-compose.clair.yml -f ./docker-compose.chartmuseum.yml down -v 修改配置 1 2 $ vi harbor.cfg max_job_workers = 20 # 从10 给为20 执行预备脚本 1 $ ./prepare --with-notary --with-clair --with-chartmuseum 启动harbor 1 $ docker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml -f ./docker-compose.clair.yml -f ./docker-compose.chartmuseum.yml up -d 日常使用 在浏览器访问 https://hub.hipstershop.cn，输入用户名、密码登录Harbor。
创建项目 点击项目–> 新建项目可以创建一个项目，一个项目可以包含多个镜像。新建一个私有项目，名字为：example。
上传镜像 使用docker命令行工具登录私有仓库并上传镜像到example。
1 2 3 4 $ docker login hub.hipstershop.cn $ docker pull nginx $ docker tag nginx hub.hipstershop.cn/example/nginx:latest $ docker push hub.hipstershop.cn/example/nginx:latest 对镜像进行病毒扫描 找到刚刚上传的镜像，然后选择镜像，点击扫描按钮对镜像镜像漏洞扫描。
点击镜像标签，可以看到详细漏洞扫描结果。
Charts 仓库 Harbor 同时也支持helm charts管理，在此可以上传charts，也可以通过helm push命令行上传。
为项目添加成员 为项目添加成员并分配权限，项目管理拥有这个项目的所有权限，开发人员用下这个项目的镜像上传、下载权限，访客仅有下载权限。
同步镜像到其他远程仓库 如果你有多个镜像仓库，比如多个数据库中心，每个数据中心都有私有仓库，可以使用Harbor的镜像同步功能。
给镜像打标签 项目配置管理 在项目配置管理选项卡中可以配置项目仓库是否公开，公开的项目仓库可以本任何人访问；部署安全相关配置，比如可以组织高危镜像部署；也可以设置镜像扫描。
用户管理 在Harbor中添加可以登录系统的用户。
仓库管理 可以添加远程镜像仓库，用于同步本地镜像到远程仓库。
复制管理 可以添加复制规则。
配置管理 Harbor全局配置。在此可以扫描镜像，设置镜像垃圾回收任务。</content></entry><entry><title/><url>https://xshrim.github.io/post/prometheus/</url><categories/><tags/><content type="html"> 介绍 总览 开始 对比 常见问题 路线图 学习媒介 词汇 概念 数据模型 度量指标类型 任务与实例 prometheus 开始 安装 配置-配置文件 配置-记录规则 配置-预警规则 配置-模板例子 配置-模板参考 配置-规则的单元测试 查询-基本概念 查询-操作符 查询-函数 查询-举例 查询-HttpAPI 存储 联邦 管理API 集成 API稳定性 可视化 表达式浏览器 Grafana 控制模板 操作 安全 集成 Instrumenting 客户端库 写客户端库 推送度量指标 导出与集成 写导出器 导出格式 警告 警告概览 警告管理器 配置 客户端 通知模板参考 通知模板例子 最佳实践 指标和标签命名 控制台和面板 instrumentation 直方图和summaries 预警 录制规则 什么时候使用Pushgateway 教程 基本授权 使用cAdvisor监控Docker容器指标 使用基于文件的服务发现抓取指标 使用Node Exporter监控Linux主机指标 Go应用指南 TLS加密</content></entry><entry><title/><url>https://xshrim.github.io/post/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9CMTU%E7%9B%B8%E5%85%B3/</url><categories/><tags/><content type="html"> Kubernetes网络MTU测试报告 概述 Kubernetes集群容器网络是以网络插件(主流基于CNI标准)的方式实现的, 各网络插件实现跨主机Pod通信的方式多种多样, 主要分为Underlay和Overlay两种, 前者的代表为Flannel插件的host-gw模式和Calico插件的bgp模式, 后者主要有Flannel插件的vxlan模式, Calico插件的ipip模式以及Weave插件的sleeve和fastpath模式.
Underlay网络是现实的物理基础层网络架构, 而Overlay网络则是基于物理网络之上构建的逻辑网络, Overlay网络中传输的数据包在物理基础网络协议栈的基础上作了额外的封装, 占用额外的字节. 因此同样的包大小能携带的数据量(Payload)会更小, 不同网络插件的网络模式所占用的额外字节数也不同, 如果不能根据实际网络模式配置每个包携带数据量的上限, 将可能导致数据包在传输过程中被丢弃, 网络通信失败.
网络基础 网络模型 互联网的实现, 逻辑上分成好几层, 每一层都有自己的特定功能并提供抽象良好的接口, 这种层级关系构成网络互联的标准框架. 工业上将其分为四层, 称为TCP/IP模型, 国际标准化组织进一步细化为七层, 称为OSI模型, 通常为了便于理解, 结合两种模型也有五层模型的说法, 即应用层, 传输层, 网络层, 链路层和物理层.
数据通过以太网从一个端点发送到另一个端点的过程简单来说分为三个阶段:
发送端封装: 数据在发送端应用程序产生后由协议栈经过层层封装, 形成最终的比特串等待通过物理网络设备发送 比特流传输: 数据比特串在发送端网络设备通过传输介质(光纤,双绞线,电磁波)传输到接收端网络设备 接收端解封: 数据到达接收端网络设备后经过接收端协议栈层层解封, 最终传递到相应的应用程序 发送端和接收端均需支持完整的互联网协议栈, 除物理层外, 每层协议封装时都会**以上层数据为Payload(或Data)**并在此基础上添加一个该层协议的协议头, 最终以比特流的形式通过物理介质进行传输. 常用协议所在层及其协议头长度如下:
协议层 协议 描述 头部字节 应用层 HTTP 超文本传输协议 - 应用层 FTP 文件传输协议 - 应用层 SMTP 简单邮件传输协议 - 应用层 DHCP 动态主机配置协议 - 应用层 RIP 路由信息协议 - 应用层 NFS 网络文件系统协议 - 应用层 DNS 域名解析协议 - 应用层 TELNET 远程终端协议 - 应用层 SNMP 简单网络管理协议 - 传输层 TCP 传输控制协议 20 传输层 UDP 用户数据报协议 8 网络层 IP 网际互联协议 20 网络层 ICMP 互联网控制信息协议 8 网络层 IGMP 互联网组管理协议 8 网络层 ARP 地址解析协议 28 链路层 MAC 多路访问控制 14 表格采用五层模型, ARP协议在ISO七层模型中属于链路层
应用层协议头部长度通常是不固定的
ICMP和IGMP协议需要经IP协议进一步封装才能达到链路层
ARP协议无需经IP协议封装, 其头部会携带源目的IP, 源目的MAC, 但达到链路层后仍需MAC协议封装
MTU和MSS MTU 以太网(Ethernet)是最流行的局域网通信技术标准, 是当今互联网的基石, 在以太网标准中, 链路层帧的最大长度是1518字节, 其中帧头部占用14字节, 帧尾CRC校验(FCS)占用4字节, 剩下的承载上层协议的地方也就是Payload最大就只剩1500字节.这个值就称为MTU. MTU的全称是maximum transmission unit(最大传输单元), MTU可以认为是网络层能够传输的最大IP包.
IP协议发现其上层传递来的数据超过MTU大小时, 将对数据进行分片(fragment), 每个分片均单独封装IP头部并通过头部的同id不同fragment offset两个字段关联起来. 分片后只有第一个分片会在IP层Payload中包含上层头部(如tcp, udp, icmp头部).
每一个网络接口(通常是网卡)都会被设置一个MTU值, 通常是默认的1500字节, 该值可以通过查看网络接口属性的命令查看(如ip addr或者ifconfig). 当同一个网络上的两台主机互相进行通信时, 如需通过多个网络, 则每个网络的链路层可能有不同的MTU, 整个传输路径中所有网络接口的最小MTU称为PMTU(路径MTU). 不同的路由路径选择会影响PMTU值, 一旦链路帧所携带的Data的大小大于任何途经网络设备的MTU值, 则该帧被该设备解封为IP数据包的时候会被重新分片, 将额外耗费性能和带宽.
网络设备通常支持链路的PMTU发现机制, 该机制是利用将IP数据包头部的DF位置为1声明不允许分片, 一旦路径上某个设备MTU小于该IP包大小, 则丢弃该包并回传一个携带了自身MTU值的ICMP错误给其发送端, 发送端将据此MTU重新计算并重传. Linux上PMTU发现机制是默认开启的, 关闭方式为echo 1 > /proc/sys/net/ipv4/ip_no_pmtu_disc.
MSS MSS即Maximum Segment Size, 是传输层TCP协议的概念, 是TCP协议提交给IP层最大分段的大小, 不包含TCP Header, 只包含TCP Payload , MSS是TCP用来限制应用层最大的发送字节数, 与IP协议的分片类似, TCP协议在上层传递下来的数据大于MSS值时会对报文作分段(segment). 在TCP三次握手过程中, 双方会在发送SYN报文的阶段通过TCP首部的Option字段携带自身的MSS值以便双方发送数据时合理设置每个TCP报文段携带的Payload的大小. UDP协议不会对报文作分段处理, 因此不存在MSS的概念.
MSS值是通过MTU计算得到的, 按照协议栈的分层关系可知, MSS = MTU - 20(IP头部) - 20(TCP头部). MTU值则是在网络接口上直接设置的.
基于以上描述, 对于一个以太网帧, MTU和MSS的关联和区别如下:
TCP协议基于MSS对报文进行分段, IP协议基于MTU对报文段进行分片.
在IP协议支持分片的情况下, TCP协议还要进行报文分段的原因在于TCP是通过失败重传机制实现可靠传输的, 一旦发生传输错误TCP进行重传, 如果不作分段, 则每次将重传完整报文, 重传量大且可能需要IP协议再次分片, 但如果TCP协议根据MSS进行分段后, 则重传时仅需传输出错的分段, IP层也不需要再作分片.
Overlay网络 Kubernetes众多的网络插件中, Underlay模式由于不存在额外的网络封装, 其MTU和MSS通常保持默认值(1500和1460), 但Overlay模式则因封装方式的不同, 均会额外占用一定的字节数, 为了保证从容器中发出经宿主机虚拟网卡封装后的链路帧不超过宿主机出口网卡的MTU限制, 需相应调整容器内虚拟网卡的MTU值.
Kubernetes集群中容器创建时会自动调用网络插件为容器和宿主机上该容器的veth pair创建虚拟网卡并设置网卡的IP地址, MTU, Mac地址等相关属性, 其中MTU的配置位于网络插件的配置文件中.
Flannel-VXLAN Flannel网络插件的vxlan模式是典型的Overlay网络, 大致架构如下:
Pod 1访问Pod 2时, 从Pod 1中发出的链路层帧经其网关cni0解封为IP层数据包后根据路由规则再次封包为链路层帧直接路由到宿主机的flannel.1虚拟网卡上, 此虚拟网卡在原链路层帧的基础上进行vxlan封装, 将其封装为携带vxlan头部的UDP数据报后继续封装为完整的链路层帧, 由宿主机网卡eth1发往目的节点, 由目的节点flannel.1进行解封后路由到Pod2中.
经vxlan封装后的完整链路层帧结构如下:
可以看到, 相比原始的链路层帧, 封装后的链路层帧多了一个VXLAN头部, 一个UDP头部, 一个IP头部和一个Mac头部, 加起来一共多了50个字节.
因此对于容器内虚拟网卡而言, 为了保证封装后的帧不超过默认MTU 1500字节, 容器内发出的原始帧应当限制在1500-50=1450字节, 即容器虚拟网卡的MTU应设置为1450字节, 相应的, 容器内发出TCP报文段的MSS为1450-40=1410字节.
Calico-IPIP Calico网络插件的ipip模式也是一种常见的Overlay网络, 与vxlan网络不同的是, ipip模式是一种IP隧道, 它将一个IP数据包封装在另一个IP数据包中, 被封装的并不是一个完整的链路层帧.
Container 1 访问Container4时, 从Container 1中发出的链路层帧经其网关cali9c02e56(其实是代答)解封为IP层数据包后根据路由规则再次封包为链路层帧直接路由到宿主机的tunl0虚拟网卡上, 此虚拟网卡将原链路层帧解封为IP数据包后进行ipip封装, 在此IP数据包的基础上封装外层IP和MAC头部, 由宿主机网卡eth0发往目的节点, 由目的节点tunl0进行解封后路由到Container 4中.
经ipip封装后的完整链路层帧结构如下:
可见相比原始的链路层帧, 封装后的链路层帧仅多了一个IP头部, 即20字节.
因此对于容器内虚拟网卡而言, 为了保证封装后的帧不超过默认MTU 1500字节, 容器内发出的原始帧应当限制在1500-20=1480字节, 即容器虚拟网卡的MTU应设置为1480字节, 相应的, 容器内发出TCP报文段的MSS为1480-40=1440字节.
测试 当前金山kubernetes集群采用canal网络, 为flannel和calico网络的结合, 跨主机通信仍然是利用flannel网络的vxlan封装实现的, calico接管的是容器和宿主机的通信. 容器内虚拟网卡和宿主机上的veth pair网卡的MTU均为1450.
开阳kubernetes集群采用calico网络的ipip模式, 正常来说容器内虚拟网卡和宿主机上的veth pair网卡的MTU应该配置为1480, 但实际上他们设置为了1440.
现在需要确认金山kubernetes集群中的pod和开阳kubernetes集群中的pod互相通信时, 是否会出现通信失败(即数据包丢失)的情况, 是否需要调整开阳kubernetes集群calico网络的MTU默认值.
ICMP 我们将通过ping命令发送ICMP包测试连通性, ICMP是网络层协议, 其报文结构为:
ICMP报文不包括传输层内容(不与具体进程关联), 除链路层帧外, ICMP和IP协议头部一共占用20 + 8 = 28字节, 一个ICMP报文的数据区域内容最大值Data = MTU - IPHeader - ICMPHeader, 即1472字节(MTU取标准值1500).
UDP 对于kubernetes集群外部对集群内容器的访问, 需要通过端口映射和转发实现, 因此此种情况的连通性测试需要利用传输层协议完成, 这里采用UDP数据报协议, 其报文结构为:
UDP数据报封装在IP数据包中, 其头部也是8字节, 因此一个UDP数据报的数据区域内容最大值Data = MTU - IPHeader - UDPHeader, 即1472字节(MTU取标准值1500).
工具 ip命令可以查看和修改网卡接口的MTU值. 具体命令为:
1 2 3 ip a # 查看网卡信息 ip r # 查看路由信息 ip link set &lt;dev> mtu 1450 # 设置网卡mtu值 ping命令可指定发送ICMP报文的数据区域大小, 并可指定IP数据包头部的DF位从而不允许数据包分片. 具体命令为:
1 ping -M do -c 1 -s 1472 &lt;remote-ip> # -M 限制分片 -s 指定数据区域大小(不包括头部) tracepath命令可以探测到网络路径上PMTU的大小. 具体命令为:
1 tracepath -l 1500 &lt;remote-ip> # -l 初始数据包长度(包括头部) tcpdump命令可以抓取网络通信过程中经过各网卡接口的数据包信息. 具体命令为:
1 tcpdump -i &lt;dev> icmp and host &lt;ip> -nn -vvv mut.py脚本通过UDP server和client收发dgram数据报测试跨集群环境(依赖NodePort)网络连通性(UDP数据报头部也是8字节). 具体脚本为:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 #!/usr/bin/python2 import IN, sys, getopt, socket def server(length, endpoint): localIP = "0.0.0.0" localPort = 6666 if endpoint == "" else int(endpoint) bufferSize = 5120 if length == 0 else length # Create a datagram socket UDPServerSocket = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM) # Bind to address and ip UDPServerSocket.bind((localIP, localPort)) print("UDP server up and listening at {}:{}".format(localIP, localPort)) # Listen for incoming datagrams while (True): bytesAddressPair = UDPServerSocket.recvfrom(bufferSize) clientAddr = "Client IP Address: {}".format(bytesAddressPair[1]) clientMsg = "Message from Client: {}".format(bytesAddressPair[0]) print(clientAddr) print(clientMsg) # Sending a reply to client bytesToSend = str.encode("Received {} Bytes".format(len(bytesAddressPair[0]))) UDPServerSocket.sendto(bytesToSend, bytesAddressPair[1]) def client(length, endpoint, df): # IN.IP_MTU = 14 # IN.IP_PMTUDISC_DONT = 0 # disable PMTU discover # IN.IP_PMTUDISC_WANT = 1 # fragment if data > PMTU # IN.IP_PMTUDISC_DO = 2 # return error if data > PMTU # IN.IP_MTU_DISCOVER = 10 IP_MTU = 14 serverAddr = "127.0.0.1:6666" if endpoint == "" else endpoint serverIP, serverPort = tuple(serverAddr.split(':')) serverPort = int(serverPort) # udp dataSize = 1472 if length == 0 else length # Create a datagram socket UDPClientSocket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # tcp # dataSize = 1472 if length == 0 else length # UDPClientSocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # Bind to address and ip UDPClientSocket.connect((serverIP, serverPort)) if df: # DF bit is set in this packet (default) UDPClientSocket.setsockopt(socket.IPPROTO_IP, IN.IP_MTU_DISCOVER, IN.IP_PMTUDISC_DO) else: # DF bit is cleared in this packet UDPClientSocket.setsockopt(socket.IPPROTO_IP, IN.IP_MTU_DISCOVER, IN.IP_PMTUDISC_DONT) mtu = UDPClientSocket.getsockopt(socket.IPPROTO_IP, IP_MTU) print("Path MTU: {}".format(mtu)) try: UDPClientSocket.send('.' * dataSize) #except socket.error: except Exception as err: print(err) else: bytesAddressPair = UDPClientSocket.recvfrom(dataSize * 3) serverAddr = "Server IP Address: {}".format(bytesAddressPair[1]) serverMsg = "Message from Server: {}".format(bytesAddressPair[0]) print(serverAddr) print(serverMsg) def main(argv): mode = "client" datasize = 0 endpoint = "" df = False try: opts, args = getopt.getopt(argv, "hdsl:e:", ["length=", "endpoint="]) except getopt.GetoptError: print("test.py -s -l &lt;datalength> -e &lt;endpoint>") sys.exit(2) for opt, arg in opts: if opt == "-h": print("test.py -s -l &lt;datalength> -e &lt;endpoint>") sys.exit() elif opt == "-s": mode = "server" elif opt == "-d": df = True elif opt in ("-l", "--length"): datasize = int(arg) elif opt in ("-e", "--endpoint"): endpoint = arg if mode == "server": server(datasize, endpoint) else: client(datasize, endpoint, df) if __name__ == "__main__": main(sys.argv[1:]) 场景 测试场景说明如下:
各场景中使用ip命令设置各网卡MTU的过程略过 主机上网卡分为主机物理网卡和容器虚拟网卡 虚拟网卡包括overlay网卡flannel.1/tunl0和veth-pair网卡(主机上calixxxx@if3, 容器内eth0@ifxxx) 同一主机下所有虚拟网卡MTU是一致的, 不一致的情况下已确认会存在通信失败 下述场景环境表格中网卡IP列表示宿主机主网卡IP地址和容器内部虚拟网卡IP地址, 下述场景环境表格中网卡MTU列表示宿主机主网卡MTU和所有虚拟网卡MTU(开阳Calico环境除外) 开阳Calico环境下仅宿主机上tunl0虚拟网卡MTU为1440, 其他虚拟网卡(包括宿主机和容器内)均为1500 宿主机内部容器通信 容器 &lt;&ndash;> 宿主机 flannel/canal环境vxlan 集群 端点 网卡IP 网卡MTU 金山 宿主机A 10.210.33.107 1500 金山 容器A 10.244.24.63 1450 从容器A发送不同大小的ICMP包到宿主机A
1 2 3 4 # 容器A执行 tracepath 10.210.33.107 ping -c 1 -s &lt;数据大小> 10.210.33.107 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.210.33.107 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 从宿主机A发送不同大小的ICMP包到容器A
1 2 3 4 # 宿主机A执行 tracepath 1.0.244.24.63 ping -c 1 -s &lt;数据大小> 10.244.24.63 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.244.24.63 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES calico环境ipip 集群 端点 网卡IP 网卡MTU 开阳 宿主机A 10.210.10.136 1500 开阳 容器A 200.20.234.11 1440 从容器A发送不同大小的ICMP包到宿主机A
1 2 3 4 # 容器A执行 tracepath 10.210.10.136 ping -c 1 -s &lt;数据大小> 10.210.10.136 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.210.10.136 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 NO YES 1471 1499 NO YES 1472 1500 NO YES 1473 1501 YES YES 从宿主机A发送不同大小的ICMP包到容器A
1 2 3 4 # 宿主机A执行 tracepath 200.20.234.11 ping -c 1 -s &lt;数据大小> 200.20.234.11 # 可分片 ping -c 1 -s &lt;数据大小> -M do 200.20.234.11 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 NO YES 1471 1499 NO YES 1472 1500 NO YES 1473 1501 YES YES 容器 &lt;&ndash;> 容器 flannel/canal环境vxlan 集群 端点 网卡IP 网卡MTU 金山 宿主机A 10.210.33.107 1500 金山 容器A 10.244.24.63 1450 金山 容器B 10.244.24.64 1450 从容器A发送不同大小的ICMP包到容器B
1 2 3 4 # 容器A执行 tracepath 10.244.24.64 ping -c 1 -s &lt;数据大小> 10.244.24.64 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.244.24.64 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES calico环境ipip 集群 端点 网卡IP 网卡MTU 开阳 宿主机 10.210.10.136 1500 开阳 容器A 200.20.234.11 1440 开阳 容器B 200.20.234.12 1440 从容器A发送不同大小的ICMP包到容器B
1 2 3 4 # 容器A执行 tracepath 200.20.234.12 ping -c 1 -s &lt;数据大小> 200.20.234.12 # 可分片 ping -c 1 -s &lt;数据大小> -M do 200.20.234.12 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 NO YES 1471 1499 NO YES 1472 1500 NO YES 1473 1501 YES YES 集群内跨宿主机容器通信 容器 &lt;&ndash;> 其他宿主机 flannel/canal环境vxlan 集群 端点 网卡IP 网卡MTU 金山 宿主机A 10.210.33.107 1500 金山 容器A 10.244.24.63 1450 金山 宿主机B 10.210.33.106 1500 从容器A发送不同大小的ICMP包到宿主机B
1 2 3 4 # 容器A执行 tracepath 10.210.33.106 ping -c 1 -s &lt;数据大小> 10.210.33.106 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.210.33.106 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 从宿主机B发送不同大小的ICMP包到容器A
1 2 3 4 # 宿主机B执行 tracepath 10.244.24.63 ping -c 1 -s &lt;数据大小> 10.244.24.63 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.244.24.63 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES calico环境ipip 集群 端点 网卡IP 网卡MTU 开阳 宿主机A 10.210.10.136 1500 开阳 容器A 200.20.234.11 1440 开阳 宿主机B 10.210.10.84 1500 从容器A发送不同大小的ICMP包到宿主机B
1 2 3 4 # 容器A执行 tracepath 10.210.10.84 ping -c 1 -s &lt;数据大小> 10.210.10.84 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.210.10.84 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 NO YES 1471 1499 NO YES 1472 1500 NO YES 1473 1501 YES YES 从宿主机B发送不同大小的ICMP包到容器A
1 2 3 4 # 宿主机B执行 tracepath 200.20.234.11 ping -c 1 -s &lt;数据大小> 200.20.234.11 # 可分片 ping -c 1 -s &lt;数据大小> -M do 200.20.234.11 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 YES YES 1413 1441 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 容器 &lt;&ndash;> 其他宿主机容器 flannel/canal环境vxlan 集群 端点 网卡IP 网卡MTU 金山 宿主机A 10.210.33.107 1500 金山 容器A 10.244.24.63 1450 金山 宿主机B 10.210.33.106 1500 金山 容器B 10.244.2.134 1450 从容器A发送不同大小的ICMP包到容器B
1 2 3 4 # 容器A执行 tracepath 10.222.2.134 ping -c 1 -s &lt;数据大小> 10.244.2.134 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.244.2.134 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES calico环境ipip 集群 端点 网卡IP 网卡MTU 开阳 宿主机A 10.210.10.136 1500 开阳 容器A 200.20.234.11 1440 开阳 宿主机B 10.210.10.84 1500 开阳 容器B 200.20.172.14 1440 从容器A发送不同大小的ICMP包到容器B
1 2 3 4 # 容器A执行 tracepath 200.20.172.14 ping -c 1 -s &lt;数据大小> 200.20.172.14 # 可分片 ping -c 1 -s &lt;数据大小> -M do 200.20.172.14 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 跨集群容器通信 容器 &lt;&ndash;> 其他集群宿主机 flannel/canal环境vxlan 集群 端点 网卡IP 网卡MTU 金山 宿主机A 10.210.33.107 1500 金山 容器A 10.244.24.63 1450 开阳 宿主机B 10.210.10.136 1500 从容器A发送不同大小的ICMP包到宿主机B
1 2 3 4 # 容器A执行 tracepath 10.210.10.136 ping -c 1 -s &lt;数据大小> 10.210.10.136 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.210.10.136 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 从宿主机B发送不同大小的UDP数据报到容器A
1 2 3 4 5 6 7 8 9 # 前提: 容器A关联了NodePort类型或者LoadBalancer类型的service # 容器A执行 python mtu.py -s # 在默认的6666端口启动udp server # 宿主机B执行 # 通过nodeport或者loadbalancer发送udp数据报到容器A中的udp server python mtu.py -l &lt;数据大小> 10.210.33.107:31829 # 可分片 python mtu.py -d -l &lt;数据大小> 10.210.33.107:31829 # 不可分片 数据大小 包大小 是否分片 连通性 1421 1439 NO YES 1422 1440 NO YES 1423 1441 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES calico环境ipip 集群 端点 网卡IP 网卡MTU 开阳 宿主机A 10.210.10.136 1500 开阳 容器A 200.20.234.11 1440 金山 宿主机B 10.210.33.107 1500 从容器A发送不同大小的ICMP包到宿主机B
1 2 3 4 # 容器A执行 tracepath 10.210.33.107 ping -c 1 -s &lt;数据大小> 10.210.33.107 # 可分片 ping -c 1 -s &lt;数据大小> -M do 10.210.33.107 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 NO YES 1471 1499 NO YES 1472 1500 NO YES 1473 1501 YES YES 从宿主机B发送不同大小的UDP数据报到容器A
1 2 3 4 5 6 7 8 9 # 前提: 容器A关联了NodePort类型或者LoadBalancer类型的service # 容器A执行 python mtu.py -s # 在默认的6666端口启动udp server # 宿主机B执行 # 通过nodeport或者loadbalancer发送udp数据报到容器A中的udp server python mtu.py -l &lt;数据大小> -e 10.210.10.136:30681 # 可分片 python mtu.py -d -l &lt;数据大小> -e 10.210.10.136:30681 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 容器 &lt;&ndash;> 其他集群容器 flannel/canal环境vxlan与calico环境ipip 集群 端点 网卡IP 网卡MTU 金山 宿主机A 10.210.33.107 1500 金山 容器A 10.244.24.63 1450 开阳 宿主机B 10.210.10.136 1500 开阳 容器B 200.20.234.11 1440 从容器A发送不同大小的UDP数据报到容器B
1 2 3 4 5 6 7 8 9 # 前提: 容器B关联了NodePort类型或者LoadBalancer类型的service # 容器B执行 python mtu.py -s # 在默认的6666端口启动udp server # 容器A执行 # 通过nodeport或者loadbalancer发送udp数据报到容器B中的udp server python mtu.py -l &lt;数据大小> -e 10.210.10.136:30681 # 可分片 python mtu.py -d -l &lt;数据大小> -e 10.210.10.136:30681 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 YES YES 1421 1449 YES YES 1422 1450 YES YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 从容器B发送不同大小的UDP数据报到容器A
1 2 3 4 5 6 7 8 9 # 前提: 容器A关联了NodePort类型或者LoadBalancer类型的service # 容器A执行 python mtu.py -s # 在默认的6666端口启动udp server # 容器B执行 # 通过nodeport或者loadbalancer发送udp数据报到容器B中的udp server python mtu.py -l &lt;数据大小> -e 10.210.33.107:31829 # 可分片 python mtu.py -d -l &lt;数据大小> -e 10.210.33.107:31829 # 不可分片 数据大小 包大小 是否分片 连通性 1411 1439 NO YES 1412 1440 NO YES 1413 1441 NO YES 1421 1449 NO YES 1422 1450 NO YES 1423 1451 YES YES 1471 1499 YES YES 1472 1500 YES YES 1473 1501 YES YES 结论 从以上多个场景的测试结果可知, 金山集群(canal-vxlan方案)和开阳集群(calico-ipip方案)在正确设置MTU且允许packet自动分片的情况下容器均能够正常提供网络服务, 金山集群容器和开阳集群容器间也可正常通信. 但如果设置packet不允许分片时, 部分场景下会由于packet大小超过PMTU而通信失败.
金山与开阳集群网络插件设置的MTU的不一致不会导致双方容器间相互访问失败.</content></entry></search>